# Metaphor Method Procedure
# Uses metaphors systematically to discover relationships and generate insights

id: metaphor_method
name: Metaphor Method
version: "1.0.0"
domain: core
tier: gold

description: |
  A systematic method for using metaphors to:
  - Discover relationships that aren't obvious
  - Generate new perspectives on problems
  - Test whether discovered relationships are valid
  - Extract abstract structures that apply across domains

core_principle: |
  Metaphors are not just decorative language. They reveal structural
  similarities between domains. By mapping from one domain to another,
  we can discover relationships that transfer.

# ============================================
# THE METHOD
# ============================================

steps:
  - id: 1
    name: Identify the target domain
    action: |
      What are you trying to understand better?
      This is the LITERAL domain you want insight into.

      Example: "Philosophical conclusions"
    output: target_domain

  - id: 2
    name: Find a source metaphor
    action: |
      What is the target domain LIKE?
      Find a different domain that has structural similarities.

      Good source metaphors:
      - Are familiar (you know them well)
      - Have clear structure (relationships are obvious)
      - Are different enough to provide new perspective

      Example: "Conclusions are like movie endings"
    output: source_metaphor

  - id: 3
    name: Map relationships from source
    action: |
      In the source domain, what relationships exist?
      List them without yet checking if they apply to target.

      Example (movie endings):
      - Ending only makes sense given the plot
      - Plot is driven by character motivations
      - Good endings resolve tensions set up earlier
      - Bad endings feel arbitrary
    output: source_relationships

  - id: 4
    name: Translate to target domain
    action: |
      For each source relationship, what's the equivalent in target?
      Don't force it - some may not translate.

      Example translations:
      - "Ending → plot" becomes "conclusion → argument"
      - "Character motivations" becomes "goals/problems"
      - "Resolve tensions" becomes "solve problems set up"
      - "Arbitrary endings" becomes "arbitrary conclusions"
    output: translated_relationships

  - id: 5
    name: Test translations
    action: |
      For each translated relationship, ask:
      - Is this actually true in the target domain?
      - Can I find examples that confirm it?
      - Can I find counterexamples?

      Keep relationships that pass testing.
      Discard or modify those that don't.
    output: tested_relationships

  - id: 6
    name: Extract abstract structure
    action: |
      For relationships that survive testing, what's the abstract structure?
      This is the pattern that applies to BOTH domains.

      Example:
      "Terminal points (endings/conclusions) are evaluated relative to
       their trajectory (plot/argument) and driving forces (motivations/goals)"

      This abstract structure is the real insight.
    output: abstract_structure

  - id: 7
    name: Apply to new metaphors (iterate)
    action: |
      Take the abstract structure and find OTHER metaphors that instantiate it.
      This tests the structure's generality and may reveal new aspects.

      Example: Journey metaphor also has terminal point (destination),
      trajectory (route), and driving forces (reasons for travel).

      What new relationships does the journey metaphor reveal?
    output: iterated_insights

# ============================================
# EXAMPLE APPLICATION
# ============================================

full_example:
  target_domain: "Philosophical inquiry / the n+1 problem"

  metaphor_1:
    source: Movie/story
    source_relationships:
      - Stories have beginnings, middles, ends
      - You don't ask "what came before chapter 1?"
      - Within the story, everything connects
      - Satisfaction comes from closure within the story
    translations:
      - Inquiries have scope (beginning to end)
      - You don't question foundations DURING inquiry
      - Within inquiry, everything should connect
      - Satisfaction comes from closure within scope
    tests:
      - '"Inquiries have scope" - yes, good inquiries are bounded'
      - '"Don''t question foundations during" - yes, that''s meta-inquiry'
      - '"Everything connects" - yes, coherence matters'
      - '"Closure within scope" - yes, this is satisfying termination'
    abstract_structure: |
      Bounded systems provide closure. Asking questions outside the system's
      scope is a different activity than operating within the system.

  metaphor_2:
    source: Game
    source_relationships:
      - Games have rules
      - Rules define valid moves
      - You don't question rules while playing
      - Winning = achieving goal within rules
    translations:
      - Inquiry has rules (logic, evidence)
      - Rules define valid reasoning
      - You don't question rules while using them
      - Success = reaching justified conclusions within rules
    tests:
      - All translations hold
    abstract_structure: |
      Rule-governed activities have internal standards for success.
      Questioning the rules is a different activity from playing by them.

  synthesis: |
    Both metaphors converge on:
    - Bounded activities can terminate
    - Unbounded activities cannot
    - Questioning the bounds is different from operating within them

# ============================================
# GENERATING GOOD METAPHORS
# ============================================

metaphor_generation:
  strategies:
    - 'Ask: "What is this LIKE?" and take the first answer seriously'
    - Look for domains with similar STRUCTURE (not surface similarity)
    - 'Consider: journeys, games, stories, organisms, machines, conversations'
    - Try multiple metaphors - they reveal different aspects

  good_metaphor_signs:
    - Many relationships translate
    - Translations pass testing
    - New insights emerge that weren't obvious before
    - The abstract structure applies beyond these two domains

  bad_metaphor_signs:
    - Few relationships translate
    - Translations seem forced
    - No new insights (just re-describing what we knew)
    - The metaphor is too similar (no new perspective)

# ============================================
# WARNINGS
# ============================================

warnings:
  metaphor_is_not_proof: |
    A metaphor suggesting X doesn't prove X.
    The translation must be TESTED in the target domain.
    Metaphors generate hypotheses; testing validates them.

  forcing_translations: |
    Not every source relationship will translate.
    Don't force bad translations. Note them as "doesn't apply."
    A metaphor that's partially useful is still useful.

  surface_similarity_trap: |
    Similar-sounding things may have different structures.
    "The brain is like a computer" is seductive but may mislead.
    Check the STRUCTURAL correspondence, not just the surface.

# ============================================
# CONNECTION TO MISSION
# ============================================

mission_connection: |
  The metaphor method operationalizes the mission statement's insight that
  metaphors can reveal relationships.

  Key applications:
  - Story metaphor: Revealed that bounded inquiry enables closure
  - Game metaphor: Revealed that rule-questioning is different from rule-following
  - Journey metaphor: Revealed that goals determine what counts as arrival

  These insights came from taking metaphors seriously and testing them.
