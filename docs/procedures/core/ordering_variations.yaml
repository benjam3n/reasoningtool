# Ordering Strategy Variations
# Different philosophies for sequencing steps in procedures
# Each variation optimizes for different outcomes

id: ordering_variations
name: Ordering Strategy Variations
version: "4.0.0"
domain: core

description: |
  Alternative ordering strategies for procedure steps. The base order_procedure
  uses a default prioritization. These variations offer different sequencing
  philosophies, each optimal for different contexts.

purpose: |
  Not all tasks should be ordered the same way. A crisis needs fail-fast ordering;
  a learning project needs information-gain ordering; a team project needs
  parallel-maximizing ordering. This procedure helps select and apply the right
  ordering strategy for the context.

tags:
  - ordering
  - sequencing
  - planning
  - variations

# ============================================
# VARIATION CATEGORIES
# ============================================
# Two-level selection: first pick a category, then pick a specific variation
# Categories group related ordering philosophies to simplify selection

variation_categories:

  # ----------------------------------------
  # CATEGORY 1: RISK MANAGEMENT
  # ----------------------------------------
  risk_management:
    id: risk_management
    name: "Risk Management Orderings"
    description: |
      Orderings focused on managing uncertainty, preserving options, and
      handling irreversible decisions. Use these when the stakes are high
      and you need to minimize downside risk or maintain flexibility.
    member_variations:
      - fail_fast_ordering
      - reversibility_ordering
      - option_preserving_ordering
      - defense_in_depth_ordering
    when_to_consider: |
      - High uncertainty about feasibility or outcomes
      - Expensive consequences of wrong decisions
      - Irreversible actions that foreclose options
      - Safety-critical systems requiring redundancy
      - Need to validate assumptions before major investment

  # ----------------------------------------
  # CATEGORY 2: MOTIVATION & PSYCHOLOGY
  # ----------------------------------------
  motivation_psychology:
    id: motivation_psychology
    name: "Motivation & Psychology Orderings"
    description: |
      Orderings that account for human psychological factors like energy,
      motivation, habits, and engagement. Essential for human executors
      who need to maintain sustainable performance over time.
    member_variations:
      - momentum_ordering
      - energy_aware_ordering
      - energy_envelope_ordering
      - anchor_based_ordering
    when_to_consider: |
      - Human executor (not automated)
      - Low motivation or energy levels
      - Long work sessions requiring pacing
      - Building new habits or routines
      - Need to maintain stakeholder engagement

  # ----------------------------------------
  # CATEGORY 3: LEARNING & DISCOVERY
  # ----------------------------------------
  learning_discovery:
    id: learning_discovery
    name: "Learning & Discovery Orderings"
    description: |
      Orderings optimized for acquiring knowledge, validating hypotheses,
      and iterative learning. Use when the goal is understanding rather
      than just completion, or when requirements are uncertain.
    member_variations:
      - learning_optimized_ordering
      - curiosity_driven_ordering
      - build_measure_learn_ordering
    when_to_consider: |
      - Exploratory projects with evolving requirements
      - Research or investigation tasks
      - Validating product-market fit
      - Situations with many unknown unknowns
      - When learning drives future decisions

  # ----------------------------------------
  # CATEGORY 4: TIME & DEADLINE MANAGEMENT
  # ----------------------------------------
  time_deadline:
    id: time_deadline
    name: "Time & Deadline Management Orderings"
    description: |
      Orderings driven by temporal constraints, deadlines, and timing
      requirements. Use when external time pressures dominate or when
      multiple workstreams must converge at specific moments.
    member_variations:
      - deadline_driven_ordering
      - critical_ratio_ordering
      - peak_targeting_ordering
      - convergence_timing_ordering
    when_to_consider: |
      - Hard external deadlines exist
      - Multiple deliverables with different due dates
      - Peak performance needed at specific time (demos, launches)
      - Multiple parallel workstreams that must converge
      - Dynamic environment where priorities shift

  # ----------------------------------------
  # CATEGORY 5: RESOURCE OPTIMIZATION
  # ----------------------------------------
  resource_optimization:
    id: resource_optimization
    name: "Resource Optimization Orderings"
    description: |
      Orderings focused on maximizing throughput, minimizing waste,
      and efficiently utilizing available resources. Use when efficiency
      and resource utilization are primary concerns.
    member_variations:
      - throughput_optimized_ordering
      - parallel_maximizing_ordering
      - dependency_fanout_ordering
      - vital_few_first_ordering
      - batch_vs_stream_ordering
      - demand_driven_ordering
    when_to_consider: |
      - Many tasks of varying duration
      - Team execution with multiple people
      - Need to maximize completions per unit time
      - Want to minimize context-switching costs
      - Uneven distribution of value across tasks

  # ----------------------------------------
  # CATEGORY 6: FAIRNESS & ALLOCATION
  # ----------------------------------------
  fairness_allocation:
    id: fairness_allocation
    name: "Fairness & Allocation Orderings"
    description: |
      Orderings that balance competing priorities, prevent starvation,
      and allocate resources proportionally. Use when multiple stakeholders
      or categories need fair treatment over time.
    member_variations:
      - weighted_fairness_ordering
      - round_robin_ordering
      - proportional_confidence_ordering
    when_to_consider: |
      - Multiple stakeholders with different importance levels
      - Must prevent any category from being ignored
      - Need predictable, bounded wait times
      - Allocating across uncertain options
      - Long-running system where fairness matters

  # ----------------------------------------
  # CATEGORY 7: CRISIS & TRIAGE
  # ----------------------------------------
  crisis_triage:
    id: crisis_triage
    name: "Crisis & Triage Orderings"
    description: |
      Orderings for resource-constrained emergency situations where
      not everything can be addressed. Use when you must maximize
      positive outcomes with limited resources, accepting some losses.
    member_variations:
      - triage_severity_ordering
    when_to_consider: |
      - Resource-constrained crisis situations
      - Multiple urgent competing demands
      - Some items cannot be saved regardless of effort
      - Need to maximize overall positive outcomes
      - Must make hard prioritization decisions

  # ----------------------------------------
  # CATEGORY 8: NEGOTIATION & STRATEGY
  # ----------------------------------------
  negotiation_strategy:
    id: negotiation_strategy
    name: "Negotiation & Strategy Orderings"
    description: |
      Orderings for strategic interactions, negotiations, and situations
      where the sequence of actions affects others' responses. Use when
      dealing with counterparties or optimizing trade-offs.
    member_variations:
      - commitment_first_ordering
      - concession_patterned_ordering
      - information_position_ordering
      - diminishing_returns_ordering
    when_to_consider: |
      - Negotiation or competitive contexts
      - Need to shape how others respond
      - Trade-offs where giving up something
      - Iterative work with decreasing returns
      - When observation before action is valuable

  # ----------------------------------------
  # CATEGORY 9: PROGRESSIVE BUILDING
  # ----------------------------------------
  progressive_building:
    id: progressive_building
    name: "Progressive Building Orderings"
    description: |
      Orderings that build complexity incrementally, ensuring each step
      works before adding the next. Use for learning, training, or
      building systems where foundations matter.
    member_variations:
      - scaffolded_progression_ordering
      - prerequisite_chain_ordering
    when_to_consider: |
      - Learning new skills or technologies
      - Building complex systems incrementally
      - Training or onboarding processes
      - When gaps in foundation cause later failures
      - Prototyping with increasing fidelity

  # ----------------------------------------
  # CATEGORY 10: COMMUNICATION & NARRATIVE
  # ----------------------------------------
  communication_narrative:
    id: communication_narrative
    name: "Communication & Narrative Orderings"
    description: |
      Orderings for presentations, writing, and communication where
      the sequence affects audience engagement and comprehension.
      Use when structuring content for human consumption.
    member_variations:
      - tension_arc_ordering
      - inverted_pyramid_ordering
    when_to_consider: |
      - Presentations or pitches
      - Status updates and reports
      - Content that may be truncated
      - Need to engage and satisfy audience
      - Executive communication

  # ----------------------------------------
  # CATEGORY 11: PRIORITY FRAMEWORKS
  # ----------------------------------------
  priority_frameworks:
    id: priority_frameworks
    name: "Priority Framework Orderings"
    description: |
      Orderings based on classic priority frameworks that classify
      items by urgency, importance, constraints, or recency.
      Use when you need a systematic way to rank items.
    member_variations:
      - urgency_importance_ordering
      - most_constrained_first_ordering
      - recency_weighted_ordering
    when_to_consider: |
      - Overwhelmed with mixed priorities
      - Scheduling with many constraints
      - Context-switching between workstreams
      - Urgency crowding out importance
      - Items have restricted choices/options

  # ----------------------------------------
  # CATEGORY 12: ARCHITECTURE & DESIGN
  # ----------------------------------------
  architecture_design:
    id: architecture_design
    name: "Architecture & Design Orderings"
    description: |
      Orderings for software development that determine whether to
      start from interfaces (outside-in) or domain logic (inside-out).
      Use when building systems with external consumers or complex domains.
    member_variations:
      - outside_in_ordering
      - inside_out_ordering
    when_to_consider: |
      - Building systems with external consumers
      - Contract or interface must be stable
      - Complex business rules that must be correct
      - Multiple teams need to integrate
      - Need to decide build direction

  # ----------------------------------------
  # CATEGORY 13: GRAPH TRAVERSAL
  # ----------------------------------------
  graph_traversal:
    id: graph_traversal
    name: "Graph Traversal Orderings"
    description: |
      Orderings derived from fundamental graph traversal algorithms.
      Use when problems have explicit dependency structures, need
      shortest paths, or involve exploring tree/graph structures.
    member_variations:
      - topological_sort_ordering
      - breadth_first_ordering
      - depth_first_ordering
      - bidirectional_search_ordering
    when_to_consider: |
      - Tasks have explicit dependencies (DAG)
      - Need shortest path (fewest steps)
      - Need to explore all paths exhaustively
      - Know both start and goal states
      - Building/compiling with dependencies

  # ----------------------------------------
  # CATEGORY 14: ALGORITHMIC OPTIMIZATION
  # ----------------------------------------
  algorithmic_optimization:
    id: algorithmic_optimization
    name: "Algorithmic Optimization Orderings"
    description: |
      Orderings based on classic algorithm design paradigms: greedy,
      dynamic programming, divide-and-conquer, and branch-and-bound.
      Use when problems have optimal substructure or can be decomposed.
    member_variations:
      - greedy_local_ordering
      - dynamic_subproblem_ordering
      - divide_conquer_ordering
      - branch_bound_ordering
    when_to_consider: |
      - Local optimum leads to global optimum (greedy)
      - Overlapping subproblems exist (DP)
      - Problem splits into independent parts (D&C)
      - Optimization with computable bounds (B&B)
      - Mathematical optimization problems

  # ----------------------------------------
  # CATEGORY 15: CONSTRAINT SOLVING
  # ----------------------------------------
  constraint_solving:
    id: constraint_solving
    name: "Constraint Solving Orderings"
    description: |
      Orderings for constraint satisfaction and guided search problems.
      Use when building solutions incrementally with constraints or
      when heuristics can guide search toward goals.
    member_variations:
      - backtrack_prune_ordering
      - heuristic_guided_ordering
    when_to_consider: |
      - Constraint satisfaction problems
      - Can validate partial solutions
      - Have heuristic estimate to goal
      - Puzzles, scheduling, planning
      - Need systematic exploration with pruning

  # ----------------------------------------
  # CATEGORY 16: QUEUE & SCHEDULING
  # ----------------------------------------
  queue_scheduling:
    id: queue_scheduling
    name: "Queue & Scheduling Orderings"
    description: |
      Orderings for managing queues, processing items by priority,
      and systematic debugging. Use when items have priorities or
      when searching for root causes.
    member_variations:
      - priority_queue_ordering
      - uniform_cost_ordering
      - bisection_debugging_ordering
    when_to_consider: |
      - Items have varying priorities
      - Weighted graph shortest path needed
      - Root cause unknown among many possibilities
      - Priorities may change dynamically
      - Need efficient access to highest priority

  # ----------------------------------------
  # CATEGORY 17: LOCAL SEARCH
  # ----------------------------------------
  local_search:
    id: local_search
    name: "Local Search Orderings"
    description: |
      Orderings based on local search optimization: improving from
      current position, escaping local optima, and systematic exploration
      with memory. Use for optimization without global structure.
    member_variations:
      - hill_climbing_ordering
      - simulated_annealing_ordering
      - random_restart_ordering
      - tabu_search_ordering
    when_to_consider: |
      - Optimization with clear neighbor structure
      - Need to escape local optima
      - Many local optima exist
      - Good-enough solution acceptable
      - Want to avoid cycling in search

  # ----------------------------------------
  # CATEGORY 18: POPULATION-BASED SEARCH
  # ----------------------------------------
  population_based_search:
    id: population_based_search
    name: "Population-Based Search Orderings"
    description: |
      Orderings that maintain multiple candidate solutions or use
      iterative deepening. Use when exploring multiple regions
      simultaneously or when memory/optimality trade-offs matter.
    member_variations:
      - genetic_evolutionary_ordering
      - beam_search_ordering
      - iterative_deepening_ordering
    when_to_consider: |
      - Complex optimization with many local optima
      - Need to explore multiple regions simultaneously
      - Limited memory but need optimal solution
      - Large branching factor, limited resources
      - Parallel evaluation possible

  # ----------------------------------------
  # CATEGORY 19: BANDIT EXPLORATION
  # ----------------------------------------
  bandit_exploration:
    id: bandit_exploration
    name: "Bandit Exploration Orderings"
    description: |
      Orderings from multi-armed bandit algorithms for balancing
      exploration of unknown options with exploitation of known good
      options. Use for sequential decision-making with learning.
    member_variations:
      - epsilon_greedy_ordering
      - thompson_sampling_ordering
      - softmax_boltzmann_ordering
      - ucb_exploration_ordering
      - monte_carlo_tree_ordering
    when_to_consider: |
      - Need to balance exploration and exploitation
      - Sequential decisions with learning
      - A/B testing and experimentation
      - Can model uncertainty about options
      - Large search spaces (games, planning)

  # ----------------------------------------
  # CATEGORY 20: DIVERSITY SEARCH
  # ----------------------------------------
  diversity_search:
    id: diversity_search
    name: "Diversity Search Orderings"
    description: |
      Orderings that prioritize behavioral diversity, novelty, and
      coverage of solution space. Use when you need multiple diverse
      solutions or when objectives are deceptive.
    member_variations:
      - novelty_search_ordering
      - go_explore_ordering
      - map_elites_ordering
      - levy_flight_ordering
      - quality_diversity_ordering
    when_to_consider: |
      - Want diverse solutions, not just one
      - Objective is deceptive (many local optima)
      - Need to illuminate solution landscape
      - Building repertoire of options
      - Targets are sparse and randomly distributed

  # ----------------------------------------
  # CATEGORY 21: MUSIC COMPOSITION & PERFORMANCE
  # ----------------------------------------
  music_composition_performance:
    id: music_composition_performance
    name: "Music Composition & Performance Orderings"
    description: |
      Orderings inspired by musical forms and performance practices.
      Use when content needs narrative structure, thematic development,
      or audience engagement over extended experiences.
    member_variations:
      - sonata_form_ordering
      - theme_and_variations_ordering
      - fugue_construction_ordering
      - rondo_form_ordering
      - call_and_response_ordering
      - crescendo_building_ordering
      - concert_setlist_ordering
    when_to_consider: |
      - Content needs introduce-develop-resolve narrative arc
      - Teaching same concept through multiple examples/contexts
      - Multiple voices/perspectives must combine harmoniously
      - Key message needs reinforcement through repetition
      - Work proceeds through dialogic exchange
      - Building toward climactic reveal or announcement
      - Extended experience needs energy management

  # ----------------------------------------
  # CATEGORY 22: MILITARY STRATEGY
  # ----------------------------------------
  military_strategy:
    id: military_strategy
    name: "Military Strategy Orderings"
    description: |
      Orderings derived from military doctrine and strategic principles.
      Use when facing active competition, time pressure, distributed
      execution, or when decisive action at key points is required.
    member_variations:
      - ooda_loop_ordering
      - schwerpunkt_ordering
      - auftragstaktik_ordering
      - economy_of_force_ordering
      - concentration_of_force_ordering
      - interior_lines_ordering
      - culminating_point_ordering
      - center_of_gravity_ordering
      - phases_of_operations_ordering
    when_to_consider: |
      - Active competitor/adversary will react to your actions
      - Need to act faster than environment changes
      - There is a decisive point where victory makes everything easier
      - Execution will be distributed with local autonomy needed
      - Resources insufficient for all objectives simultaneously
      - Facing multiple separated threats/competitors
      - Risk of overextension or unsustainable commitments
      - Work has distinct preparation, execution, and sustain phases

  # ----------------------------------------
  # CATEGORY 23: PROJECT MANAGEMENT
  # ----------------------------------------
  project_management:
    id: project_management
    name: "Project Management Orderings"
    description: |
      Orderings from formal project management methodologies (PERT, CPM,
      CCPM, Agile). Use when managing schedules, resources, and uncertainty
      in complex multi-person projects with explicit dependencies.
    member_variations:
      - pert_ordering
      - critical_path_ordering
      - critical_chain_ordering
      - agile_sprint_ordering
      - earned_value_ordering
      - resource_leveling_ordering
      - fast_tracking_crashing_ordering
    when_to_consider: |
      - Managing complex project schedules
      - Need probabilistic duration estimates
      - Resource constraints affect scheduling
      - Must compress schedule to meet deadline
      - Tracking earned value and schedule variance
      - Multiple parallel workstreams with dependencies
      - Need to optimize critical path or critical chain

  # ----------------------------------------
  # CATEGORY 24: PEDAGOGY & EDUCATIONAL THEORY
  # ----------------------------------------
  pedagogy_educational:
    id: pedagogy_educational
    name: "Pedagogy & Educational Theory Orderings"
    description: |
      Orderings based on learning science research and educational psychology.
      Use when learning, skill-building, or long-term retention is a primary
      goal. These variations optimize for durable understanding rather than
      immediate performance.
    member_variations:
      - spiral_curriculum_ordering
      - mastery_learning_ordering
      - cognitive_load_ordering
      - worked_examples_ordering
      - fading_scaffolds_ordering
      - interleaved_practice_ordering
      - spaced_repetition_ordering
      - desirable_difficulties_ordering
    when_to_consider: |
      - Learning or skill-building is a primary goal
      - Long-term retention matters more than immediate performance
      - Material has high intrinsic complexity
      - Learners are novices who need scaffolding
      - Teaching hierarchical skills where gaps compound
      - Building intuition before formal understanding
      - Training with eventual autonomous performance
      - Need to counter illusions of competence

  # ----------------------------------------
  # CATEGORY 25: DETECTION & VERIFICATION
  # ----------------------------------------
  detection_verification:
    id: detection_verification
    name: "Detection & Verification Orderings"
    description: |
      Orderings optimized for detecting cheating, fraud, deception, and anomalies.
      Use when investigating potential malfeasance, verifying integrity, or
      establishing whether someone or something can be trusted. These variations
      structure investigative and verification steps to maximize detection probability
      while minimizing false positives and protecting against detection evasion.
    member_variations:
      - forensic_audit_ordering
      - benford_anomaly_ordering
      - academic_integrity_ordering
      - anti_cheat_behavioral_ordering
      - baseline_deviation_ordering
      - cognitive_load_interview_ordering
      - peace_model_ordering
      - mice_access_ordering
      - behavioral_tells_ordering
      - trust_but_verify_ordering
      - layered_verification_ordering
    when_to_consider: |
      - Investigating potential fraud, cheating, or deception
      - Auditing financial records or transactions
      - Verifying academic or professional integrity
      - Detecting anomalies in behavioral or statistical patterns
      - Conducting interviews where deception is possible
      - Vetting individuals for sensitive access
      - Building verification systems for high-stakes decisions
      - Counter-intelligence or security screening
      - Validating claims before trusting them

  # ----------------------------------------
  # CATEGORY 26: STRATEGIC DECEPTION
  # ----------------------------------------
  strategic_deception:
    id: strategic_deception
    name: "Strategic Deception Orderings"
    description: |
      Orderings for legitimate competitive, adversarial, and performance contexts
      where the sequence of actions is designed to influence opponent perception,
      manage attention, or create strategic advantage through misdirection.
      Derived from magic/illusion performance, military deception doctrine,
      game theory signaling, poker strategy, and negotiation tactics.

      LEGITIMATE USE CASES ONLY:
      - Competitive strategy and game theory
      - Magic and illusion performance sequencing
      - Poker and bluffing strategy
      - Military deception (feints, misdirection) in authorized contexts
      - Negotiation tactics (anchoring, strategic disclosure)
      - Red team / penetration testing (authorized security testing)
      - Surprise reveals in presentations and announcements
      - Competitive business strategy
    member_variations:
      - misdirection_attention_ordering
      - forcing_choice_ordering
      - signal_manipulation_ordering
      - layered_deception_ordering
      - tempo_disruption_ordering
      - strategic_revelation_ordering
      - false_pattern_ordering
      - leveling_metagame_ordering
    when_to_consider: |
      - Competitive/adversarial context with strategic opponent
      - Performance art requiring audience attention management
      - Authorized security testing (red team exercises)
      - Negotiation where information asymmetry is leverage
      - Game-theoretic situations with signaling dynamics
      - Presentations designed for maximum surprise impact
      - Situations where apparent intent differs from true intent
      - When opponent is analyzing and predicting your moves

# ============================================
# APPLICABILITY
# ============================================
when_to_use:
  - Default ordering doesn't fit the situation
  - Context strongly favors one concern (risk, time, learning, etc.)
  - Need to compare different ordering approaches
  - Building STEPS document and need to justify sequence

when_not_to_use:
  - Steps have strict hard dependencies (order is forced)
  - Only one or two steps (ordering is trivial)
  - Already have externally-mandated sequence

# ============================================
# INTERFACE
# ============================================
inputs:
  - name: steps
    type: list
    required: true
    description: List of steps to order

  - name: dependencies
    type: dict
    required: true
    description: Dependency graph between steps

  - name: context
    type: enum
    values: [default, crisis, learning, team, deadline, exploration, reversibility, throughput, demand, commitment, iterative, progression, dynamic, triage, peak, narrative, recency, anchor, constrained, convergence, fairness, options, envelope, concession, prerequisite, defense, sonata, theme_variations, fugue, rondo, call_response, crescendo, setlist]
    required: false
    default: default
    description: Context that determines which ordering variation to apply

  - name: executor_type
    type: enum
    values: [human_solo, ai_agent, team, automated]
    required: false
    description: Who executes affects energy and parallel considerations

outputs:
  - name: ordered_steps
    type: list
    description: Steps in recommended execution order

  - name: ordering_rationale
    type: string
    description: Why this order was chosen

  - name: alternative_orderings
    type: list
    description: Other valid orderings with trade-offs

# ============================================
# ORDERING VARIATIONS
# ============================================
variations:

  # ----------------------------------------
  # VARIATION 1: FAIL-FAST ORDERING
  # ----------------------------------------
  fail_fast:
    id: fail_fast_ordering
    name: "Fail-Fast Ordering"
    category: risk_management

    philosophy: |
      Do the most uncertain, risky, or likely-to-fail steps FIRST.
      If something will fail, find out immediately before investing
      more effort. Preserves optionality and avoids sunk cost.

    when_to_use:
      - High uncertainty about feasibility
      - Expensive later steps that would be wasted on failure
      - Multiple possible paths, need to validate one early
      - Limited resources that shouldn't be wasted

    prioritization_rules:
      1_highest_uncertainty:
        rule: "Steps with unknown outcomes go first"
        reason: "Resolve uncertainty before committing"

      2_highest_risk:
        rule: "Steps most likely to fail go early"
        reason: "Fail before investing more effort"

      3_blocking_decisions:
        rule: "Decision points that affect later steps go first"
        reason: "Don't do work that depends on unknown decisions"

      4_assumption_tests:
        rule: "Steps that test key assumptions go early"
        reason: "Validate assumptions before building on them"

    anti_patterns:
      - "Saving risky work for later"
      - "Hoping problems will resolve themselves"
      - "Doing easy comfortable work first to feel productive"

    example:
      context: "Building a startup product"
      steps:
        - "Build full feature set"
        - "Talk to potential customers"
        - "Create polished UI"
        - "Set up infrastructure"
      fail_fast_order:
        1: "Talk to potential customers (highest uncertainty - do they want this?)"
        2: "Build minimal prototype"
        3: "Set up infrastructure (only if validated)"
        4: "Create polished UI (only if validated)"
      rationale: "Customer validation is highest risk - find out before building"

  # ----------------------------------------
  # VARIATION 2: MOMENTUM ORDERING
  # ----------------------------------------
  momentum:
    id: momentum_ordering
    name: "Momentum Ordering (Quick Wins First)"
    category: motivation_psychology

    philosophy: |
      Start with easy, completable tasks to build momentum and confidence.
      Progress begets progress. Completed tasks provide psychological fuel
      for tackling harder ones. Particularly good for human executors prone
      to procrastination or overwhelm.

    when_to_use:
      - Human executor feeling overwhelmed
      - Need to demonstrate early progress (stakeholder visibility)
      - Low motivation or energy
      - Long project needing sustained engagement

    prioritization_rules:
      1_quick_completables:
        rule: "Tasks that can be finished quickly go first"
        reason: "Build sense of progress and accomplishment"

      2_high_visibility:
        rule: "Tasks with visible outputs go early"
        reason: "Tangible progress maintains motivation"

      3_unblock_easy_chains:
        rule: "Easy tasks that unblock other easy tasks go first"
        reason: "Creates cascade of completions"

      4_defer_big_ambiguous:
        rule: "Large uncertain tasks come after momentum established"
        reason: "Tackle hard things from position of strength"

    anti_patterns:
      - "Starting with the hardest task (leads to paralysis)"
      - "Saving all easy tasks for later (no early wins)"
      - "Deprioritizing visible tasks (lose stakeholder support)"

    example:
      context: "Learning a new programming language"
      steps:
        - "Build a complex project"
        - "Read entire documentation"
        - "Write Hello World"
        - "Complete 5 small tutorials"
        - "Set up development environment"
      momentum_order:
        1: "Set up development environment (quick, necessary)"
        2: "Write Hello World (instant success)"
        3: "Complete 5 small tutorials (building confidence)"
        4: "Read documentation (with context from tutorials)"
        5: "Build complex project (momentum established)"
      rationale: "Build confidence through small wins before tackling complexity"

  # ----------------------------------------
  # VARIATION 3: LEARNING-OPTIMIZED ORDERING
  # ----------------------------------------
  learning_optimized:
    id: learning_optimized_ordering
    name: "Learning-Optimized Ordering"
    category: learning_discovery

    philosophy: |
      Order steps to maximize information gained per unit effort.
      Early steps should reveal information that improves decisions
      about later steps. Treat the process as an information-gathering
      exercise, not just a completion exercise.

    when_to_use:
      - Exploratory projects where requirements may change
      - Complex domains where learning affects approach
      - When you don't know what you don't know
      - Research or investigation tasks

    prioritization_rules:
      1_information_value:
        rule: "Steps that reveal most information go first"
        reason: "Better decisions downstream"

      2_cheap_experiments:
        rule: "Low-cost probes before expensive commitments"
        reason: "Learn cheaply before betting big"

      3_assumption_revealers:
        rule: "Steps that expose hidden assumptions go early"
        reason: "Surface unknown unknowns"

      4_feedback_generators:
        rule: "Steps that produce feedback go before steps that need it"
        reason: "Enable learning loops"

    anti_patterns:
      - "Committing to full implementation before understanding"
      - "Avoiding exploration because it 'feels unproductive'"
      - "Following fixed plan when early learning suggests changes"

    example:
      context: "Designing a new feature"
      steps:
        - "Write detailed spec"
        - "Build full feature"
        - "Talk to 3 users about problem"
        - "Build throwaway prototype"
        - "A/B test approaches"
      learning_order:
        1: "Talk to 3 users (reveals actual needs)"
        2: "Build throwaway prototype (tests feasibility cheaply)"
        3: "A/B test approaches (validates direction)"
        4: "Write detailed spec (informed by learning)"
        5: "Build full feature (with confidence)"
      rationale: "Each step informs the next; spec comes after understanding"

  # ----------------------------------------
  # VARIATION 4: PARALLEL-MAXIMIZING ORDERING
  # ----------------------------------------
  parallel_maximizing:
    id: parallel_maximizing_ordering
    name: "Parallel-Maximizing Ordering"
    category: resource_optimization

    philosophy: |
      Minimize total elapsed time by maximizing parallel execution.
      Do steps that unblock parallel work first. Prefer fan-out
      patterns over sequential chains. Ideal for teams or when
      multiple resources are available.

    when_to_use:
      - Team execution with multiple people
      - Time pressure (wall clock matters more than total effort)
      - Resources are available but underutilized
      - Want to reduce elapsed time even if total work increases

    prioritization_rules:
      1_fan_out_enablers:
        rule: "Steps that enable parallel work go first"
        reason: "Unblock multiple paths simultaneously"

      2_single_predecessor:
        rule: "Steps that block multiple successors prioritized"
        reason: "Remove bottlenecks"

      3_long_parallel_chains:
        rule: "Start long independent chains early"
        reason: "They run in background while other work happens"

      4_avoid_reconvergence_delay:
        rule: "Balance parallel paths to converge at similar times"
        reason: "No path finishes early and waits"

    anti_patterns:
      - "Serial execution when parallel is possible"
      - "Blocking entire team waiting for one step"
      - "Starting all parallel work at once (may overload)"

    example:
      context: "Building a web application with 3 developers"
      steps:
        - "Define API contract"
        - "Build frontend"
        - "Build backend"
        - "Write tests"
        - "Integration testing"
        - "Deploy"
      parallel_order: |
        1. Define API contract (unblocks parallel work)
        2. [PARALLEL]
           2a. Build frontend (Dev 1)
           2b. Build backend (Dev 2)
           2c. Write tests (Dev 3)
        3. Integration testing (after 2a, 2b, 2c)
        4. Deploy
      rationale: "API contract enables 3 devs to work simultaneously"

  # ----------------------------------------
  # VARIATION 5: ENERGY-AWARE ORDERING
  # ----------------------------------------
  energy_aware:
    id: energy_aware_ordering
    name: "Energy-Aware Ordering"
    category: motivation_psychology

    philosophy: |
      Match task difficulty to executor energy levels. Hard cognitive
      work when fresh, routine work when tired. For human executors,
      this can dramatically improve output quality and reduce burnout.

    when_to_use:
      - Human solo executor
      - Long work sessions
      - Mix of cognitively demanding and routine tasks
      - Preventing burnout on long projects

    prioritization_rules:
      1_hard_when_fresh:
        rule: "Cognitively demanding tasks at start of session"
        reason: "Best cognitive resources for hardest problems"

      2_creative_after_warm_up:
        rule: "Creative tasks after brief warm-up period"
        reason: "Creativity flows after initial engagement"

      3_routine_when_tired:
        rule: "Routine/mechanical tasks late in session"
        reason: "Can execute on autopilot"

      4_breaks_before_complexity:
        rule: "Schedule breaks before returning to hard problems"
        reason: "Restore cognitive resources"

    energy_profiles:
      morning_person:
        - "Hard analytical work: 8am-12pm"
        - "Creative work: 10am-2pm"
        - "Meetings/collaboration: 2pm-4pm"
        - "Routine work: 4pm-6pm"

      evening_person:
        - "Warm-up/routine: morning"
        - "Creative work: afternoon"
        - "Hard analytical: evening"

    example:
      context: "Full day of coding work"
      steps:
        - "Architecture design (hard)"
        - "Code review (medium)"
        - "Fix minor bugs (routine)"
        - "Write documentation (medium)"
        - "Implement complex feature (hard)"
        - "Update dependencies (routine)"
      energy_aware_order:
        1: "Architecture design (fresh morning energy)"
        2: "Implement complex feature (still fresh)"
        3: "Code review (moderate post-lunch)"
        4: "Write documentation (can do somewhat tired)"
        5: "Fix minor bugs (low energy OK)"
        6: "Update dependencies (mechanical, end of day)"
      rationale: "Hard thinking when fresh, routine when depleted"

  # ----------------------------------------
  # VARIATION 6: REVERSIBILITY ORDERING
  # ----------------------------------------
  reversibility:
    id: reversibility_ordering
    name: "Reversibility Ordering"
    category: risk_management

    philosophy: |
      Do reversible actions before irreversible ones. If you can undo
      something easily, do it earlier. If something is hard or impossible
      to undo, do it later after more certainty. Preserves optionality.

    when_to_use:
      - High-stakes decisions with irreversible components
      - Uncertainty about the right approach
      - Want to preserve ability to change course
      - Multiple stakeholders who might object later

    prioritization_rules:
      1_fully_reversible:
        rule: "Easily undoable steps can go anytime"
        reason: "No lasting commitment"

      2_costly_to_reverse:
        rule: "Steps that are expensive to undo go later"
        reason: "Delay commitment until more certain"

      3_irreversible_last:
        rule: "Cannot-undo steps go as late as possible"
        reason: "Maximum information before point of no return"

      4_create_before_destroy:
        rule: "Creation before deletion, backup before modification"
        reason: "Preserve ability to recover"

    reversibility_categories:
      easily_reversible:
        examples: ["Write draft", "Create branch", "Make config change", "Add feature flag"]
        timing: "Can do early, easy to undo"

      costly_to_reverse:
        examples: ["Send announcement", "Deploy to production", "Hire someone", "Sign contract"]
        timing: "Delay until confident"

      irreversible:
        examples: ["Delete data", "End partnership", "Public statement", "Ship physical product"]
        timing: "Last possible moment after all validation"

    example:
      context: "Launching a major feature"
      steps:
        - "Write press release"
        - "Build feature"
        - "Send press release"
        - "Deploy behind feature flag"
        - "Remove feature flag (general availability)"
        - "Delete old code paths"
      reversibility_order:
        1: "Build feature (can abandon)"
        2: "Deploy behind feature flag (reversible)"
        3: "Write press release (not sent yet)"
        4: "Remove feature flag (harder to reverse)"
        5: "Send press release (irreversible)"
        6: "Delete old code paths (irreversible)"
      rationale: "Each step increases commitment; delay irreversible until confident"

  # ----------------------------------------
  # VARIATION 7: DEADLINE-DRIVEN ORDERING
  # ----------------------------------------
  deadline_driven:
    id: deadline_driven_ordering
    name: "Deadline-Driven Ordering"
    category: time_deadline

    philosophy: |
      Work backward from constraints. If something MUST happen by a date,
      ensure all its predecessors are scheduled with buffer. External
      deadlines dominate; internal preferences are secondary.

    when_to_use:
      - Hard external deadlines exist
      - Multiple deadlines at different times
      - Need to guarantee on-time delivery
      - Dependencies have significant lead times

    prioritization_rules:
      1_deadline_criticality:
        rule: "Steps on deadline-critical paths go first"
        reason: "No slack means no room for delay"

      2_buffer_allocation:
        rule: "Risky steps get more buffer, routine steps less"
        reason: "Absorb variance where it's likely"

      3_deadline_stacking:
        rule: "When multiple deadlines, work backward from each"
        reason: "Don't let one deadline crowd another"

      4_milestone_ordering:
        rule: "Intermediate milestones create forcing functions"
        reason: "Progress checkpoints prevent last-minute crunch"

    example:
      context: "Product launch with fixed date"
      constraints:
        - "Launch: Day 30"
        - "Marketing assets needed: Day 25"
        - "Code freeze: Day 20"
        - "Testing complete: Day 18"
      backward_planning:
        day_1_10: "Development (requires 10 days)"
        day_11_18: "Testing (requires 7 days + 1 buffer)"
        day_15_25: "Marketing asset creation (parallel with testing)"
        day_19_20: "Code freeze prep"
        day_26_30: "Launch prep and buffer"
      rationale: "Work backward from each constraint to ensure nothing is late"

  # ----------------------------------------
  # VARIATION 8: DEPENDENCY-FANOUT ORDERING
  # ----------------------------------------
  dependency_fanout:
    id: dependency_fanout_ordering
    name: "Dependency-Fanout Ordering"
    category: resource_optimization

    philosophy: |
      Prioritize steps that unblock the most other steps. A step that
      enables 5 other steps should happen before a step that enables 1.
      Maximizes the rate at which work becomes unblocked.

    when_to_use:
      - Complex dependency graphs
      - Multiple people waiting for inputs
      - Want to maximize options at each point
      - Reduce blocking and waiting time

    prioritization_rules:
      1_count_dependents:
        rule: "Steps with more dependents go first"
        reason: "Unblock more work sooner"
        formula: "priority = count(steps_waiting_on_this)"

      2_transitive_impact:
        rule: "Consider indirect dependents too"
        reason: "Step A enables B, which enables C, D, E"
        formula: "priority = count(all_downstream_steps)"

      3_weighted_by_value:
        rule: "High-value dependents count more"
        reason: "Unblocking important work > unblocking trivial work"

    example:
      context: "API development with multiple consumers"
      steps:
        A: "Define API schema (enables: B, C, D, E)"
        B: "Build endpoint 1 (enables: F)"
        C: "Build endpoint 2 (enables: G)"
        D: "Write client SDK (enables: H, I, J)"
        E: "Write docs (enables: K)"
      fanout_analysis:
        A: "4 direct dependents"
        D: "3 direct dependents"
        B: "1 direct dependent"
        C: "1 direct dependent"
        E: "1 direct dependent"
      fanout_order:
        1: "A - Define API schema (unblocks 4)"
        2: "D - Write client SDK (unblocks 3)"
        3: "[B, C, E] - Build endpoints and docs (each unblocks 1)"
      rationale: "A unblocks the most work, so it goes first"

  # ----------------------------------------
  # VARIATION 9: THROUGHPUT-OPTIMIZED ORDERING
  # ----------------------------------------
  throughput_optimized:
    id: throughput_optimized_ordering
    name: "Throughput-Optimized Ordering (SPT)"
    category: resource_optimization

    philosophy: |
      Minimize average completion time by doing shortest tasks first.
      From operations research: Shortest Processing Time (SPT) is
      mathematically optimal for minimizing average flow time. This
      maximizes the number of tasks completed per unit time.

    when_to_use:
      - Many tasks of varying duration
      - Goal is to maximize completions
      - Need to reduce average wait time
      - Reporting on "tasks completed" matters

    different_from_momentum: |
      Momentum ordering is psychological (build confidence).
      Throughput ordering is mathematical (minimize average completion time).
      Momentum might pick a visible task over a shorter invisible one.
      Throughput always picks shortest regardless of visibility.

    prioritization_rules:
      1_shortest_first:
        rule: "Tasks with shortest processing time go first"
        reason: "Mathematically minimizes average completion time"
        formula: "Sort by estimated_duration ASC"

      2_preemption_optional:
        rule: "Consider whether to preempt long tasks for new short ones"
        reason: "Shortest Remaining Processing Time (SRPT) variant"

      3_starvation_prevention:
        rule: "Add aging factor to prevent long tasks from never running"
        reason: "Pure SPT can starve long tasks indefinitely"
        formula: "adjusted_priority = duration - (wait_time Ã— aging_factor)"

    anti_patterns:
      - "Doing long tasks first (increases average wait)"
      - "Ignoring task duration in prioritization"
      - "Letting long tasks starve (never scheduled)"

    example:
      context: "Processing support tickets"
      tasks:
        - "Complex bug investigation (4 hours)"
        - "Password reset (5 minutes)"
        - "Feature question (15 minutes)"
        - "Account setup (30 minutes)"
        - "Quick clarification (2 minutes)"
      throughput_order:
        1: "Quick clarification (2 min)"
        2: "Password reset (5 min)"
        3: "Feature question (15 min)"
        4: "Account setup (30 min)"
        5: "Complex bug investigation (4 hours)"
      rationale: "4 customers served in first hour vs 0 if we start with the bug"

    source: "Operations Research - Shortest Processing Time rule"

  # ----------------------------------------
  # VARIATION 10: DEMAND-DRIVEN ORDERING
  # ----------------------------------------
  demand_driven:
    id: demand_driven_ordering
    name: "Demand-Driven Ordering (Pull System)"
    category: resource_optimization

    philosophy: |
      Don't do work until downstream actually needs it. Inspired by
      Toyota's Kanban/JIT system: work is "pulled" by demand rather
      than "pushed" by availability. Avoids doing work that may never
      be needed or becomes obsolete.

    when_to_use:
      - Requirements are uncertain or evolving
      - Work might become unnecessary
      - Want to minimize waste (wasted effort)
      - Downstream consumer signals when ready
      - '"Just-in-time" delivery is acceptable'

    when_not_to_use:
      - Long lead times make late start impossible
      - Downstream has no way to signal demand
      - Work must be done speculatively (research)

    prioritization_rules:
      1_wait_for_signal:
        rule: "Don't start work until downstream requests it"
        reason: "Avoid doing work that isn't needed"

      2_limit_wip:
        rule: "Limit work-in-progress to prevent overload"
        reason: "Focus on completion over starting"
        guideline: "WIP limit = 1-3 items per person"

      3_takt_time:
        rule: "Match pace of work to pace of demand"
        reason: "Sustainable flow without buildup"

      4_pull_chain:
        rule: "Each step pulls from previous step"
        reason: "No speculative inventory at any stage"

    anti_patterns:
      - "Building features before they're requested"
      - "Preparing all materials 'just in case'"
      - "Push mentality: 'We might need this'"
      - "Starting many things, finishing few"

    example:
      context: "Building features for a product"
      push_approach:
        - "Build all planned features"
        - "Some features never used"
        - "Resources wasted on unused work"
      pull_approach:
        - "Build minimal version"
        - "Wait for user feedback/requests"
        - "Build next feature when demand clear"
        - "Resources focused on validated needs"
      rationale: "Only do work when you know it's needed"

    source: "Toyota Production System - Kanban, JIT"

  # ----------------------------------------
  # VARIATION 11: COMMITMENT-FIRST ORDERING
  # ----------------------------------------
  commitment_first:
    id: commitment_first_ordering
    name: "Commitment-First Ordering (Stackelberg)"
    category: negotiation_strategy

    philosophy: |
      Make strategic commitments early to shape others' responses.
      From game theory: the first mover in a sequential game can
      gain advantage by committing, forcing followers to adapt.
      Sometimes you WANT irreversibility to create leverage.

    different_from_reversibility: |
      Reversibility ordering says: "do reversible things first."
      Commitment ordering says: "sometimes do irreversible things
      first to create strategic advantage." The right choice depends
      on whether you're optimizing for optionality or leverage.

    when_to_use:
      - Negotiation or competitive contexts
      - Need to establish position before others
      - Want to shape how others respond
      - Credible commitment creates advantage
      - Moving first prevents others from preempting

    prioritization_rules:
      1_commitment_value:
        rule: "Identify actions that create binding commitments"
        reason: "Commitments shape follower responses"

      2_first_mover_analysis:
        rule: "Assess first-mover advantage vs disadvantage"
        reason: "Not all moves benefit from going first"
        questions:
          - "Does moving first constrain others favorably?"
          - "Can the commitment be credibly enforced?"
          - "Is the commitment observable to others?"

      3_credibility:
        rule: "Commitments must be credible to be effective"
        reason: "Empty threats don't shape behavior"

      4_sequential_ordering:
        rule: "Order moves to maximize strategic leverage"
        reason: "Each move sets context for next"

    anti_patterns:
      - "Committing without strategic purpose"
      - "Making commitments that aren't credible"
      - "Waiting when first-mover advantage exists"
      - "Committing in ways that can be ignored"

    example:
      context: "Negotiating a contract"
      tasks:
        - "Send initial offer"
        - "Research market rates"
        - "Prepare alternatives (BATNA)"
        - "Set public deadline"
        - "Make final proposal"
      commitment_order:
        1: "Research market rates (information)"
        2: "Prepare alternatives (strengthen position)"
        3: "Set public deadline (credible commitment)"
        4: "Send initial offer (anchoring move)"
        5: "Make final proposal (after observing response)"
      rationale: "Public deadline commits you but also pressures counterparty"

    source: "Game Theory - Stackelberg competition, commitment devices"

  # ----------------------------------------
  # VARIATION 12: DIMINISHING-RETURNS AWARE
  # ----------------------------------------
  diminishing_returns:
    id: diminishing_returns_ordering
    name: "Diminishing-Returns Aware Ordering"
    category: negotiation_strategy

    philosophy: |
      Know when to stop or switch before returns decline below
      opportunity cost. From optimal foraging theory: leave a "patch"
      when the marginal return drops below the average return of
      switching to a new patch. Prevents over-investment in declining
      activities.

    when_to_use:
      - Iterative improvement work (optimization, polishing)
      - Research with decreasing discoveries
      - Any activity with diminishing marginal returns
      - When opportunity cost of continuing is high
      - Multiple "patches" to explore

    prioritization_rules:
      1_marginal_value_check:
        rule: "Monitor marginal return of current activity"
        reason: "Detect when returns are declining"
        formula: "Continue while marginal_return > average_return_of_switching"

      2_switch_threshold:
        rule: "Define threshold for switching activities"
        reason: "Prevents over-exploitation"
        examples:
          - "Stop optimizing when gains < 1% per iteration"
          - "Stop researching when last 3 sources added nothing"
          - "Stop debugging when cost exceeds rewrite cost"

      3_patch_quality:
        rule: "Estimate quality of alternative activities"
        reason: "Switching cost must be worth it"

      4_sunk_cost_immunity:
        rule: "Ignore sunk costs when deciding to switch"
        reason: "Past investment doesn't affect future returns"

    anti_patterns:
      - "Polishing endlessly (perfectionism)"
      - "Abandoning too early (impatience)"
      - "Ignoring opportunity cost of continuing"
      - "Sunk cost fallacy ('already invested so much')"

    signals_to_switch:
      - "Last few iterations produced minimal improvement"
      - "Effort required is increasing while gains decrease"
      - "Other activities have higher expected return"
      - "You're in maintenance mode, not growth mode"

    example:
      context: "Researching a topic"
      activities:
        A: "Reading papers in domain X"
        B: "Reading papers in domain Y"
        C: "Talking to experts"
      diminishing_returns_approach:
        - "Start with domain X (most promising)"
        - "After 5 papers: 3 new insights"
        - "After 10 papers: 1 new insight"
        - "After 12 papers: 0 new insights â†’ SWITCH"
        - "Switch to domain Y or expert interviews"
      rationale: "Don't read paper 13-20 in X when returns have dropped"

    source: "Optimal Foraging Theory - Marginal Value Theorem"

  # ----------------------------------------
  # VARIATION 13: SCAFFOLDED PROGRESSION
  # ----------------------------------------
  scaffolded_progression:
    id: scaffolded_progression_ordering
    name: "Scaffolded Progression Ordering"
    category: progressive_building

    philosophy: |
      Start with the simplest complete version, then progressively
      elaborate. Each step builds on the last, staying within the
      "zone of proximal development" - challenging but achievable
      given prior steps. Temporary support structures are added then
      removed as capability grows.

    when_to_use:
      - Learning new skills
      - Building complex systems incrementally
      - Training or onboarding
      - Prototyping with increasing fidelity
      - When each step must work before adding complexity

    prioritization_rules:
      1_minimum_viable_first:
        rule: "Start with smallest complete version"
        reason: "Establishes foundation that works"
        principle: "Make it work, then make it better"

      2_zone_of_proximal_development:
        rule: "Each step should be achievable given prior steps"
        reason: "Prevents overwhelming leaps"
        test: "Can this be done with only prior knowledge + small stretch?"

      3_progressive_complexity:
        rule: "Add complexity incrementally"
        reason: "Each addition is debuggable against working baseline"
        pattern: "Version N+1 = Version N + one new element"

      4_scaffold_and_remove:
        rule: "Add temporary support, remove when no longer needed"
        reason: "Prevents permanent dependency on scaffolding"

    complexity_dimensions:
      - "Fewer features â†’ more features"
      - "Simpler cases â†’ edge cases"
      - "Happy path â†’ error handling"
      - "Manual â†’ automated"
      - "Hardcoded â†’ configurable"
      - "Single â†’ multiple"
      - "Synchronous â†’ asynchronous"

    anti_patterns:
      - "Building the complex version first"
      - "Adding all features before any work"
      - "Skipping steps in progression"
      - "Never removing scaffolding"

    example:
      context: "Building a web application"
      scaffolded_steps:
        1: "Static HTML page (works, no logic)"
        2: "Add single dynamic element (one moving part)"
        3: "Add user input (interaction)"
        4: "Add database persistence (state)"
        5: "Add user authentication (complexity)"
        6: "Add multiple users (scale)"
        7: "Add error handling (robustness)"
        8: "Add performance optimization (polish)"
      rationale: "Each step has working baseline to build on"

    source: "Vygotsky - Zone of Proximal Development, Scaffolding"

  # ----------------------------------------
  # VARIATION 14: CRITICAL-RATIO DYNAMIC
  # ----------------------------------------
  critical_ratio_dynamic:
    id: critical_ratio_ordering
    name: "Critical-Ratio Dynamic Ordering"
    category: time_deadline

    philosophy: |
      Continuously rebalance task priority based on urgency relative
      to work remaining. Unlike static ordering, priorities shift as
      time passes and work completes. Tasks with low critical ratio
      (little slack, much work) get priority.

    formula: |
      Critical Ratio (CR) = (Time until due date) / (Work time remaining)

      CR < 1.0: Behind schedule (HIGH PRIORITY)
      CR = 1.0: Exactly on schedule
      CR > 1.0: Ahead of schedule (can defer)

    when_to_use:
      - Multiple tasks with different deadlines
      - Deadlines and work estimates are known
      - Environment is dynamic (new tasks arrive)
      - Need to balance urgency and workload
      - Want adaptive, not static, scheduling

    prioritization_rules:
      1_calculate_ratios:
        rule: "Compute CR for all active tasks"
        formula: "CR = time_remaining / work_remaining"
        frequency: "Recalculate at each decision point"

      2_priority_by_ratio:
        rule: "Lowest CR gets highest priority"
        reason: "Tasks with least slack need attention"
        ordering: "Sort tasks by CR ascending"

      3_dynamic_updates:
        rule: "Recompute when circumstances change"
        triggers:
          - "Task completed"
          - "New task added"
          - "Deadline changed"
          - "Work estimate revised"
          - "Significant time passed"

      4_threshold_alerts:
        rule: "Alert when any CR drops below threshold"
        thresholds:
          warning: "CR < 1.2 (getting tight)"
          critical: "CR < 1.0 (behind schedule)"
          emergency: "CR < 0.5 (crisis mode)"

    anti_patterns:
      - "Static priority that doesn't adapt"
      - "Ignoring changing deadlines"
      - "Not updating work estimates"
      - "Working on high-CR tasks while low-CR tasks slip"

    example:
      context: "Managing multiple project deliverables"
      tasks_at_day_0:
        A: "Due day 10, needs 5 days work â†’ CR = 10/5 = 2.0"
        B: "Due day 6, needs 4 days work â†’ CR = 6/4 = 1.5"
        C: "Due day 8, needs 6 days work â†’ CR = 8/6 = 1.33"
      initial_priority: "C (1.33) â†’ B (1.5) â†’ A (2.0)"

      after_day_3_completed_C:
        A: "Due day 10, needs 5 days â†’ CR = 7/5 = 1.4"
        B: "Due day 6, needs 4 days â†’ CR = 3/4 = 0.75 (CRITICAL)"

      rebalanced_priority: "B (0.75) â†’ A (1.4)"
      rationale: "B's ratio dropped below 1.0, needs immediate attention"

    source: "Operations Research - Critical Ratio scheduling rule"

  # ----------------------------------------
  # VARIATION 15: TRIAGE-SEVERITY ORDERING
  # ----------------------------------------
  triage_severity:
    id: triage_severity_ordering
    name: "Triage-Severity Ordering"
    category: crisis_triage

    philosophy: |
      Prioritize based on severity AND treatability. From medical triage
      (START algorithm): not just "who needs help most" but "who will
      benefit most from help now." Maximize positive outcomes given
      limited resources. Sometimes the most critical case isn't the
      best use of resources.

    when_to_use:
      - Resource-constrained situations
      - Multiple urgent competing demands
      - Some items can't be saved regardless of effort
      - Need to maximize overall positive outcomes
      - Crisis or emergency contexts

    prioritization_rules:
      1_triage_categories:
        rule: "Sort into categories by severity and treatability"
        categories:
          immediate: "Critical, will benefit from immediate attention"
          delayed: "Serious but can wait without deterioration"
          minor: "Can handle themselves or wait longest"
          expectant: "Too far gone to save with available resources"

      2_immediate_first:
        rule: "Address 'immediate' category first"
        reason: "Highest impact per unit of resource"

      3_skip_expectant:
        rule: "Don't spend resources on unsalvageable items"
        reason: "Opportunity cost - others can be saved"
        hard_truth: "Sometimes you must let things fail to save others"

      4_reassess_continuously:
        rule: "Conditions change; re-triage periodically"
        reason: "Delayed can become immediate; immediate can become expectant"

    anti_patterns:
      - "Helping whoever asks first (FIFO in crisis)"
      - "Spending all resources on unsalvageable case"
      - "Ignoring severity because task is 'interesting'"
      - "Static triage without reassessment"

    example:
      context: "Tech debt crisis - multiple critical bugs"
      bugs:
        A: "Payment system down - immediate (will lose revenue now)"
        B: "Minor UI glitch - minor (annoying but functional)"
        C: "Database corruption - delayed (serious but stable for now)"
        D: "Legacy system failing - expectant (too tangled, must rewrite later)"
      triage_order:
        1: "A - Payment system (immediate - highest impact)"
        2: "C - Database (delayed - prevent escalation)"
        3: "B - UI glitch (minor - when bandwidth permits)"
        skip: "D - Legacy system (expectant - don't patch, schedule rewrite)"
      rationale: "Greatest good for greatest number of users"

    source: "Medical Triage - START/SALT algorithms"

  # ----------------------------------------
  # VARIATION 16: PEAK-TARGETING ORDERING
  # ----------------------------------------
  peak_targeting:
    id: peak_targeting_ordering
    name: "Peak-Targeting Ordering (Periodization)"
    category: time_deadline

    philosophy: |
      Structure work in phases to peak at specific target times.
      From sports periodization: you can't maintain peak performance
      indefinitely, so plan backward from when peak matters. Build
      from high-volume/low-intensity to low-volume/high-intensity.

    when_to_use:
      - Specific events where peak performance matters (demos, launches, presentations)
      - Cannot maintain maximum effort indefinitely
      - Need to time peak capability precisely
      - Building toward a known culmination point

    key_concepts:
      macrocycle: "Entire period leading to peak (months/year)"
      mesocycle: "Training blocks with specific focus (weeks)"
      microcycle: "Weekly patterns"
      taper: "Reducing volume before peak to recover"

    prioritization_rules:
      1_identify_peak_date:
        rule: "When must you perform at maximum?"
        reason: "All planning works backward from this"

      2_phase_structure:
        rule: "Divide time into preparation, build, and peak phases"
        pattern:
          early: "Foundation work - high volume, general skills"
          middle: "Specific work - moderate volume, targeted skills"
          late: "Peak work - low volume, high intensity, specifics"

      3_taper_before_peak:
        rule: "Reduce volume before peak event"
        reason: "Recover energy while maintaining sharpness"
        guideline: "7-14 days reduced volume before peak"

      4_accept_non_peak:
        rule: "Performance will be lower in early phases"
        reason: "Building foundation requires accepting temporary lower output"

    anti_patterns:
      - "Maximum effort all the time (leads to burnout)"
      - "No clear peak target (diffuse effort)"
      - "Peaking too early (exhausted when it matters)"
      - "Skipping foundation phase (weak peak)"

    example:
      context: "Preparing for a major product launch"
      peak_date: "Day 60"
      periodization:
        days_1_20:
          phase: "Foundation"
          focus: "Architecture, research, prototyping"
          intensity: "High volume, exploratory"
        days_21_45:
          phase: "Build"
          focus: "Core implementation, integration"
          intensity: "Moderate volume, focused"
        days_46_55:
          phase: "Peak preparation"
          focus: "Polish, testing, edge cases"
          intensity: "Low volume, high quality"
        days_56_60:
          phase: "Taper"
          focus: "Final checks, rest, preparation"
          intensity: "Minimal new work, preserve energy"
      rationale: "Peak performance on launch day, not exhaustion"

    source: "Sports Science - Periodization training"

  # ----------------------------------------
  # VARIATION 17: TENSION-ARC ORDERING
  # ----------------------------------------
  tension_arc:
    id: tension_arc_ordering
    name: "Tension-Arc Ordering (Narrative Structure)"
    category: communication_narrative

    philosophy: |
      Structure work to build toward a climax, then resolve.
      From storytelling: setup establishes context, rising action
      builds stakes, climax is the peak moment, resolution ties
      up loose ends. Good for presentations, persuasion, and any
      work with an audience.

    when_to_use:
      - Presentations or pitches
      - User experiences with a journey
      - Persuasive writing or communication
      - Any work that needs to engage and satisfy an audience
      - Project narratives for stakeholders

    three_act_structure:
      act_1_setup:
        purpose: "Establish context, characters, stakes"
        proportion: "~25% of total"
        tasks: "Background, problem definition, why it matters"

      act_2_rising_action:
        purpose: "Build tension, escalate stakes, complications"
        proportion: "~50% of total"
        tasks: "Main work, challenges, progression, obstacles overcome"

      act_3_resolution:
        purpose: "Climax and resolution, payoff"
        proportion: "~25% of total"
        tasks: "Key reveal, solution, conclusion, call to action"

    prioritization_rules:
      1_setup_first:
        rule: "Establish context before diving into details"
        reason: "Audience needs orientation before engagement"

      2_escalate_progressively:
        rule: "Each step should raise stakes higher"
        reason: "Maintains engagement, builds toward climax"

      3_save_best_for_climax:
        rule: "Most impactful content at the ~75% mark"
        reason: "Peak tension before resolution"

      4_resolve_cleanly:
        rule: "Don't end abruptly; provide closure"
        reason: "Satisfying conclusion cements the experience"

    anti_patterns:
      - "Burying the lead (climax too late)"
      - "Front-loading all good content (anticlimactic)"
      - "No setup (audience confused)"
      - "No resolution (unsatisfying)"

    example:
      context: "Product demo presentation"
      tension_arc_order:
        setup:
          - "Establish the problem users face"
          - "Show the pain points and stakes"
        rising_action:
          - "Introduce solution concept"
          - "Show basic functionality"
          - "Add complexity and capability"
          - "Demonstrate edge case handling"
        climax:
          - "Show the 'wow' feature"
          - "Reveal unexpected capability"
        resolution:
          - "Summarize benefits"
          - "Call to action"
          - "Q&A"
      rationale: "Audience engagement peaks at climax, leaves satisfied"

    source: "Storytelling - Three-act structure, narrative arc"

  # ----------------------------------------
  # VARIATION 18: RECENCY-WEIGHTED ORDERING
  # ----------------------------------------
  recency_weighted:
    id: recency_weighted_ordering
    name: "Recency-Weighted Ordering (LRU-style)"
    category: priority_frameworks

    philosophy: |
      Prioritize based on recent access patterns. From cache
      algorithms: what was relevant recently is likely relevant
      again. Recent context is more valuable than distant context.
      "Hot" items stay prioritized; "cold" items drift down.

    when_to_use:
      - Context-switching between multiple workstreams
      - Maintaining working memory across sessions
      - When recent work predicts future needs
      - Managing attention across many items

    prioritization_rules:
      1_track_last_access:
        rule: "Record when each item was last touched"
        reason: "Recency is a proxy for relevance"

      2_recently_touched_up:
        rule: "Items accessed recently get priority"
        reason: "Working context is fresh"

      3_cold_items_drift:
        rule: "Untouched items gradually lose priority"
        reason: "If not needed recently, likely not needed soon"

      4_explicit_pinning:
        rule: "Allow manual override for known-important items"
        reason: "Some items are important despite not being recent"

    variants:
      lru: "Least Recently Used - pure recency"
      lfu: "Least Frequently Used - pure frequency"
      arc: "Adaptive - balances recency and frequency dynamically"

    anti_patterns:
      - "Ignoring recency (old context overwhelms new)"
      - "Pure recency (important but dormant items forgotten)"
      - "No eviction (attention spread too thin)"

    example:
      context: "Managing multiple open projects"
      projects:
        A: "Touched today"
        B: "Touched yesterday"
        C: "Touched last week"
        D: "Touched last month"
      recency_order:
        1: "A - current context, prioritize"
        2: "B - recent context, keep warm"
        3: "C - cooling, deprioritize but don't forget"
        4: "D - cold, consider archiving or explicit keep"
      rationale: "Focus on active work; dormant work can wait"

    source: "Computer Science - Cache eviction policies (LRU, LFU, ARC)"

  # ----------------------------------------
  # VARIATION 19: ANCHOR-BASED ORDERING
  # ----------------------------------------
  anchor_based:
    id: anchor_based_ordering
    name: "Anchor-Based Ordering (Habit Chaining)"
    category: motivation_psychology

    philosophy: |
      Attach new work to existing routines. From behavior design
      (BJ Fogg's Tiny Habits): "After I [existing behavior], I will
      [new behavior]." Sequence tasks so each completed step
      naturally triggers the next. Reduces activation energy.

    when_to_use:
      - Building new habits or routines
      - Onboarding processes
      - Checklists that must flow naturally
      - When motivation is limited
      - Creating reliable sequences

    key_concepts:
      anchor: "Existing reliable behavior that triggers new behavior"
      tiny_behavior: "New behavior scaled down to require minimal effort"
      celebration: "Positive emotion that reinforces the sequence"
      chain: "Multiple behaviors linked in sequence"

    prioritization_rules:
      1_identify_anchors:
        rule: "Find existing reliable behaviors to attach to"
        examples:
          - "After I pour my coffee..."
          - "After I sit at my desk..."
          - "After I finish a meeting..."

      2_sequence_by_natural_flow:
        rule: "Order so each step flows naturally to the next"
        reason: "Reduce friction between steps"
        test: "Does completing step N naturally lead to step N+1?"

      3_start_tiny:
        rule: "Scale down first step to require minimal motivation"
        reason: "Activation energy is highest at start"
        principle: "Make it so easy you can't say no"

      4_build_chains:
        rule: "Link behaviors: A triggers B triggers C"
        reason: "One anchor can cascade through entire routine"

    anti_patterns:
      - "Orphan tasks with no trigger"
      - "Requiring high motivation for first step"
      - "Breaking natural flow with context switches"
      - "Chains that are too long without reinforcement"

    example:
      context: "Morning code review routine"
      anchor_chain:
        anchor: "After I open my laptop"
        step_1: "I will open the PR dashboard (tiny - 2 seconds)"
        step_2: "After dashboard opens, I will pick one PR"
        step_3: "After picking PR, I will read the description"
        step_4: "After reading description, I will leave one comment"
        celebration: "Check off daily code review"
      rationale: "Each step triggers the next; no orphan tasks"

    source: "Behavior Design - BJ Fogg's Tiny Habits, Implementation Intentions"

  # ----------------------------------------
  # VARIATION 20: MOST-CONSTRAINED-FIRST
  # ----------------------------------------
  most_constrained_first:
    id: most_constrained_first_ordering
    name: "Most-Constrained-First Ordering (MRV)"
    category: priority_frameworks

    philosophy: |
      Address items with fewest options first. From constraint
      satisfaction: the variable with the minimum remaining values
      (MRV) should be assigned first because it's most likely to
      fail, revealing problems early. Highly constrained items
      have less flexibility, so resolve them before they become
      impossible.

    when_to_use:
      - Scheduling with many constraints
      - Resource allocation with limited options
      - Any problem where some items have restricted choices
      - Planning where early decisions constrain later ones

    prioritization_rules:
      1_count_options:
        rule: "For each item, count how many valid options exist"
        reason: "Items with fewer options are more constrained"

      2_most_constrained_first:
        rule: "Address items with fewest options first"
        reason: "Less flexibility = higher risk of failure"
        formula: "priority = 1 / count(valid_options)"

      3_degree_tiebreaker:
        rule: "Among equally constrained items, pick most constraining"
        reason: "Resolving it will simplify other decisions"
        formula: "tiebreaker = count(other_items_this_affects)"

      4_propagate_constraints:
        rule: "After each assignment, update remaining options"
        reason: "Constraints cascade; keep counts current"

    anti_patterns:
      - "Addressing unconstrained items first (easy but wasteful)"
      - "Ignoring constraint propagation"
      - "Not reassessing after decisions"
      - "Treating all items as equally flexible"

    example:
      context: "Scheduling conference room bookings"
      bookings:
        A: "Must be Tuesday or Wednesday (2 options)"
        B: "Any day works (5 options)"
        C: "Must be Tuesday (1 option)"
        D: "Monday, Tuesday, or Wednesday (3 options)"
      mcf_order:
        1: "C - only 1 option, schedule first"
        2: "A - only 2 options, schedule second"
        3: "D - 3 options, schedule third"
        4: "B - most flexible, schedule last"
      after_scheduling_C:
        A: "Now only Wednesday (C took Tuesday)"
        D: "Now Monday or Wednesday"
        B: "Now 4 options"
      rationale: "Most constrained reveals failures fastest"

    source: "AI/Constraint Satisfaction - Minimum Remaining Values (MRV) heuristic"

  # ----------------------------------------
  # VARIATION 21: CONVERGENCE-TIMING ORDERING
  # ----------------------------------------
  convergence_timing:
    id: convergence_timing_ordering
    name: "Convergence-Timing Ordering (Mise en Place)"
    category: time_deadline

    philosophy: |
      Time multiple workstreams to converge at the right moment.
      From culinary arts (mise en place): when preparing a meal,
      all dishes must be ready simultaneously. Plan backward from
      the serving moment, accounting for different preparation and
      cooking times. Some items can wait; others cannot.

    when_to_use:
      - Multiple parallel workstreams that must converge
      - Different tasks have different durations
      - Final delivery requires simultaneous completion
      - Some outputs degrade if completed too early

    key_concepts:
      convergence_point: "The moment when all streams must meet"
      buffer_tasks: "Tasks that can wait without degradation"
      critical_timing: "Tasks that must complete at precise moment"
      prep_vs_execution: "What can be done ahead vs. last minute"

    prioritization_rules:
      1_identify_convergence:
        rule: "When must everything come together?"
        reason: "All planning works backward from this moment"

      2_classify_timing_sensitivity:
        rule: "Which tasks can wait? Which must be just-in-time?"
        categories:
          can_wait: "Prep work, setup, things that don't degrade"
          buffer_zone: "Can be early by 10-30%, stays warm"
          precise: "Must complete at exact moment"

      3_start_times_not_order:
        rule: "Calculate start times, not just sequence"
        formula: "start_time = convergence - duration - buffer"
        reason: "A 2-hour task starting now vs. 15-min task starting later"

      4_parallel_with_stagger:
        rule: "Start long-running tasks early, short tasks late"
        reason: "All finish at convergence point"

    anti_patterns:
      - "Starting everything at once (some finish too early)"
      - "Doing things in order of 'importance' (timing wrong)"
      - "Not accounting for different task durations"
      - "No buffer for precise-timing tasks"

    example:
      context: "Preparing dinner - main course, sides, sauce"
      convergence: "7:00 PM serving time"
      workstreams:
        roast: "90 min cook + 15 min rest â†’ start 5:15 PM"
        vegetables: "20 min cook â†’ start 6:40 PM"
        sauce: "30 min + can hold warm â†’ start 6:15 PM"
        table_setting: "10 min + no degradation â†’ start anytime"
        bread_warming: "5 min + degrades fast â†’ start 6:55 PM"
      order_by_start_time:
        1: "Table setting (anytime before 7 PM)"
        2: "Roast (5:15 PM - long duration)"
        3: "Sauce (6:15 PM - can buffer)"
        4: "Vegetables (6:40 PM - moderate timing)"
        5: "Bread warming (6:55 PM - precise timing)"
      rationale: "Everything ready at 7 PM, nothing cold or overcooked"

    source: "Culinary Arts - Mise en place, professional kitchen workflow"

  # ----------------------------------------
  # VARIATION 22: WEIGHTED-FAIRNESS ORDERING
  # ----------------------------------------
  weighted_fairness:
    id: weighted_fairness_ordering
    name: "Weighted-Fairness Ordering (WFQ)"
    category: fairness_allocation

    philosophy: |
      Balance priority with fairness; prevent starvation through
      weighted allocation. From network scheduling: pure priority
      can starve low-priority items forever. Weighted Fair Queuing
      gives each category a guaranteed share while still respecting
      relative importance.

    when_to_use:
      - Multiple stakeholders with different importance levels
      - Must prevent any category from being completely ignored
      - Long-running system where fairness matters over time
      - Want predictable allocation, not just best-effort

    key_concepts:
      weight: "Relative importance of each category (not absolute)"
      share: "Guaranteed portion of resources/attention"
      starvation: "When low-priority items never get served"
      aging: "Increasing priority of waiting items over time"

    prioritization_rules:
      1_assign_weights:
        rule: "Give each category a weight reflecting importance"
        example: "Critical:50%, Normal:35%, Low:15%"
        note: "Weights are relative, not absolute priority"

      2_allocate_proportionally:
        rule: "Allocate attention/resources proportional to weights"
        reason: "Everyone gets their fair share"
        example: "In 10 hours, Low gets at least 1.5 hours"

      3_round_robin_within_weights:
        rule: "Rotate within categories to prevent individual starvation"
        reason: "Even low-priority items eventually get served"

      4_burst_allowance:
        rule: "Allow temporary imbalance but rebalance over time"
        reason: "Short-term urgency shouldn't starve others long-term"

    anti_patterns:
      - "Pure priority (low-priority never served)"
      - "Equal treatment (ignores legitimate differences)"
      - "No guaranteed minimum (some categories starved)"
      - "Never rebalancing (accumulated unfairness)"

    example:
      context: "Managing support tickets from different customer tiers"
      weights:
        enterprise: "50% of attention"
        professional: "35% of attention"
        free_tier: "15% of attention"
      in_practice:
        - "Don't do 5 enterprise tickets then move on"
        - "After each enterprise, consider: is pro/free share met?"
        - "If free tier backlog grows, allocate time even if enterprise waiting"
        - "Track over time: is each tier getting its share?"
      rationale: "Enterprise gets more, but free users aren't ignored"

    source: "Network Scheduling - Weighted Fair Queuing (WFQ)"

  # ----------------------------------------
  # VARIATION 23: OPTION-PRESERVING ORDERING
  # ----------------------------------------
  option_preserving:
    id: option_preserving_ordering
    name: "Option-Preserving Ordering (Real Options)"
    category: risk_management

    philosophy: |
      Delay decisions that close options; preserve flexibility for
      as long as it's valuable. From real options theory: options
      have value. An irreversible decision made today forecloses
      futures that might be better. Defer commitment until the
      value of deciding exceeds the value of waiting.

    different_from_reversibility: |
      Reversibility asks: "Can I undo this?"
      Option-preserving asks: "What futures am I foreclosing?"
      A reversible action might still close valuable options.
      An irreversible action might be fine if no valuable options lost.

    when_to_use:
      - High uncertainty about future states
      - Options have value that increases with information
      - Some paths foreclose others permanently
      - Cost of waiting is lower than value of optionality

    key_concepts:
      option_value: "Value of being able to choose later"
      exercise_decision: "When to commit vs. keep waiting"
      foreclosure: "Paths that become impossible after a decision"
      information_arrival: "New info that changes optimal choice"

    prioritization_rules:
      1_identify_foreclosures:
        rule: "What options does each action close?"
        questions:
          - "After this, what becomes impossible?"
          - "What futures am I giving up?"
          - "Is this one-way or two-way door?"

      2_value_remaining_options:
        rule: "Estimate value of keeping options open"
        factors:
          - "Uncertainty remaining"
          - "Time until more information arrives"
          - "Cost of being wrong if decided now"

      3_compare_to_waiting_cost:
        rule: "Decide when option value < waiting cost"
        formula: "Commit when: value_of_deciding > value_of_waiting"
        reason: "Sometimes you must decide despite uncertainty"

      4_order_by_option_preservation:
        rule: "Do option-preserving actions before option-closing"
        reason: "Maintain flexibility as long as valuable"

    anti_patterns:
      - "Committing early 'to be decisive' (premature foreclosure)"
      - "Waiting forever (analysis paralysis)"
      - "Ignoring foreclosed options"
      - "Treating all decisions as equally reversible"

    example:
      context: "Career decisions while exploring options"
      decisions:
        A: "Take generalist role (preserves many paths)"
        B: "Take specialist role (forecloses other specialties)"
        C: "Start PhD (forecloses industry for years)"
        D: "Take sabbatical (preserves all, costs time)"
      option_preserving_order:
        1: "A - Generalist role (explore while preserving options)"
        2: "D - Sabbatical (only if info will arrive)"
        defer: "B, C - Specialist/PhD (decide when uncertainty lower)"
      rationale: "Keep doors open until you know which to walk through"

    source: "Finance/Decision Theory - Real Options, Option Value"

  # ----------------------------------------
  # VARIATION 24: ENERGY-ENVELOPE ORDERING
  # ----------------------------------------
  energy_envelope:
    id: energy_envelope_ordering
    name: "Energy-Envelope Ordering (Setlist Pacing)"
    category: motivation_psychology

    philosophy: |
      Plan energy peaks and valleys; don't exhaust the audience
      or executor. From concert setlist design: sustained high
      energy leads to fatigue. Strategic valleys allow recovery
      for bigger peaks. The goal is maximum total engagement,
      not maximum instantaneous intensity.

    different_from_energy_aware: |
      Energy-aware matches task difficulty to available energy.
      Energy-envelope plans the shape of energy across time.
      Energy-aware is reactive; energy-envelope is proactive design.

    when_to_use:
      - Extended sessions (presentations, workshops, projects)
      - Audience or executor stamina is limited
      - Want to maximize engagement over time
      - Multiple phases with different intensity needs

    key_concepts:
      peak: "High-intensity moment requiring full attention"
      valley: "Lower-intensity recovery period"
      envelope: "The shape of energy across the session"
      climax: "The single highest peak (usually near end)"

    prioritization_rules:
      1_map_energy_requirements:
        rule: "Classify each item as peak, valley, or moderate"
        reason: "Know what you're working with"

      2_design_the_envelope:
        rule: "Plan the shape: opening, build, valleys, climax, close"
        patterns:
          gradual_build: "Start low, steadily increase to climax"
          u_shape: "High open, dip to middle, high close"
          wave: "Multiple peaks with valleys between"
          bookend: "Strong open and close, moderate middle"

      3_insert_valleys_strategically:
        rule: "Place recovery moments before and after peaks"
        reason: "Recovery enables higher peaks"
        guideline: "No more than 2-3 high-intensity items consecutively"

      4_save_best_for_climax:
        rule: "Position the biggest peak at ~75-85% of timeline"
        reason: "End strong, not exhausted"

    anti_patterns:
      - "All peaks, no valleys (exhaustion)"
      - "Climax too early (anticlimactic end)"
      - "Random energy levels (no coherent arc)"
      - "Ending on a valley (weak finish)"

    example:
      context: "Half-day workshop (4 hours)"
      energy_envelope:
        hour_1:
          - "Opening hook (peak - grab attention)"
          - "Context setting (moderate)"
          - "First exercise (moderate-high)"
        hour_2:
          - "Break (valley - recovery)"
          - "Core concept 1 (moderate)"
          - "Discussion (valley)"
        hour_3:
          - "Core concept 2 (moderate)"
          - "Challenging exercise (peak)"
          - "Debrief (valley - recovery)"
        hour_4:
          - "Advanced application (peak - climax)"
          - "Q&A (moderate)"
          - "Strong closing (moderate-high)"
      rationale: "Peaks at hours 1, 3, 4; valleys enable recovery"

    source: "Music/Performance - Concert setlist design, audience energy management"

  # ----------------------------------------
  # VARIATION 25: CONCESSION-PATTERNED ORDERING
  # ----------------------------------------
  concession_patterned:
    id: concession_patterned_ordering
    name: "Concession-Patterned Ordering"
    category: negotiation_strategy

    philosophy: |
      In negotiations or trade-offs, make small concessions first
      and bigger ones later. From negotiation theory: the pattern
      of concessions signals your limits. Early large concessions
      suggest weakness and invite more demands. Small concessions
      that decrease over time signal approaching your limit.

    when_to_use:
      - Negotiations with multiple issues
      - Trade-offs where you're giving up something
      - Persuasion that requires incremental agreement
      - Any back-and-forth exchange of value

    key_concepts:
      anchor: "Your opening position (ambitious but credible)"
      concession: "Movement from your position toward theirs"
      pattern: "The shape of concessions over time"
      limit: "Your true walk-away point (keep hidden)"

    prioritization_rules:
      1_anchor_first:
        rule: "Establish ambitious opening position"
        reason: "Anchors pull the final outcome toward you"
        note: "Make it precise, not round (signals knowledge)"

      2_small_concessions_early:
        rule: "Start with small movements from anchor"
        reason: "Shows flexibility without signaling weakness"
        pattern: "First concession < second < third..."

      3_decreasing_increments:
        rule: "Each concession should be smaller than the last"
        reason: "Signals approaching limit"
        example: "Concede $100, then $50, then $25, then $10..."

      4_reciprocity:
        rule: "Only concede in response to their concession"
        reason: "Unilateral concessions invite more demands"

      5_save_big_concession:
        rule: "Reserve one significant concession for closing"
        reason: "Creates feeling of 'final deal'"

    anti_patterns:
      - "Large first concession (signals weakness)"
      - "Increasing concessions (invites more demands)"
      - "Unilateral concessions (no reciprocity)"
      - "Giving best offer first (no room to move)"

    example:
      context: "Salary negotiation"
      pattern:
        anchor: "Request $150K (ambitious but justified)"
        concession_1: "OK, $145K (small: $5K)"
        concession_2: "I could do $142K (smaller: $3K)"
        concession_3: "My absolute minimum is $140K (smallest: $2K)"
        final: "Include signing bonus and I'll accept $140K"
      what_not_to_do:
        - "Start at $140K (no room to move)"
        - "Drop from $150K to $130K immediately"
        - "Keep conceding without their movement"
      rationale: "Decreasing concessions signal approaching limit"

    source: "Negotiation Theory - Concession patterns, anchoring"

  # ----------------------------------------
  # VARIATION 26: PREREQUISITE-CHAIN ORDERING
  # ----------------------------------------
  prerequisite_chain:
    id: prerequisite_chain_ordering
    name: "Prerequisite-Chain Ordering (Bloom's Taxonomy)"
    category: progressive_building

    philosophy: |
      Lower-level knowledge before higher-level application. From
      educational psychology (Bloom's Taxonomy): you can't analyze
      before you understand, can't create before you can apply.
      Skills build hierarchically; skipping levels creates gaps
      that undermine everything built on top.

    when_to_use:
      - Training or education sequences
      - Skill building with hierarchical dependencies
      - Knowledge that builds on prior knowledge
      - When gaps in foundation cause later failures

    blooms_hierarchy:
      1_remember: "Recall facts and basic concepts"
      2_understand: "Explain ideas, interpret meaning"
      3_apply: "Use information in new situations"
      4_analyze: "Draw connections, identify patterns"
      5_evaluate: "Justify decisions, make judgments"
      6_create: "Produce new work, design solutions"

    prioritization_rules:
      1_identify_level:
        rule: "What cognitive level does each task require?"
        reason: "Higher levels depend on lower levels"

      2_prerequisite_first:
        rule: "Complete lower-level prerequisites before higher"
        reason: "Can't analyze what you don't understand"
        sequence: "Remember â†’ Understand â†’ Apply â†’ Analyze â†’ Evaluate â†’ Create"

      3_verify_foundation:
        rule: "Check mastery before advancing"
        reason: "Gaps propagate upward"
        test: "Can they perform at N before attempting N+1?"

      4_scaffold_transitions:
        rule: "Provide support when moving up levels"
        reason: "Each level is qualitatively different"

    anti_patterns:
      - "Jumping to creation without foundations"
      - "Assuming understanding from exposure"
      - "Skipping 'boring' lower levels"
      - "Testing at higher level than taught"

    example:
      context: "Learning a new programming language"
      prerequisite_chain:
        remember: "Syntax rules, keywords, operators"
        understand: "What each construct does and why"
        apply: "Write simple programs using constructs"
        analyze: "Debug code, trace execution, identify patterns"
        evaluate: "Compare approaches, assess code quality"
        create: "Design and build novel applications"
      wrong_approach:
        - "Start with 'build a full app' (level 6)"
        - "Skip syntax drills as 'boring' (level 1)"
        - "Jump to debugging without understanding (level 4 without 2)"
      rationale: "Each level requires mastery of previous levels"

    source: "Educational Psychology - Bloom's Taxonomy, learning progression"

  # ----------------------------------------
  # VARIATION 27: DEFENSE-IN-DEPTH ORDERING
  # ----------------------------------------
  defense_in_depth:
    id: defense_in_depth_ordering
    name: "Defense-in-Depth Ordering (Swiss Cheese)"
    category: risk_management

    philosophy: |
      Layer defenses so no single failure causes catastrophe.
      From safety engineering (Swiss Cheese Model): every defense
      has holes. Stack multiple independent defenses so a threat
      must pass through all holes simultaneously to cause harm.
      Order matters: outer defenses catch most, inner catch rest.

    when_to_use:
      - Safety-critical systems
      - Security implementations
      - Quality assurance processes
      - Any context where failure is costly
      - Risk mitigation strategies

    key_concepts:
      defense_layer: "One mechanism that can stop a threat"
      hole: "Weakness or failure mode in a defense"
      independence: "Defenses fail for different reasons"
      alignment: "When holes line up, threat passes through"

    prioritization_rules:
      1_identify_threats:
        rule: "What are you defending against?"
        reason: "Defenses must address actual threats"

      2_layer_from_outer_to_inner:
        rule: "Broad defenses first, specific defenses later"
        pattern:
          outer: "Catch most common threats cheaply"
          middle: "Catch threats that passed outer layer"
          inner: "Catch rare threats that passed all outer"

      3_ensure_independence:
        rule: "Each layer should fail for different reasons"
        reason: "Correlated failures = useless redundancy"
        test: "If layer N fails, does it cause layer N+1 to fail?"

      4_dont_over_layer:
        rule: "More layers isn't always better"
        reason: "Complexity can introduce new failure modes"
        guideline: "Enough layers that aligned holes are rare"

    anti_patterns:
      - "Single point of failure (no redundancy)"
      - "Correlated defenses (fail together)"
      - "So many layers that system is brittle"
      - "Assuming one perfect defense is enough"

    example:
      context: "Preventing production deployment failures"
      defense_layers:
        layer_1_outer: "Code review (catches obvious errors)"
        layer_2: "Automated tests (catches logic errors)"
        layer_3: "Staging environment (catches integration errors)"
        layer_4: "Canary deployment (catches production-only errors)"
        layer_5_inner: "Rollback capability (catches everything else)"
      independence_check:
        - "Review and tests catch different things"
        - "Staging and production differ, so some pass staging"
        - "Canary and rollback are last-resort defenses"
      rationale: "Failure must pass all 5 layers to cause outage"

    source: "Safety Engineering - Swiss Cheese Model, Defense in Depth"

  # ----------------------------------------
  # VARIATION 28: BISECTION-DEBUGGING ORDERING
  # ----------------------------------------
  bisection_debugging:
    id: bisection_debugging_ordering
    name: "Bisection-Debugging Ordering (Binary Search)"
    category: queue_scheduling

    philosophy: |
      Systematically halve the search space to find problems fast.
      From debugging (git bisect, binary search): when you don't
      know where a bug is, don't check linearly. Split the space
      in half, determine which half contains the problem, repeat.
      O(log n) instead of O(n) for finding issues.

    when_to_use:
      - Root cause unknown among many possibilities
      - Linear search would be too slow
      - Problem is deterministic and reproducible
      - Can test "is the problem in this half?"

    key_concepts:
      search_space: "All possible locations of the problem"
      bisection: "Dividing search space in half"
      invariant: "Property that identifies which half has problem"
      convergence: "Each step halves remaining space"

    prioritization_rules:
      1_define_bounds:
        rule: "Identify the full search space"
        examples:
          - "Code: known working commit to broken commit"
          - "Pipeline: input to output"
          - "Config: list of all settings"

      2_midpoint_test:
        rule: "Test at the midpoint of current range"
        reason: "Maximizes information gain per test"

      3_halve_and_repeat:
        rule: "Eliminate half based on test result"
        pattern: "If problem in first half, discard second half"

      4_continue_until_converged:
        rule: "Stop when search space is one item"
        formula: "log2(n) tests to find among n items"

    anti_patterns:
      - "Linear search from start (O(n) vs O(log n))"
      - "Random jumping without tracking bounds"
      - "Not defining clear pass/fail criteria"
      - "Using when problem is intermittent"

    example:
      context: "Finding which of 1024 commits introduced a bug"
      bisection_approach:
        test_1: "Test commit 512 â†’ bug present â†’ problem in 1-512"
        test_2: "Test commit 256 â†’ bug absent â†’ problem in 257-512"
        test_3: "Test commit 384 â†’ bug present â†’ problem in 257-384"
        test_4: "Test commit 320 â†’ bug absent â†’ problem in 321-384"
        "...": "Continue until single commit identified"
      total_tests: "10 tests (log2(1024)) vs 1024 linear tests"
      rationale: "Each test eliminates half of possibilities"

    source: "Computer Science - Binary Search, Git Bisect"

  # ----------------------------------------
  # VARIATION 29: INVERTED-PYRAMID ORDERING
  # ----------------------------------------
  inverted_pyramid:
    id: inverted_pyramid_ordering
    name: "Inverted-Pyramid Ordering"
    category: communication_narrative

    philosophy: |
      Most important information first; details in descending order.
      From journalism: readers may stop at any point, so front-load
      the essential content. The "lede" contains who/what/when/where/why.
      Supporting details follow, with least important at the end.
      Content can be cut from the bottom without losing the core.

    when_to_use:
      - Readers/consumers may not finish
      - Content may be truncated
      - Time-constrained communication
      - Executive summaries
      - Status updates and reports

    key_concepts:
      lede: "The opening with most essential information"
      five_ws: "Who, what, when, where, why (and how)"
      supporting: "Details that enhance but aren't essential"
      cut_from_bottom: "Can remove end without losing core message"

    prioritization_rules:
      1_identify_core:
        rule: "What must the reader absolutely know?"
        test: "If they read only one sentence, what should it be?"

      2_front_load_essentials:
        rule: "Put the 5 Ws in the first paragraph"
        reason: "Reader gets complete picture immediately"

      3_descending_importance:
        rule: "Each subsequent section is less essential"
        pattern: "Core â†’ important â†’ useful â†’ nice-to-have"

      4_self_contained_sections:
        rule: "Each section should make sense even if later cut"
        reason: "Graceful degradation as content is truncated"

    anti_patterns:
      - "Burying the lede (important info hidden)"
      - "Building suspense (not appropriate here)"
      - "Requiring full read for comprehension"
      - "Putting key points at the end"

    different_from_tension_arc: |
      Tension arc builds to climax at 75% for engagement.
      Inverted pyramid front-loads for interruptible consumption.
      Use tension arc for captive audiences, inverted pyramid for scanners.

    example:
      context: "Status update email"
      inverted_pyramid_order:
        lede: "Project X shipped yesterday, 2 days early, all tests passing."
        supporting_1: "Key features: user auth, dashboard, API v2."
        supporting_2: "Team: Alice (lead), Bob, Carol contributed."
        background: "This completes Q4 roadmap item #3."
        detail: "Detailed changelog attached."
      if_truncated:
        first_line_only: "Reader knows: shipped, early, successful"
        first_two: "Reader also knows: what features"
      rationale: "Complete understanding at every break point"

    source: "Journalism - Inverted Pyramid, News Writing"

  # ----------------------------------------
  # VARIATION 30: URGENCY-IMPORTANCE ORDERING
  # ----------------------------------------
  urgency_importance:
    id: urgency_importance_ordering
    name: "Urgency-Importance Ordering (Eisenhower Matrix)"
    category: priority_frameworks

    philosophy: |
      Separate urgency from importance; prioritize accordingly.
      From Eisenhower: "The urgent are not important, and the
      important are never urgent." Urgent tasks demand immediate
      attention but may not matter long-term. Important tasks
      build toward goals but often lack deadlines.

    when_to_use:
      - Overwhelmed with mixed priorities
      - Urgency is crowding out importance
      - Need to distinguish fires from foundations
      - Time management and delegation decisions

    quadrants:
      q1_do_first:
        criteria: "Urgent AND Important"
        action: "Do immediately"
        examples: "Crises, deadlines, emergencies"

      q2_schedule:
        criteria: "Important but NOT Urgent"
        action: "Schedule dedicated time"
        examples: "Strategy, learning, relationships, prevention"
        key_insight: "This quadrant determines long-term success"

      q3_delegate:
        criteria: "Urgent but NOT Important"
        action: "Delegate or minimize"
        examples: "Interruptions, some meetings, others' priorities"

      q4_eliminate:
        criteria: "Neither Urgent nor Important"
        action: "Eliminate or severely limit"
        examples: "Time wasters, trivial tasks, distractions"

    prioritization_rules:
      1_classify_all_tasks:
        rule: "Place each task in one of four quadrants"
        questions:
          urgent: "Does this have a deadline or consequence if delayed?"
          important: "Does this contribute to my goals/values?"

      2_protect_q2:
        rule: "Schedule Q2 time before Q3 floods your calendar"
        reason: "Q2 is where growth happens"
        trap: "Q3 feels urgent but crowds out Q2"

      3_urgency_trap_awareness:
        rule: "Question whether 'urgent' is truly urgent"
        reason: "Others' urgency isn't your importance"

      4_batch_q3_q4:
        rule: "Handle low-importance items in batches, not as interrupts"
        reason: "Protect focus for Q1 and Q2"

    anti_patterns:
      - "Living in Q1 (always firefighting)"
      - "Q3 crowding out Q2 (busy but not productive)"
      - "Confusing urgent with important"
      - "No dedicated Q2 time (important never done)"

    example:
      context: "Weekly task prioritization"
      tasks_classified:
        Q1_do_first:
          - "Client demo tomorrow (urgent + important)"
          - "Production bug affecting users (urgent + important)"
        Q2_schedule:
          - "Write technical documentation (important, no deadline)"
          - "Learn new framework (important for growth)"
          - "1:1 with mentee (important relationship)"
        Q3_delegate:
          - "Respond to non-urgent emails (urgent feel, low importance)"
          - "Attend optional meeting (someone else's priority)"
        Q4_eliminate:
          - "Reorganize desk (neither urgent nor important)"
          - "Social media browsing (distraction)"
      order: "Q1 â†’ Q2 (scheduled blocks) â†’ Q3 (batched) â†’ Q4 (eliminated)"
      rationale: "Protect Q2 time or it never happens"

    source: "Time Management - Eisenhower Matrix, Stephen Covey"

  # ----------------------------------------
  # VARIATION 31: OUTSIDE-IN ORDERING
  # ----------------------------------------
  outside_in:
    id: outside_in_ordering
    name: "Outside-In Ordering (API-First)"
    category: architecture_design

    philosophy: |
      Start from boundaries and interfaces, work inward to core.
      From software design (API-first, contract-driven): define
      how the system interacts with the outside world before
      implementing internals. Ensures the interface meets user
      needs; implementation details follow the contract.

    when_to_use:
      - Building systems with external consumers
      - Contract or interface must be stable
      - Multiple teams need to integrate
      - User experience drives technical decisions
      - Testing from user perspective (BDD/acceptance tests)

    key_concepts:
      boundary: "Where your system meets the outside world"
      contract: "The interface specification"
      consumer_driven: "Interface shaped by consumer needs"
      implementation_hidden: "Internals can change if contract stable"

    prioritization_rules:
      1_identify_boundaries:
        rule: "Where does your system touch the outside?"
        examples:
          - "APIs (REST, GraphQL, gRPC)"
          - "User interfaces"
          - "Database schemas"
          - "Message contracts"

      2_define_contracts_first:
        rule: "Specify the interface before implementation"
        reason: "Consumers can start integrating immediately"
        artifacts: "OpenAPI spec, Proto files, UI mockups"

      3_acceptance_before_unit:
        rule: "Write acceptance tests before unit tests"
        reason: "Verify system works from outside before inside"

      4_implement_inward:
        rule: "Build from boundaries toward core"
        pattern: "Controllers â†’ Services â†’ Domain â†’ Infrastructure"

    anti_patterns:
      - "Building core first, retrofitting API"
      - "Implementation leaking into interface"
      - "Changing contracts frequently"
      - "Testing only internals"

    different_from_inside_out: |
      Outside-in: User needs drive implementation.
      Inside-out: Core domain logic drives interface.
      Outside-in is better for integrations; inside-out for complex domains.

    example:
      context: "Building a payment processing service"
      outside_in_order:
        1_boundaries: "Define API contract (OpenAPI spec)"
        2_acceptance: "Write acceptance tests for key flows"
        3_controllers: "Implement API endpoints (empty handlers)"
        4_services: "Build service layer behind controllers"
        5_domain: "Implement core payment logic"
        6_infrastructure: "Add database, external API integrations"
      benefit: "Frontend team can mock API and build in parallel"
      rationale: "Contract stability enables parallel development"

    source: "Software Design - API-First, Contract-Driven Development, BDD"

  # ----------------------------------------
  # VARIATION 32: INSIDE-OUT ORDERING
  # ----------------------------------------
  inside_out:
    id: inside_out_ordering
    name: "Inside-Out Ordering (Domain-First)"
    category: architecture_design

    philosophy: |
      Start from the core domain logic, work outward to boundaries.
      From Domain-Driven Design: the domain model is the heart of
      the system. Get the core concepts and rules right first;
      interfaces and infrastructure are just delivery mechanisms
      for the domain.

    when_to_use:
      - Complex business rules that must be correct
      - Domain expertise is the differentiator
      - Core logic is more stable than interfaces
      - Building for correctness over integration speed
      - When you don't yet know how it will be consumed

    key_concepts:
      domain: "Core business concepts and rules"
      pure_logic: "Business rules independent of I/O"
      hexagonal: "Domain at center, ports/adapters at edges"
      bounded_context: "Logical boundary around a domain model"

    prioritization_rules:
      1_model_domain_first:
        rule: "Understand and model the core business concepts"
        reason: "This is the hard, differentiating work"

      2_pure_before_impure:
        rule: "Implement pure business logic before I/O"
        reason: "Pure code is easier to test and reason about"

      3_defer_infrastructure:
        rule: "Delay database, API, UI decisions"
        reason: "These are implementation details"
        quote: "Make the domain code work, then make it real"

      4_grow_outward:
        rule: "Add interfaces as needed to expose domain"
        pattern: "Domain â†’ Application Services â†’ Adapters â†’ UI/API"

    anti_patterns:
      - "Starting with database schema"
      - "Letting UI drive domain model"
      - "Infrastructure concerns in domain logic"
      - "Not having a clear domain boundary"

    example:
      context: "Building an insurance claims system"
      inside_out_order:
        1_domain_model: "Model Claim, Policy, Coverage, Adjudication rules"
        2_domain_services: "Implement claims processing logic (pure)"
        3_application_services: "Orchestrate domain operations"
        4_repositories: "Add persistence for domain objects"
        5_api: "Expose claims API for consumers"
        6_ui: "Build claims management interface"
      benefit: "Domain rules are correct and testable in isolation"
      rationale: "Core correctness is more valuable than fast integration"

    source: "Software Design - Domain-Driven Design, Hexagonal Architecture"

  # ----------------------------------------
  # VARIATION 33: BATCH-VS-STREAM ORDERING
  # ----------------------------------------
  batch_vs_stream:
    id: batch_vs_stream_ordering
    name: "Batch-vs-Stream Ordering"
    category: resource_optimization

    philosophy: |
      Choose between grouping similar work (batch) or processing
      as items arrive (stream). From manufacturing and data:
      batching reduces setup/context-switch costs but increases
      latency. Streaming reduces latency but increases switching.
      The right choice depends on setup cost vs. latency requirements.

    when_to_use:
      - Deciding between context-switching and batching
      - Processing queues of work items
      - Email, notifications, or review workflows
      - Any work with setup costs

    key_concepts:
      setup_cost: "Time/effort to switch contexts"
      batch: "Group similar items, process together"
      stream: "Process each item as it arrives"
      latency: "Time from arrival to completion"
      throughput: "Items completed per unit time"

    trade_offs:
      batching:
        pros:
          - "Lower total setup time (one setup, many items)"
          - "Higher throughput for similar items"
          - "Deeper focus without switching"
        cons:
          - "Higher latency (items wait for batch)"
          - "Earlier items wait for later ones"
          - "Requires holding items"

      streaming:
        pros:
          - "Lower latency (process immediately)"
          - "Fairness (FIFO order)"
          - "No queue buildup"
        cons:
          - "Higher total setup time (setup per item)"
          - "More context switching"
          - "Lower throughput for diverse items"

    prioritization_rules:
      1_assess_setup_cost:
        rule: "How expensive is switching contexts?"
        high_setup: "Favor batching"
        low_setup: "Streaming is viable"

      2_assess_latency_requirement:
        rule: "How quickly must items be processed?"
        low_latency_required: "Favor streaming"
        latency_tolerant: "Batching acceptable"

      3_optimal_batch_size:
        rule: "Batch size = sqrt(2 Ã— demand Ã— setup_cost / holding_cost)"
        reason: "Economic Order Quantity formula"
        practical: "Start with 5-10 items, adjust based on results"

      4_hybrid_approach:
        rule: "Time-boxed batches combine benefits"
        pattern: "Process batch OR after N minutes, whichever first"

    anti_patterns:
      - "Always streaming when setup is high (constant switching)"
      - "Always batching when latency matters (items waiting)"
      - "Infinite batch size (items wait forever)"
      - "Not considering the trade-off explicitly"

    example:
      context: "Processing code review requests"
      analysis:
        setup_cost: "~10 min to load context for new codebase"
        latency_requirement: "Reviews needed within 24 hours"
        items_per_day: "~20 reviews across 5 codebases"
      decision: "Batch by codebase, process batches twice daily"
      batched_order:
        morning: "All reviews for codebase A, then B, then C"
        afternoon: "All reviews for codebase D, then E"
      rationale: "5 context switches vs 20; latency still < 24 hours"

    source: "Manufacturing - Economic Order Quantity, Data Processing - Batch vs Stream"

  # ----------------------------------------
  # VARIATION 34: BUILD-MEASURE-LEARN ORDERING
  # ----------------------------------------
  build_measure_learn:
    id: build_measure_learn_ordering
    name: "Build-Measure-Learn Ordering (Lean Startup)"
    category: learning_discovery

    philosophy: |
      Iterate through build â†’ measure â†’ learn cycles as fast as
      possible. From Lean Startup: the goal isn't to build the
      perfect product, it's to learn what customers want. Build
      the minimum viable product (MVP), measure real behavior,
      learn whether to pivot or persevere. Speed through the loop
      matters more than perfection at any step.

    when_to_use:
      - High uncertainty about what to build
      - Need to validate assumptions with real users
      - Resources are limited (can't build everything)
      - Market feedback is available
      - Willing to pivot based on learning

    key_concepts:
      mvp: "Minimum Viable Product - smallest thing that enables learning"
      validated_learning: "Learning backed by real data, not opinions"
      pivot: "Change direction based on learning"
      persevere: "Continue current direction, iterate"
      cycle_time: "Time to complete one build-measure-learn loop"

    prioritization_rules:
      1_identify_riskiest_assumption:
        rule: "What assumption, if wrong, kills the project?"
        reason: "Test this first"
        examples:
          - "Will customers pay for this?"
          - "Can we build this technically?"
          - "Will users actually use this feature?"

      2_build_minimum_to_learn:
        rule: "Build only what's needed to test the assumption"
        anti_pattern: "Building the full product before any feedback"
        mvp_types:
          - "Landing page (test demand)"
          - "Concierge (manual before automated)"
          - "Wizard of Oz (fake the backend)"
          - "Prototype (test usability)"

      3_measure_real_behavior:
        rule: "Collect data on actual user behavior, not opinions"
        reason: "What people say â‰  what people do"
        metrics: "Signup rates, usage, retention, willingness to pay"

      4_learn_and_decide:
        rule: "Analyze data, decide: pivot or persevere"
        pivot_signals:
          - "Hypothesis invalidated by data"
          - "Better opportunity discovered"
          - "Current path not working"
        persevere_signals:
          - "Hypothesis validated"
          - "Metrics trending positive"
          - "Clear path to improvement"

      5_minimize_cycle_time:
        rule: "Speed through the loop is critical"
        reason: "More cycles = more learning = better product"

    anti_patterns:
      - "Building for months without user feedback"
      - "Measuring vanity metrics (likes, pageviews)"
      - "Learning but never pivoting when needed"
      - "Pivoting too often (no persistence)"

    example:
      context: "Testing a new SaaS product idea"
      build_measure_learn_cycles:
        cycle_1:
          assumption: "People have this problem"
          build: "Landing page describing the problem"
          measure: "Email signups, bounce rate"
          learn: "500 signups in 1 week â†’ problem validated"
        cycle_2:
          assumption: "Our solution approach works"
          build: "Clickable prototype"
          measure: "User testing sessions"
          learn: "Users confused by workflow â†’ pivot approach"
        cycle_3:
          assumption: "Simplified approach works"
          build: "Working MVP with core feature"
          measure: "Actual usage, retention"
          learn: "40% weekly retention â†’ persevere, iterate"
      rationale: "3 cycles of learning before significant investment"

    source: "Lean Startup - Eric Ries, Build-Measure-Learn loop"

  # ----------------------------------------
  # VARIATION 35: PROPORTIONAL-CONFIDENCE ORDERING
  # ----------------------------------------
  proportional_confidence:
    id: proportional_confidence_ordering
    name: "Proportional-Confidence Ordering (Kelly-Inspired)"
    category: fairness_allocation

    philosophy: |
      Commit resources proportional to your confidence/edge. From
      Kelly Criterion in betting: bet more when you have higher
      edge, less when uncertain. Never bet everything. Applied to
      work: invest more effort in high-confidence items, less in
      speculative ones. Diversify across confidence levels.

    when_to_use:
      - Allocating resources across uncertain options
      - Portfolio of projects with varying confidence
      - Investment decisions (time, money, attention)
      - When you have estimates of probability/payoff

    key_concepts:
      edge: "Your advantage or confidence level"
      kelly_fraction: "Optimal bet size given edge"
      fractional_kelly: "Conservative fraction (Â½ or â…“) for safety"
      ruin: "Risk of losing everything"
      expected_value: "Probability Ã— payoff"

    prioritization_rules:
      1_estimate_confidence:
        rule: "How confident are you this will succeed?"
        scale: "0-100% probability of success"
        honesty: "Be realistic, not optimistic"

      2_estimate_payoff:
        rule: "What's the upside if it succeeds?"
        include: "Both magnitude and strategic value"

      3_calculate_expected_value:
        rule: "EV = probability Ã— payoff - (1-probability) Ã— cost"
        use_for: "Comparing across options"

      4_size_proportionally:
        rule: "Higher EV/confidence â†’ more resources"
        formula: "Allocation âˆ edge (but never 100%)"
        fractional: "Use Â½ or â…“ of 'optimal' for safety margin"

      5_diversify:
        rule: "Don't put all resources on one bet"
        reason: "Even high-confidence bets fail sometimes"

    anti_patterns:
      - "All-in on single high-confidence bet"
      - "Equal allocation regardless of confidence"
      - "Ignoring low-confidence but high-payoff options"
      - "Overconfidence in estimates"

    example:
      context: "Allocating engineering time across 4 projects"
      projects:
        A: "Core feature - 80% confidence, 2x payoff"
        B: "Experiment - 30% confidence, 10x payoff"
        C: "Tech debt - 95% confidence, 1.2x payoff"
        D: "Moonshot - 10% confidence, 50x payoff"
      expected_values:
        A: "0.8 Ã— 2 = 1.6"
        B: "0.3 Ã— 10 = 3.0"
        C: "0.95 Ã— 1.2 = 1.14"
        D: "0.1 Ã— 50 = 5.0"
      proportional_allocation:
        D: "40% (highest EV despite low confidence)"
        B: "30% (high EV)"
        A: "20% (solid EV)"
        C: "10% (low EV, do minimum)"
      rationale: "Bet sizes reflect expected value, not just confidence"

    source: "Finance - Kelly Criterion, Position Sizing"

  # ----------------------------------------
  # VARIATION 36: INFORMATION-POSITION ORDERING
  # ----------------------------------------
  information_position:
    id: information_position_ordering
    name: "Information-Position Ordering (Act Last)"
    category: negotiation_strategy

    philosophy: |
      When possible, act later to gain information advantage.
      From poker: players in late position see others act first,
      gaining valuable information before deciding. In any
      sequential decision, acting later lets you observe and
      adapt. Trade off: sometimes early action has advantages.

    when_to_use:
      - Sequential decision-making with multiple actors
      - Information revealed by others' actions
      - Flexibility to change based on observations
      - When being reactive is advantageous

    when_not_to_use:
      - First-mover advantage exists (see commitment_first)
      - Delay has significant costs
      - Information won't be revealed by waiting

    key_concepts:
      position: "Order in the decision sequence"
      information_asymmetry: "Knowing more than others"
      observation: "Learning from others' actions"
      optionality: "Ability to adapt based on new info"

    prioritization_rules:
      1_assess_position_value:
        rule: "Will waiting reveal useful information?"
        questions:
          - "What will I learn from others' actions?"
          - "Can I use that information?"
          - "Is the information worth the wait?"

      2_defer_when_beneficial:
        rule: "Move later in sequence when information helps"
        examples:
          - "Let others bid first in auction"
          - "Speak later in meeting after hearing others"
          - "Make decision after seeing more data"

      3_act_early_when_advantageous:
        rule: "Sometimes first-mover advantage trumps information"
        cases:
          - "Commitment creates leverage"
          - "Resources are limited (first-come)"
          - "Anchoring benefits from moving first"

      4_create_information_asymmetry:
        rule: "Get information others don't have"
        methods:
          - "Ask questions before committing"
          - "Observe before acting"
          - "Research before deciding"

    anti_patterns:
      - "Always acting first (miss information)"
      - "Always waiting (miss opportunities)"
      - "Not using the information gained"
      - "Telegraphing your intent before acting"

    example:
      context: "Salary negotiation"
      information_position_approach:
        early_actions:
          - "Research market rates (get information)"
          - "Ask about budget range (let them anchor first if possible)"
          - "Understand their constraints"
        defer_until_informed:
          - "Don't name your number first if possible"
          - "Let them reveal their range"
          - "Observe their reactions to your questions"
        then_act:
          - "Make informed counteroffer"
          - "Use gathered information in negotiation"
      exception: "If they insist you go first, anchor high (commitment_first)"
      rationale: "Information advantage enables better decisions"

    source: "Poker Strategy - Position, Game Theory - Information Asymmetry"

  # ----------------------------------------
  # VARIATION 37: VITAL-FEW-FIRST ORDERING
  # ----------------------------------------
  vital_few_first:
    id: vital_few_first_ordering
    name: "Vital-Few-First Ordering (Pareto)"
    category: resource_optimization

    philosophy: |
      Focus on the 20% that drives 80% of results first. From
      Pareto Principle: in most situations, a small number of
      causes drive most of the outcomes. Identify the "vital few"
      and prioritize them over the "useful many." Don't let the
      trivial crowd out the critical.

    when_to_use:
      - Limited time/resources, must prioritize ruthlessly
      - Outcomes follow power-law distribution
      - Need to maximize impact with constrained input
      - Analysis shows uneven distribution of value

    key_concepts:
      vital_few: "The ~20% of inputs causing ~80% of outputs"
      useful_many: "The ~80% of inputs causing ~20% of outputs"
      power_law: "Uneven distribution where few items dominate"
      leverage: "Impact per unit of effort"

    prioritization_rules:
      1_identify_distribution:
        rule: "Analyze what's driving results"
        questions:
          - "Which 20% of customers drive 80% of revenue?"
          - "Which 20% of bugs cause 80% of crashes?"
          - "Which 20% of features get 80% of usage?"

      2_rank_by_impact:
        rule: "Order items by impact, not by ease or recency"
        reason: "High-impact items first"
        method: "Impact score = value delivered / effort required"

      3_focus_on_vital_few:
        rule: "Complete vital few before touching useful many"
        trap: "Doing easy low-impact tasks for quick wins"
        discipline: "Resist urge to clear small items first"

      4_dont_neglect_useful_many_entirely:
        rule: "The 'useful many' still matter, just later"
        reason: "80% of items still contribute 20% of value"
        approach: "Batch useful-many items, time-box them"

    anti_patterns:
      - "Treating all tasks as equally important"
      - "Doing easy tasks first (feels productive, isn't)"
      - "Ignoring the vital few because they're hard"
      - "Over-focusing on vital few, neglecting everything else"

    example:
      context: "Improving product quality"
      analysis:
        bugs_by_impact:
          top_5_bugs: "Cause 78% of user complaints"
          next_20_bugs: "Cause 15% of user complaints"
          remaining_50_bugs: "Cause 7% of user complaints"
      vital_few_first_order:
        1: "Fix top 5 bugs (78% impact reduction)"
        2: "Fix next 20 bugs (15% more)"
        3: "Batch remaining 50 (7% more)"
      comparison:
        fifo_approach: "Fix bugs in order reported â†’ random impact"
        vital_few: "Fix by impact â†’ 78% improvement from first 5 fixes"
      rationale: "5 fixes achieve what would take 75 with random order"

    source: "Quality Management - Pareto Principle, Juran's Vital Few"

# ============================================
# COMPUTER SCIENCE ALGORITHM ORDERINGS
# ============================================
# These variations are directly derived from fundamental
# CS algorithms and data structures.

  # ----------------------------------------
  # VARIATION 38: TOPOLOGICAL-SORT ORDERING
  # ----------------------------------------
  topological_sort:
    id: topological_sort_ordering
    name: "Topological-Sort Ordering (Dependency DAG)"
    category: graph_traversal

    philosophy: |
      Process items only after all their dependencies are complete.
      From graph algorithms: topological sort produces a linear
      ordering of vertices in a DAG such that for every edge (u,v),
      u comes before v. Any valid topological order respects all
      dependencies. Multiple valid orderings may exist.

    when_to_use:
      - Tasks have explicit dependencies
      - Must respect prerequisite relationships
      - Building/compiling systems with dependencies
      - Course scheduling, package installation
      - Any DAG-structured workflow

    key_concepts:
      dag: "Directed Acyclic Graph - no cycles allowed"
      in_degree: "Number of incoming edges (dependencies)"
      zero_in_degree: "Ready to process (no unmet dependencies)"
      topological_order: "Any valid ordering respecting all edges"

    algorithms:
      kahns_algorithm:
        approach: "BFS-based, process zero in-degree first"
        steps:
          1: "Find all nodes with in-degree 0 (no dependencies)"
          2: "Process one, remove its outgoing edges"
          3: "Add newly zero in-degree nodes to queue"
          4: "Repeat until all processed"
        good_for: "Parallel execution, cycle detection"

      dfs_based:
        approach: "Post-order DFS, reverse the result"
        steps:
          1: "DFS from each unvisited node"
          2: "After visiting all neighbors, add to stack"
          3: "Pop stack for topological order"
        good_for: "Recursive elegance, memory efficiency"

    prioritization_rules:
      1_identify_dependencies:
        rule: "Map out what depends on what"
        output: "Directed graph of dependencies"

      2_find_ready_items:
        rule: "Items with no unmet dependencies are ready"
        formula: "in_degree(item) == 0"

      3_process_and_update:
        rule: "After completing item, update dependents"
        effect: "Reduces in-degree of downstream items"

      4_detect_cycles:
        rule: "If no zero in-degree items remain but work exists, cycle detected"
        response: "Circular dependency - cannot be resolved"

    anti_patterns:
      - "Ignoring dependencies (items fail)"
      - "Creating cycles (deadlock)"
      - "Processing items before dependencies ready"
      - "Not parallelizing independent items"

    example:
      context: "Building a software project"
      dependencies:
        A_utils: "No dependencies"
        B_config: "Depends on A"
        C_database: "Depends on A"
        D_api: "Depends on B, C"
        E_frontend: "Depends on D"
        F_tests: "Depends on D, E"
      topological_orders:
        valid_1: "A â†’ B â†’ C â†’ D â†’ E â†’ F"
        valid_2: "A â†’ C â†’ B â†’ D â†’ E â†’ F"
        parallel: "A, then [B, C] in parallel, then D, E, F"
      rationale: "Any order where dependencies come before dependents"

    source: "Graph Algorithms - Topological Sort, Kahn's Algorithm"

  # ----------------------------------------
  # VARIATION 39: BREADTH-FIRST ORDERING
  # ----------------------------------------
  breadth_first:
    id: breadth_first_ordering
    name: "Breadth-First Ordering (Level by Level)"
    category: graph_traversal

    philosophy: |
      Explore all options at current depth before going deeper.
      From BFS traversal: visit all neighbors before visiting
      neighbors' neighbors. Guarantees shortest path in unweighted
      graphs. Good when solution is likely close to starting point
      or when you need to explore uniformly.

    when_to_use:
      - Solution likely close to start (shallow)
      - Need shortest path (fewest steps)
      - Want to explore all options at each level
      - Wide, shallow problem spaces
      - Finding minimum number of operations

    key_concepts:
      queue: "FIFO data structure drives BFS"
      level: "All nodes at same distance from start"
      frontier: "Current level being explored"
      shortest_path: "BFS finds it in unweighted graphs"

    prioritization_rules:
      1_start_at_root:
        rule: "Begin with initial state/starting point"
        action: "Add to queue"

      2_process_level_completely:
        rule: "Explore all items at current level before next"
        mechanism: "FIFO queue ensures level-order"

      3_expand_frontier:
        rule: "For each item, add its children to queue"
        effect: "Next level gets queued after current"

      4_stop_when_found:
        rule: "First solution found is optimal (fewest steps)"
        reason: "BFS explores shortest paths first"

    comparison_to_dfs:
      bfs: "Wide then deep - finds shortest path"
      dfs: "Deep then wide - finds any path fast"
      memory: "BFS uses more memory (stores whole level)"
      when_bfs_wins: "Solution is shallow, need shortest path"
      when_dfs_wins: "Solution is deep, memory constrained"

    anti_patterns:
      - "Using BFS when solution is deep (wastes memory)"
      - "Not stopping when first solution found"
      - "Using when path length doesn't matter"
      - "Applying to very wide graphs (memory explosion)"

    example:
      context: "Finding shortest path through a maze"
      approach:
        start: "Entrance cell"
        level_1: "All cells 1 step from start"
        level_2: "All cells 2 steps from start"
        continue: "Until exit found"
      guarantee: "First path to exit is shortest"
      comparison:
        bfs: "Explores uniformly, guaranteed shortest"
        dfs: "Might find long path first"
      rationale: "When shortest path matters, BFS is optimal"

    source: "Graph Algorithms - Breadth-First Search"

  # ----------------------------------------
  # VARIATION 40: DEPTH-FIRST ORDERING
  # ----------------------------------------
  depth_first:
    id: depth_first_ordering
    name: "Depth-First Ordering (Go Deep First)"
    category: graph_traversal

    philosophy: |
      Explore one path completely before trying alternatives.
      From DFS traversal: go as deep as possible down one branch
      before backtracking. Memory efficient (only stores current
      path). Good when solution is deep or when you need to
      explore all paths.

    when_to_use:
      - Solution likely deep in search space
      - Memory is constrained
      - Need to explore all paths (exhaustive search)
      - Detecting cycles or connectivity
      - Topological sorting

    key_concepts:
      stack: "LIFO data structure drives DFS (or recursion)"
      backtrack: "Return to previous node when stuck"
      path: "Current sequence from root to current node"
      visited: "Track nodes already explored"

    prioritization_rules:
      1_pick_one_path:
        rule: "Choose one option and commit to exploring it fully"
        action: "Push to stack, recurse"

      2_go_as_deep_as_possible:
        rule: "Keep going until no more options"
        mechanism: "Recursive calls or explicit stack"

      3_backtrack_when_stuck:
        rule: "When path exhausted, return to last choice point"
        effect: "Try alternative branch"

      4_mark_visited:
        rule: "Don't revisit already-explored nodes"
        reason: "Prevents infinite loops"

    variants:
      pre_order: "Process node before children"
      post_order: "Process node after children"
      in_order: "Process between left and right (binary trees)"

    comparison_to_bfs:
      dfs: "Deep then wide - memory efficient"
      bfs: "Wide then deep - shortest path"
      memory: "DFS uses O(depth), BFS uses O(width)"
      when_dfs_wins: "Deep solutions, memory limits, need all paths"
      when_bfs_wins: "Shallow solutions, shortest path needed"

    anti_patterns:
      - "Using DFS when shortest path matters"
      - "Not tracking visited (infinite loops)"
      - "Using on very deep graphs without depth limit"
      - "When solution is near root (BFS faster)"

    example:
      context: "Generating all permutations"
      approach:
        start: "Empty permutation"
        recurse: "Add one element, recurse"
        backtrack: "Remove element, try next"
        complete: "When permutation full, record it"
      why_dfs: "Need to explore ALL paths, not just shortest"
      memory: "Only stores current permutation, not all partial ones"
      rationale: "DFS naturally generates all possibilities"

    source: "Graph Algorithms - Depth-First Search"

  # ----------------------------------------
  # VARIATION 41: GREEDY-LOCAL ORDERING
  # ----------------------------------------
  greedy_local:
    id: greedy_local_ordering
    name: "Greedy-Local Ordering (Best Local Choice)"
    category: algorithmic_optimization

    philosophy: |
      At each step, make the locally optimal choice without
      reconsidering. From greedy algorithms: build solution
      incrementally by always choosing what looks best right now.
      Fast (no backtracking) but only optimal when greedy-choice
      property holds.

    when_to_use:
      - Problem has greedy-choice property
      - Local optimum leads to global optimum
      - Need fast approximate solution
      - Optimal substructure exists
      - Activity selection, Huffman coding, MST

    key_concepts:
      greedy_choice: "Local optimum leads to global optimum"
      optimal_substructure: "Optimal solution contains optimal subsolutions"
      irrevocable: "Choices are never reconsidered"
      myopic: "Only considers current state, not future"

    when_greedy_works:
      activity_selection: "Earliest finish time first"
      huffman_coding: "Lowest frequency first"
      minimum_spanning_tree: "Smallest edge first (Kruskal)"
      dijkstra: "Closest unvisited vertex first"
      fractional_knapsack: "Highest value/weight ratio first"

    when_greedy_fails:
      0_1_knapsack: "Best ratio doesn't guarantee optimal"
      tsp: "Nearest neighbor often suboptimal"
      coin_change_some_denominations: "Greedy fails for {1,5,6} making 12"
      graph_coloring: "Greedy may use more colors than needed"

    prioritization_rules:
      1_define_greedy_criterion:
        rule: "What makes one choice 'better' than another?"
        examples:
          - "Shortest processing time"
          - "Earliest deadline"
          - "Highest value/cost ratio"
          - "Nearest neighbor"

      2_sort_by_criterion:
        rule: "Order all options by greedy criterion"
        action: "Best first"

      3_select_greedily:
        rule: "Take best available option that's feasible"
        check: "Does it violate any constraints?"

      4_never_reconsider:
        rule: "Once chosen, don't undo"
        trade_off: "Speed vs optimality"

    anti_patterns:
      - "Using greedy when it doesn't guarantee optimal"
      - "Not verifying greedy-choice property holds"
      - "Reconsidering choices (that's backtracking)"
      - "Ignoring feasibility constraints"

    example:
      context: "Activity selection (maximize non-overlapping activities)"
      greedy_criterion: "Earliest finish time"
      activities:
        A: "9:00-10:30"
        B: "9:30-11:00"
        C: "10:00-10:30"
        D: "10:30-11:30"
        E: "11:00-12:00"
      greedy_order:
        1: "C (finishes 10:30) - select"
        2: "A (finishes 10:30, overlaps C) - skip"
        3: "B (finishes 11:00, overlaps C) - skip"
        4: "D (finishes 11:30, starts after C) - select"
        5: "E (finishes 12:00, overlaps D) - skip"
      result: "C, D selected (2 activities)"
      optimal: "Yes - greedy works for activity selection"

    source: "Algorithm Design - Greedy Algorithms"

  # ----------------------------------------
  # VARIATION 42: DYNAMIC-SUBPROBLEM ORDERING
  # ----------------------------------------
  dynamic_subproblem:
    id: dynamic_subproblem_ordering
    name: "Dynamic-Subproblem Ordering (Bottom-Up DP)"
    category: algorithmic_optimization

    philosophy: |
      Solve and cache subproblems before solving larger problems.
      From dynamic programming: when subproblems overlap, solve
      each once and store results. Bottom-up approach builds from
      smallest subproblems to the full solution. Avoids redundant
      computation.

    when_to_use:
      - Overlapping subproblems exist
      - Optimal substructure property holds
      - Recursive solution would recompute same values
      - Can define clear subproblem ordering
      - Fibonacci, shortest paths, knapsack, edit distance

    key_concepts:
      overlapping_subproblems: "Same subproblems solved multiple times"
      optimal_substructure: "Optimal solution uses optimal subsolutions"
      memoization: "Top-down caching (recursive)"
      tabulation: "Bottom-up table filling (iterative)"

    approaches:
      top_down_memoization:
        style: "Recursive with cache"
        order: "Solve subproblems on demand"
        pros: "Natural recursion, only solves needed subproblems"
        cons: "Recursion overhead, stack limits"

      bottom_up_tabulation:
        style: "Iterative table filling"
        order: "Solve smallest subproblems first, build up"
        pros: "No recursion overhead, can optimize space"
        cons: "Must determine correct order, solves all subproblems"

    prioritization_rules:
      1_identify_subproblems:
        rule: "What are the building blocks?"
        examples:
          - "Fibonacci: F(n-1), F(n-2)"
          - "Knapsack: items 1..i with capacity j"
          - "Edit distance: prefixes of both strings"

      2_define_recurrence:
        rule: "How does solution relate to subproblems?"
        formula: "dp[i] = f(dp[smaller indices])"

      3_determine_base_cases:
        rule: "What are the smallest subproblems?"
        examples:
          - "Fibonacci: F(0)=0, F(1)=1"
          - "Empty string has edit distance = length of other"

      4_fill_table_in_order:
        rule: "Ensure subproblems solved before they're needed"
        typical: "Smaller indices before larger"

      5_extract_answer:
        rule: "Final answer is in specific cell"
        location: "Usually dp[n] or dp[n][m]"

    anti_patterns:
      - "Recomputing subproblems (exponential time)"
      - "Wrong order (using values not yet computed)"
      - "Not recognizing overlapping subproblems"
      - "Using DP when greedy works (overkill)"

    example:
      context: "Computing Fibonacci numbers"
      naive_recursive:
        F_5: "Calls F(4) and F(3)"
        F_4: "Calls F(3) and F(2)"
        F_3: "Called multiple times - redundant!"
        complexity: "O(2^n) - exponential"

      bottom_up_dp:
        order: "F(0), F(1), F(2), F(3), F(4), F(5)"
        table: "[0, 1, 1, 2, 3, 5]"
        complexity: "O(n) - linear"

      space_optimization:
        insight: "Only need last two values"
        space: "O(1) instead of O(n)"

      rationale: "Solve small before large, store results"

    source: "Algorithm Design - Dynamic Programming"

  # ----------------------------------------
  # VARIATION 43: BACKTRACK-PRUNE ORDERING
  # ----------------------------------------
  backtrack_prune:
    id: backtrack_prune_ordering
    name: "Backtrack-Prune Ordering (Try-Fail-Undo)"
    category: constraint_solving

    philosophy: |
      Build solution incrementally, abandon partial solutions that
      can't possibly work. From backtracking: try a choice, recurse,
      if it fails undo and try next. Pruning eliminates branches
      early when they violate constraints. Explores solution space
      systematically without full enumeration.

    when_to_use:
      - Constraint satisfaction problems
      - Finding all solutions (or any solution)
      - When partial solutions can be validated
      - Puzzles: N-Queens, Sudoku, crosswords
      - Combinatorial search with constraints

    key_concepts:
      partial_solution: "Incomplete assignment being built"
      constraint_check: "Does partial solution violate any rule?"
      backtrack: "Undo last choice, try alternative"
      prune: "Skip entire subtrees that can't lead to solution"

    prioritization_rules:
      1_choose:
        rule: "Make a choice to extend partial solution"
        strategy: "Often use variable/value ordering heuristics"

      2_check_constraints:
        rule: "Does this choice violate any constraint?"
        if_valid: "Continue to next choice"
        if_invalid: "Prune this branch"

      3_recurse:
        rule: "If valid, recursively solve remaining problem"
        base_case: "If complete solution, record it"

      4_backtrack:
        rule: "If recursion fails, undo choice, try next option"
        mechanism: "Return from recursive call, pop from stack"

      5_prune_aggressively:
        rule: "Detect failures as early as possible"
        techniques:
          - "Forward checking: eliminate impossible values"
          - "Constraint propagation: infer additional constraints"
          - "Heuristics: choose most constrained variable first"

    ordering_heuristics:
      mrv: "Minimum Remaining Values - most constrained first"
      degree: "Choose variable affecting most others"
      lcv: "Least Constraining Value - keep options open"

    anti_patterns:
      - "Not pruning (explores impossible branches)"
      - "Pruning too late (wasted exploration)"
      - "Not undoing state properly (corrupted search)"
      - "Using when better algorithms exist"

    example:
      context: "Solving Sudoku"
      backtrack_approach:
        1_choose: "Pick empty cell, try digit 1-9"
        2_check: "Does digit violate row/column/box constraint?"
        3_recurse: "If valid, move to next empty cell"
        4_backtrack: "If stuck, undo and try next digit"
        5_prune: "Skip digits already in row/column/box"

      with_mrv_heuristic:
        improvement: "Choose cell with fewest valid options first"
        reason: "Fails faster if unsolvable, reduces branching"

      pruning_power:
        without: "9^81 possible assignments to explore"
        with_constraints: "Prune most branches immediately"

    source: "Algorithm Design - Backtracking, Constraint Satisfaction"

  # ----------------------------------------
  # VARIATION 44: HEURISTIC-GUIDED ORDERING
  # ----------------------------------------
  heuristic_guided:
    id: heuristic_guided_ordering
    name: "Heuristic-Guided Ordering (A* Style)"
    category: constraint_solving

    philosophy: |
      Use estimates to guide search toward likely solutions first.
      From A* search: f(n) = g(n) + h(n) where g is cost so far
      and h is estimated cost to goal. Always expand the most
      promising node. Optimal if heuristic is admissible (never
      overestimates).

    when_to_use:
      - Search problems with goal states
      - Can estimate distance/cost to goal
      - Want optimal solution (with admissible heuristic)
      - Pathfinding, puzzle solving, planning
      - When blind search is too slow

    key_concepts:
      heuristic: "Estimate of cost from current state to goal"
      admissible: "Never overestimates true cost (optimistic)"
      consistent: "h(n) â‰¤ cost(n,n') + h(n') for all edges"
      f_value: "f(n) = g(n) + h(n) - total estimated cost"
      priority_queue: "Always expand lowest f-value node"

    components:
      g_n: "Actual cost from start to current node"
      h_n: "Estimated cost from current to goal"
      f_n: "g(n) + h(n) = estimated total path cost"

    prioritization_rules:
      1_compute_f_values:
        rule: "For each candidate, compute f = g + h"
        g: "Known cost to reach this state"
        h: "Estimated cost to reach goal from here"

      2_expand_lowest_f:
        rule: "Always process node with lowest f value"
        mechanism: "Priority queue ordered by f"

      3_update_as_discovered:
        rule: "If better path found to node, update g and f"
        effect: "May reprioritize node in queue"

      4_stop_at_goal:
        rule: "When goal has lowest f, optimal path found"
        reason: "No unexplored path could be shorter"

    heuristic_design:
      admissible_examples:
        manhattan: "Sum of x and y distances (grid pathfinding)"
        euclidean: "Straight-line distance"
        misplaced_tiles: "Count of tiles out of place (puzzles)"
      trade_off: "Better heuristic = less search but more computation"

    anti_patterns:
      - "Overestimating heuristic (not admissible, not optimal)"
      - "Zero heuristic (degenerates to Dijkstra)"
      - "Not using priority queue (loses efficiency)"
      - "Computing expensive heuristic when cheap one suffices"

    example:
      context: "Pathfinding on a map"
      setup:
        start: "City A"
        goal: "City Z"
        g: "Actual road distance traveled so far"
        h: "Straight-line distance to Z (admissible)"

      search_process:
        step_1: "Start at A, f(A) = 0 + h(A)"
        step_2: "Expand A, add neighbors with f values"
        step_3: "Expand node with lowest f"
        continue: "Until Z has lowest f in queue"

      why_optimal: "Admissible h means f never overestimates true cost"
      efficiency: "h guides search toward goal, avoiding dead ends"

    source: "AI/Search Algorithms - A*, Best-First Search"

  # ----------------------------------------
  # VARIATION 45: DIVIDE-CONQUER ORDERING
  # ----------------------------------------
  divide_conquer:
    id: divide_conquer_ordering
    name: "Divide-Conquer Ordering (Split-Solve-Combine)"
    category: algorithmic_optimization

    philosophy: |
      Break problem into independent subproblems, solve each
      recursively, combine results. From divide and conquer:
      the problem is divided until trivially solvable, then
      solutions are merged. Enables parallelization and often
      achieves O(n log n) complexity.

    when_to_use:
      - Problem can be split into independent parts
      - Subproblems are same type as original
      - Combining solutions is straightforward
      - Sorting, searching, matrix operations
      - Naturally parallelizable workloads

    key_concepts:
      divide: "Split problem into smaller subproblems"
      conquer: "Solve subproblems recursively"
      combine: "Merge subproblem solutions into final answer"
      base_case: "Smallest subproblem solved directly"

    classic_examples:
      merge_sort:
        divide: "Split array in half"
        conquer: "Recursively sort each half"
        combine: "Merge two sorted halves"
        complexity: "O(n log n)"

      quicksort:
        divide: "Partition around pivot"
        conquer: "Recursively sort partitions"
        combine: "Nothing (sorted in place)"
        complexity: "O(n log n) average"

      binary_search:
        divide: "Check middle, eliminate half"
        conquer: "Search remaining half"
        combine: "Nothing (just return result)"
        complexity: "O(log n)"

    prioritization_rules:
      1_identify_divide_point:
        rule: "How to split problem into parts?"
        strategies:
          - "Split in half (merge sort)"
          - "Partition by value (quicksort)"
          - "Split by dimension (matrix)"

      2_ensure_independence:
        rule: "Subproblems should not depend on each other"
        reason: "Enables parallel execution"

      3_solve_subproblems:
        rule: "Apply same algorithm recursively"
        base: "Stop at trivial size"

      4_combine_efficiently:
        rule: "Merging should not dominate complexity"
        merge_sort: "O(n) merge step"
        quicksort: "O(1) combine (nothing to do)"

    parallelization:
      opportunity: "Subproblems can be solved in parallel"
      fork_join: "Fork subproblems, join results"
      speedup: "Up to O(log n) with enough processors"

    anti_patterns:
      - "Subproblems not independent (can't parallelize)"
      - "Expensive combine step (dominates complexity)"
      - "Unbalanced divide (one subproblem much larger)"
      - "Not reaching base case (infinite recursion)"

    example:
      context: "Sorting a large array"
      merge_sort_order:
        divide: "[5,2,8,1,9,3] â†’ [5,2,8] and [1,9,3]"
        recurse_left: "[5,2,8] â†’ [5] [2,8] â†’ [5] [2] [8]"
        combine_left: "[2] [8] â†’ [2,8] â†’ [2,5,8]"
        recurse_right: "[1,9,3] â†’ [1] [9,3] â†’ [1] [3] [9]"
        combine_right: "[3] [9] â†’ [3,9] â†’ [1,3,9]"
        final_combine: "[2,5,8] + [1,3,9] â†’ [1,2,3,5,8,9]"
      rationale: "Divide until trivial, combine back up"

    source: "Algorithm Design - Divide and Conquer"

  # ----------------------------------------
  # VARIATION 46: PRIORITY-QUEUE ORDERING
  # ----------------------------------------
  priority_queue:
    id: priority_queue_ordering
    name: "Priority-Queue Ordering (Heap-Based)"
    category: queue_scheduling

    philosophy: |
      Always process the highest-priority item next. From heap
      data structures: maintain items in priority order, extract
      max/min in O(log n). Dynamic priority handling - new items
      inserted in correct position, priorities can be updated.

    when_to_use:
      - Items have varying priorities
      - Priorities may change or new items arrive
      - Need efficient access to highest priority
      - Dijkstra's algorithm, event simulation
      - Task scheduling, hospital triage

    key_concepts:
      heap: "Tree-based structure maintaining heap property"
      priority: "Value determining processing order"
      extract: "Remove and return highest priority item"
      insert: "Add new item in O(log n)"
      update: "Change priority, reheapify"

    heap_types:
      max_heap: "Highest priority = highest value"
      min_heap: "Highest priority = lowest value"
      use_case: "Depends on problem (min for Dijkstra)"

    prioritization_rules:
      1_define_priority:
        rule: "What determines priority?"
        examples:
          - "Deadline (earliest = highest)"
          - "Importance score"
          - "Distance from goal (smallest = highest)"
          - "Severity level"

      2_insert_with_priority:
        rule: "Add items with their priority values"
        complexity: "O(log n)"

      3_extract_highest:
        rule: "Process highest priority item"
        complexity: "O(log n)"

      4_update_if_needed:
        rule: "Reprioritize items when circumstances change"
        example: "Dijkstra updates distances when shorter path found"

    comparison_to_sorting:
      full_sort: "O(n log n) upfront, then O(1) access"
      priority_queue: "O(log n) per operation, dynamic"
      when_pq_wins: "Items arrive over time, priorities change"
      when_sort_wins: "All items known upfront, process once"

    anti_patterns:
      - "Using unsorted list (O(n) extract)"
      - "Full sort when items arrive dynamically"
      - "Not updating priorities when they change"
      - "Using when FIFO/LIFO would suffice"

    example:
      context: "Emergency room triage"
      patients:
        A: "Chest pain - priority 10 (critical)"
        B: "Broken finger - priority 3"
        C: "Difficulty breathing - priority 9"
        D: "Minor cut - priority 1"
      heap_state: "[A:10, C:9, B:3, D:1]"
      processing:
        1: "Extract A (priority 10) - treat first"
        new_arrival: "E: allergic reaction - priority 8"
        heap_state: "[C:9, E:8, B:3, D:1]"
        2: "Extract C (priority 9) - treat second"
      rationale: "Always treating most critical patient"

    source: "Data Structures - Heap, Priority Queue"

  # ----------------------------------------
  # VARIATION 47: ROUND-ROBIN ORDERING
  # ----------------------------------------
  round_robin:
    id: round_robin_ordering
    name: "Round-Robin Ordering (Fair Time-Slicing)"
    category: fairness_allocation

    philosophy: |
      Give each item equal turns in circular order. From CPU
      scheduling: each process gets a time quantum, then yields
      to the next. Ensures fairness - no item starves. Simple
      and predictable but not optimal for throughput.

    when_to_use:
      - Fairness is primary concern
      - All items have similar priority
      - Need predictable, bounded wait times
      - Time-sharing systems
      - When no better priority criterion exists

    key_concepts:
      quantum: "Time slice allocated to each item"
      circular: "After last item, return to first"
      preemption: "Item yields after quantum expires"
      waiting_time: "Bounded by (n-1) Ã— quantum"

    prioritization_rules:
      1_maintain_circular_queue:
        rule: "Items arranged in circular order"
        structure: "Queue with wrap-around"

      2_allocate_quantum:
        rule: "Each item gets fixed time slice"
        trade_off: "Small quantum = more switching, better response"
        guideline: "Quantum should be > context switch time"

      3_rotate_after_quantum:
        rule: "After quantum, move to back of queue"
        effect: "Next item gets its turn"

      4_complete_items_leave:
        rule: "Item done before quantum exits queue"
        remaining: "If not done, continues next turn"

    variations:
      simple_rr: "Fixed quantum for all"
      weighted_rr: "Different quanta based on weight"
      virtual_rr: "Adjust for I/O-bound processes"

    comparison:
      fifo: "First come, first served - unfair for long items"
      priority: "May starve low priority"
      round_robin: "Fair but may not optimize throughput"

    anti_patterns:
      - "Quantum too small (excessive context switching)"
      - "Quantum too large (degenerates to FIFO)"
      - "Using when priorities differ significantly"
      - "Not suitable for batch processing"

    example:
      context: "CPU scheduling 3 processes"
      quantum: "4 time units"
      processes:
        P1: "Needs 8 units"
        P2: "Needs 3 units"
        P3: "Needs 5 units"
      round_robin_execution:
        time_0_4: "P1 runs (4 units done, 4 remaining)"
        time_4_7: "P2 runs (3 units done, complete)"
        time_7_11: "P3 runs (4 units done, 1 remaining)"
        time_11_15: "P1 runs (4 units done, complete)"
        time_15_16: "P3 runs (1 unit done, complete)"
      total_time: "16 units"
      fairness: "Each process got regular turns"

    source: "Operating Systems - Round-Robin Scheduling"

  # ----------------------------------------
  # VARIATION 48: BRANCH-BOUND ORDERING
  # ----------------------------------------
  branch_bound:
    id: branch_bound_ordering
    name: "Branch-and-Bound Ordering (Bound-Based Pruning)"
    category: algorithmic_optimization

    philosophy: |
      Explore solution space systematically, pruning branches that
      can't beat the best known solution. From optimization: maintain
      a bound on each partial solution's potential. If bound is worse
      than best complete solution, prune entire subtree. Guarantees
      optimal solution while avoiding full enumeration.

    when_to_use:
      - Optimization problems (minimize/maximize)
      - Can compute bounds on partial solutions
      - Need guaranteed optimal solution
      - TSP, knapsack, integer programming
      - When heuristics alone aren't sufficient

    key_concepts:
      branching: "Split problem into subproblems"
      bounding: "Compute optimistic bound on each branch"
      pruning: "Skip branches that can't improve best"
      incumbent: "Best complete solution found so far"

    prioritization_rules:
      1_compute_bound:
        rule: "For each partial solution, compute optimistic bound"
        property: "Bound must be â‰¤ optimal solution in subtree (minimizing)"
        examples:
          - "Relaxed LP solution for integer programs"
          - "MST bound for TSP"
          - "Fractional knapsack for 0/1 knapsack"

      2_compare_to_incumbent:
        rule: "If bound â‰¥ incumbent, prune branch"
        reason: "Can't possibly beat best known solution"

      3_select_next_branch:
        strategies:
          best_first: "Expand node with best bound"
          depth_first: "Go deep to find incumbent fast"
          breadth_first: "Systematic level-by-level"
        trade_off: "Best-first finds optimal faster but uses more memory"

      4_update_incumbent:
        rule: "When complete solution found, update if better"
        effect: "Tighter incumbent enables more pruning"

    bounding_techniques:
      relaxation: "Solve easier version of problem"
      greedy: "Fast heuristic solution as bound"
      lagrangian: "Dualize constraints"

    anti_patterns:
      - "Weak bounds (little pruning, near full enumeration)"
      - "Expensive bound computation (overhead > savings)"
      - "Not updating incumbent quickly (poor pruning)"
      - "Using when better algorithms exist"

    example:
      context: "0/1 Knapsack optimization"
      problem:
        items: "[value:60,weight:10], [v:100,w:20], [v:120,w:30]"
        capacity: "50"

      branch_and_bound:
        bound_function: "Fractional knapsack solution (upper bound)"
        branching: "Include or exclude each item"

        node_1:
          state: "Include item 1"
          bound: "60 + fractional(remaining) = 60 + 160 = 220"
          incumbent: "None yet"
          action: "Explore"

        node_2:
          state: "Include item 1, include item 2"
          bound: "160 + fractional(remaining) = 160 + 40 = 200"
          action: "Explore"

        found_solution:
          items: "[1, 2]"
          value: "160"
          incumbent: "160"

        pruning:
          other_branches: "If bound < 160, prune"

      result: "Optimal found without exploring all 2^n subsets"

    source: "Optimization - Branch and Bound"

# ============================================
# SEARCH PROCEDURE ORDERINGS
# ============================================
# These variations are derived from search algorithms
# used in AI, optimization, and problem-solving.

  # ----------------------------------------
  # VARIATION 49: ITERATIVE-DEEPENING ORDERING
  # ----------------------------------------
  iterative_deepening:
    id: iterative_deepening_ordering
    name: "Iterative-Deepening Ordering (IDDFS/IDA*)"
    category: population_based_search

    philosophy: |
      Combine DFS memory efficiency with BFS optimality by
      repeatedly running depth-limited DFS with increasing limits.
      From IDDFS: get the best of both worlds - O(d) memory like
      DFS, optimal shortest path like BFS. Redundant work is
      acceptable because most nodes are at the deepest level.

    when_to_use:
      - Need optimal solution but memory constrained
      - Don't know solution depth in advance
      - Branching factor is moderate to high
      - Want completeness guarantee
      - Puzzles, game trees, pathfinding

    key_concepts:
      depth_limit: "Maximum depth for current iteration"
      iteration: "One complete DFS up to current limit"
      deepening: "Increase limit and repeat"
      redundancy: "Earlier iterations redo work (acceptable overhead)"

    algorithm:
      for_depth_0_to_infinity:
        - "Run depth-limited DFS up to current depth"
        - "If solution found, return it (optimal)"
        - "If not found, increment depth limit"
        - "Repeat until solution found or space exhausted"

    prioritization_rules:
      1_start_shallow:
        rule: "Begin with depth limit 0"
        reason: "Find shallow solutions first"

      2_complete_level_before_deepening:
        rule: "Fully explore current depth before increasing"
        guarantee: "First solution found is optimal"

      3_increment_limit:
        rule: "Increase depth by 1 each iteration"
        alternative: "IDA* increases by f-value threshold"

      4_accept_redundancy:
        rule: "Re-exploring shallow nodes is OK"
        math: "Overhead is O(b) where b is branching factor"
        reason: "Memory savings outweigh time cost"

    variants:
      iddfs: "Plain iterative deepening DFS"
      ida_star: "With A* heuristic - increase by f-value"
      ilds: "Iterative lengthening (for weighted graphs)"

    comparison:
      vs_bfs: "Same optimality, much less memory"
      vs_dfs: "Optimal (DFS isn't), similar memory"
      vs_a_star: "IDA* has same optimality, linear memory"

    anti_patterns:
      - "Using when memory isn't constrained (A* faster)"
      - "High branching factor with deep solution"
      - "When redundant work is unacceptable"
      - "Problems where shallow solutions don't exist"

    example:
      context: "Solving 15-puzzle with IDA*"
      iterations:
        iter_1: "Depth limit 10, no solution, expand nodes"
        iter_2: "Depth limit 15, no solution, re-expand + more"
        iter_3: "Depth limit 20, no solution"
        iter_4: "Depth limit 25, SOLUTION FOUND"
      memory: "Only stores current path (O(25) nodes)"
      comparison: "A* would store millions of nodes"
      rationale: "Trade time redundancy for memory efficiency"

    source: "AI Search - IDDFS (Korf 1985), IDA*"

  # ----------------------------------------
  # VARIATION 50: HILL-CLIMBING ORDERING
  # ----------------------------------------
  hill_climbing:
    id: hill_climbing_ordering
    name: "Hill-Climbing Ordering (Local Search)"
    category: local_search

    philosophy: |
      Always move to the best neighboring state. From local search:
      start somewhere, look at neighbors, move to the best one,
      repeat until no neighbor is better. Simple and fast but can
      get stuck in local optima. No backtracking - purely greedy
      local moves.

    when_to_use:
      - Optimization with clear neighbor structure
      - Good-enough solution acceptable (not necessarily optimal)
      - Fast iteration more important than optimality
      - Landscape is relatively smooth (few local optima)
      - As baseline before trying fancier methods

    key_concepts:
      current_state: "Where you are now"
      neighbors: "States reachable by one move"
      evaluation: "How good is each state?"
      local_optimum: "No neighbor is better (may not be global)"
      plateau: "Neighbors have same value (no gradient)"

    variants:
      simple: "Move to any better neighbor"
      steepest_ascent: "Move to BEST neighbor"
      stochastic: "Random choice among better neighbors"
      first_choice: "Move to first better neighbor found"

    prioritization_rules:
      1_evaluate_current:
        rule: "Compute fitness/value of current state"
        baseline: "This is what we're trying to beat"

      2_generate_neighbors:
        rule: "Find all states one step away"
        method: "Problem-specific neighbor function"

      3_select_best_neighbor:
        rule: "Pick neighbor with highest evaluation"
        variant: "Or first improvement, or random better"

      4_move_if_better:
        rule: "If best neighbor > current, move there"
        if_not: "Stop - at local optimum"

      5_repeat:
        rule: "Continue until stuck"
        no_backtrack: "Never undo a move"

    problems:
      local_optima: "Better than neighbors but not best overall"
      plateaus: "Flat regions with no gradient"
      ridges: "Narrow paths to optimum"

    anti_patterns:
      - "Using when global optimum required"
      - "Landscapes with many local optima"
      - "Not trying random restarts"
      - "Expecting completeness"

    example:
      context: "Optimizing neural network weights locally"
      process:
        start: "Random initial weights"
        neighbors: "Weights Â± small delta"
        evaluate: "Loss function"
        iterate:
          step_1: "Current loss: 0.5"
          step_2: "Best neighbor loss: 0.45 â†’ move"
          step_3: "Best neighbor loss: 0.42 â†’ move"
          step_4: "Best neighbor loss: 0.41 â†’ move"
          step_5: "All neighbors â‰¥ 0.41 â†’ STUCK"
      result: "Local optimum at 0.41 (may not be global best)"
      rationale: "Fast but may miss better solutions"

    source: "Optimization - Local Search, Hill Climbing"

  # ----------------------------------------
  # VARIATION 51: SIMULATED-ANNEALING ORDERING
  # ----------------------------------------
  simulated_annealing:
    id: simulated_annealing_ordering
    name: "Simulated-Annealing Ordering (Probabilistic Escape)"
    category: local_search

    philosophy: |
      Like hill climbing but occasionally accept worse moves to
      escape local optima. From metallurgy: high temperature allows
      atoms to move freely; cooling slowly lets them settle into
      low-energy configurations. Start with high "temperature"
      (accept bad moves), gradually cool (become more selective).

    when_to_use:
      - Optimization with many local optima
      - Global optimum important but exact not required
      - Can define neighbor structure and energy function
      - TSP, scheduling, VLSI design
      - When hill climbing gets stuck

    key_concepts:
      temperature: "Controls probability of accepting worse moves"
      cooling_schedule: "How temperature decreases over time"
      acceptance_probability: "exp(-Î”E/T) for worse moves"
      annealing: "Slow cooling to reach good configuration"

    algorithm:
      initialize: "Start with random solution, high temperature"
      loop:
        1_generate_neighbor: "Pick a random neighbor"
        2_compute_delta: "Î”E = E(neighbor) - E(current)"
        3_accept_or_reject:
          if_better: "Always accept (Î”E < 0)"
          if_worse: "Accept with probability exp(-Î”E/T)"
        4_cool: "Reduce temperature according to schedule"
        5_repeat: "Until temperature ~ 0 or time limit"

    prioritization_rules:
      1_high_temp_exploration:
        rule: "At high T, explore widely (accept bad moves)"
        reason: "Escape local optima early"
        probability: "Most moves accepted"

      2_gradual_cooling:
        rule: "Reduce T slowly"
        schedules:
          linear: "T = T - Î±"
          geometric: "T = T Ã— Î± (e.g., Î± = 0.95)"
          logarithmic: "T = Tâ‚€ / log(1 + t)"
        trade_off: "Faster cooling = faster but worse results"

      3_low_temp_exploitation:
        rule: "At low T, be selective (mostly accept improvements)"
        reason: "Converge to good solution"
        probability: "Only better moves accepted"

      4_final_quench:
        rule: "At T â‰ˆ 0, do pure hill climbing"
        effect: "Fine-tune final solution"

    comparison_to_hill_climbing:
      hill_climbing: "Always accept best, gets stuck"
      simulated_annealing: "Sometimes accept worse, escapes"
      trade_off: "SA slower but finds better solutions"

    anti_patterns:
      - "Cooling too fast (acts like hill climbing)"
      - "Cooling too slow (wastes computation)"
      - "Temperature too low initially (no exploration)"
      - "Not tuning acceptance probability"

    example:
      context: "Traveling Salesman Problem"
      process:
        initial_tour: "Random - distance 500"
        high_temp_T_1000:
          neighbor: "Swap two cities - distance 520"
          delta: "+20 (worse)"
          probability: "exp(-20/1000) = 0.98 â†’ ACCEPT"
        medium_temp_T_100:
          neighbor: "Swap two cities - distance 490"
          delta: "-10 (better) â†’ ACCEPT"
          neighbor_2: "Swap - distance 510"
          delta_2: "+20"
          probability_2: "exp(-20/100) = 0.82 â†’ ACCEPT"
        low_temp_T_10:
          neighbor: "Swap - distance 495"
          delta: "+5"
          probability: "exp(-5/10) = 0.61 â†’ maybe accept"
        very_low_T_1:
          only_improvements: "accepted"
      final: "Tour distance 420 (better than hill climbing's 450)"

    source: "Optimization - Simulated Annealing (Kirkpatrick 1983)"

  # ----------------------------------------
  # VARIATION 52: BEAM-SEARCH ORDERING
  # ----------------------------------------
  beam_search:
    id: beam_search_ordering
    name: "Beam-Search Ordering (Width-Limited Best-First)"
    category: population_based_search

    philosophy: |
      Like BFS but only keep the k best nodes at each level.
      From NLP/AI: memory-bounded best-first search that prunes
      unpromising branches. Trade completeness for tractability.
      Beam width k controls memory/quality trade-off.

    when_to_use:
      - Large branching factor, limited memory
      - Good heuristic to rank candidates
      - Approximate solution acceptable
      - Machine translation, speech recognition
      - When full BFS/best-first is infeasible

    key_concepts:
      beam_width: "k - number of nodes kept at each level"
      pruning: "Discard all but top k candidates"
      heuristic: "Function to rank candidates"
      incomplete: "May prune the optimal solution"

    beam_width_effects:
      k_1: "Equivalent to greedy/hill climbing"
      k_small: "Fast, more pruning, higher risk of missing optimal"
      k_large: "Slower, less pruning, better quality"
      k_infinite: "Equivalent to full best-first search"

    prioritization_rules:
      1_initialize:
        rule: "Start with initial state(s)"
        beam: "At most k candidates"

      2_expand_all:
        rule: "Generate all children of current beam"
        result: "Many candidates (up to k Ã— b)"

      3_score_and_rank:
        rule: "Evaluate all candidates with heuristic"
        sort: "Best to worst"

      4_prune_to_beam:
        rule: "Keep only top k candidates"
        discard: "All others permanently removed"

      5_repeat:
        rule: "Continue until goal found or beam empty"
        note: "If beam empties, no solution found"

    variants:
      standard: "Fixed beam width throughout"
      variable: "Adjust width based on quality variance"
      stochastic: "Random selection among top candidates"
      best_first_beam: "Hybrid with best-first ordering"

    anti_patterns:
      - "Beam too narrow (misses good solutions)"
      - "Beam too wide (no memory benefit)"
      - "Poor heuristic (wrong candidates kept)"
      - "Using when optimality required"

    example:
      context: "Machine translation (beam width k=3)"
      translation_of: "The cat sat"
      step_1:
        candidates: ["Le", "La", "Les", "Un", "Une"]
        scores: [0.4, 0.3, 0.1, 0.1, 0.1]
        beam: ["Le", "La", "Les"]  # top 3
      step_2:
        expand: "Each + next word"
        candidates: ["Le chat", "Le chien", "La chat", "La chatte", ...]
        scores: [0.35, 0.05, 0.02, 0.30, ...]
        beam: ["Le chat", "La chatte", "Le fÃ©lin"]  # top 3
      step_3:
        continue: "Until end of sentence"
      result: "Best translation from beam"
      trade_off: "Fast but may miss optimal translation"

    source: "AI/NLP - Beam Search, Best-First Beam Search"

  # ----------------------------------------
  # VARIATION 53: GENETIC-EVOLUTIONARY ORDERING
  # ----------------------------------------
  genetic_evolutionary:
    id: genetic_evolutionary_ordering
    name: "Genetic-Evolutionary Ordering (Population-Based)"
    category: population_based_search

    philosophy: |
      Maintain a population of solutions, evolve them through
      selection, crossover, and mutation. From biology: survival
      of the fittest. Good solutions "breed" to create offspring;
      random mutations introduce diversity. Population approach
      naturally explores multiple regions simultaneously.

    when_to_use:
      - Complex optimization with many local optima
      - Can encode solutions as "chromosomes"
      - No gradient information available
      - Parallel evaluation possible
      - Feature selection, scheduling, design optimization

    key_concepts:
      population: "Set of candidate solutions"
      chromosome: "Encoding of one solution"
      fitness: "How good is a solution"
      selection: "Choose parents based on fitness"
      crossover: "Combine parents to create offspring"
      mutation: "Random changes for diversity"
      generation: "One cycle of evolution"

    algorithm:
      initialize: "Random population of solutions"
      evaluate: "Compute fitness for each"
      loop_per_generation:
        1_selection: "Choose parents (fitness-proportional)"
        2_crossover: "Combine parent genes to make children"
        3_mutation: "Random changes to some children"
        4_evaluate: "Compute fitness of new individuals"
        5_replace: "New generation replaces old"
      terminate: "After N generations or fitness threshold"

    prioritization_rules:
      1_fitness_based_selection:
        rule: "Better solutions more likely to be parents"
        methods:
          roulette: "Probability âˆ fitness"
          tournament: "Pick best of random subset"
          rank: "Based on rank, not absolute fitness"

      2_crossover_for_exploitation:
        rule: "Combine good solutions to find better"
        types:
          one_point: "Split and swap tails"
          two_point: "Swap middle section"
          uniform: "Each gene from random parent"

      3_mutation_for_exploration:
        rule: "Random changes prevent premature convergence"
        rate: "Typically 1-5% of genes"
        purpose: "Introduce new genetic material"

      4_elitism:
        rule: "Keep best solutions across generations"
        reason: "Never lose the best found so far"

    comparison:
      vs_hill_climbing: "Explores multiple regions simultaneously"
      vs_simulated_annealing: "Population vs single solution"
      vs_random_search: "Guided by fitness, not purely random"

    anti_patterns:
      - "Population too small (premature convergence)"
      - "Population too large (slow)"
      - "Mutation rate too high (random search)"
      - "Mutation rate too low (stuck in local optima)"
      - "Poor fitness function"

    example:
      context: "Evolving neural network architecture"
      chromosome: "[layers, neurons_per_layer, activation, ...]"
      process:
        generation_0:
          population: "100 random architectures"
          best_fitness: "0.65 accuracy"
        generation_10:
          selection: "Top 50% become parents"
          crossover: "Combine layer configs"
          mutation: "Randomly change activations"
          best_fitness: "0.78 accuracy"
        generation_50:
          best_fitness: "0.91 accuracy"
        generation_100:
          best_fitness: "0.94 accuracy (converged)"
      result: "Evolved architecture outperforms hand-designed"

    source: "Evolutionary Computation - Genetic Algorithms (Holland)"

  # ----------------------------------------
  # VARIATION 54: MONTE-CARLO-TREE ORDERING
  # ----------------------------------------
  monte_carlo_tree:
    id: monte_carlo_tree_ordering
    name: "Monte-Carlo-Tree Ordering (MCTS/UCB)"
    category: bandit_exploration

    philosophy: |
      Build a search tree by random sampling and statistics.
      From game AI (AlphaGo): balance exploration of unknown
      regions with exploitation of known good moves using UCB
      (Upper Confidence Bound). Incrementally grow tree toward
      promising areas. No domain knowledge required.

    when_to_use:
      - Large search spaces (games, planning)
      - Can simulate/rollout to terminal states
      - Want to balance exploration and exploitation
      - No good heuristic available
      - Game playing, planning under uncertainty

    key_concepts:
      tree: "Partial game tree built incrementally"
      simulation: "Random playout to estimate value"
      ucb: "Upper Confidence Bound for selection"
      exploration: "Try uncertain moves"
      exploitation: "Focus on known good moves"

    four_phases:
      1_selection:
        action: "Traverse tree using UCB to select child"
        formula: "UCB1 = Q(s,a) + câˆš(ln(N(s))/N(s,a))"
        meaning: "Balance average value + exploration bonus"

      2_expansion:
        action: "Add new child node to tree"
        when: "Reach a node not fully expanded"

      3_simulation:
        action: "Random playout from new node to terminal"
        purpose: "Estimate value of new node"

      4_backpropagation:
        action: "Update statistics back up the tree"
        update: "Visit counts and average values"

    prioritization_rules:
      1_ucb_selection:
        rule: "Use UCB formula to pick child nodes"
        exploration_term: "câˆš(ln(N)/n) - high for unvisited"
        exploitation_term: "Q - average value from simulations"
        balance: "Parameter c controls trade-off"

      2_expand_promising:
        rule: "Expand nodes that UCB selects"
        effect: "Tree grows toward good regions"

      3_simulate_to_learn:
        rule: "Random playouts give value estimates"
        many_simulations: "More accurate estimates"

      4_propagate_learning:
        rule: "Update all ancestors with result"
        effect: "Tree statistics improve over time"

    ucb_parameter_c:
      low_c: "More exploitation (exploit known good)"
      high_c: "More exploration (try unknowns)"
      typical: "c = âˆš2 (theoretical optimal)"

    anti_patterns:
      - "Too few simulations (inaccurate estimates)"
      - "Wrong c value (imbalanced explore/exploit)"
      - "Not enough tree growth (shallow search)"
      - "Using when better heuristics exist"

    example:
      context: "Game of Go move selection"
      process:
        iteration_1:
          select: "Root â†’ UCB picks move A (unexplored)"
          expand: "Add node for move A"
          simulate: "Random game â†’ Black wins"
          backprop: "A: 1 win / 1 visit"
        iteration_100:
          tree_state: "A: 45/80, B: 30/50, C: 5/10, ..."
          select: "UCB favors B (good ratio + some uncertainty)"
        iteration_1000:
          tree_state: "A: 400/700, B: 350/500, C: 50/200"
          best_move: "B (highest win rate)"
      result: "Move B selected based on statistics"
      alphago: "Combined MCTS with neural networks"

    source: "AI/Games - Monte Carlo Tree Search, UCT (Kocsis & SzepesvÃ¡ri)"

  # ----------------------------------------
  # VARIATION 55: RANDOM-RESTART ORDERING
  # ----------------------------------------
  random_restart:
    id: random_restart_ordering
    name: "Random-Restart Ordering (Multi-Start Local Search)"
    category: local_search

    philosophy: |
      Run local search multiple times from different starting
      points. From optimization: if stuck in local optimum, just
      try again from somewhere else. Simple but effective - covers
      more of the search space by random initial positions. Keep
      the best result across all restarts.

    when_to_use:
      - Local search gets stuck in local optima
      - Many local optima exist
      - Good-enough solution acceptable
      - Can afford multiple runs
      - When simulated annealing too complex

    key_concepts:
      restart: "Begin local search from new random point"
      best_so_far: "Best solution found across all restarts"
      independence: "Each restart is independent"
      coverage: "More restarts = better coverage of space"

    algorithm:
      best_overall: "None"
      for_k_restarts:
        1_random_start: "Generate random initial solution"
        2_local_search: "Run hill climbing to local optimum"
        3_update_best: "If better than best_overall, update"
      return: "best_overall"

    prioritization_rules:
      1_diversify_starts:
        rule: "Ensure starting points are spread out"
        method: "Random, grid, or stratified sampling"

      2_run_to_convergence:
        rule: "Let each local search reach its optimum"
        reason: "Don't stop early"

      3_track_best:
        rule: "Remember best across all restarts"
        guarantee: "Output is best of all local optima found"

      4_enough_restarts:
        rule: "More restarts = higher chance of global optimum"
        diminishing: "Returns diminish as space gets covered"

    how_many_restarts:
      formula: "P(find global) = 1 - (1-p)^k"
      where: "p = probability one restart finds global"
      example: "If p=0.01, need ~230 restarts for 90% chance"

    comparison:
      vs_single_run: "Much better coverage"
      vs_simulated_annealing: "Simpler, sometimes competitive"
      vs_genetic: "No population overhead"

    anti_patterns:
      - "Too few restarts (poor coverage)"
      - "Not running local search to convergence"
      - "Starting points not diverse enough"
      - "Using when single run usually succeeds"

    example:
      context: "Optimizing function with many local minima"
      restarts:
        restart_1:
          start: "x = 0.15"
          local_min: "f(0.23) = 0.45"
        restart_2:
          start: "x = 0.67"
          local_min: "f(0.72) = 0.31"
        restart_3:
          start: "x = 0.34"
          local_min: "f(0.41) = 0.52"
        restart_4:
          start: "x = 0.89"
          local_min: "f(0.85) = 0.18"  # best!
        "...": "continue for k restarts"
      result: "Best found: f(0.85) = 0.18"
      comparison: "Single run might have stopped at 0.45"

    source: "Optimization - Multi-Start Local Search, Random Restarts"

  # ----------------------------------------
  # VARIATION 56: TABU-SEARCH ORDERING
  # ----------------------------------------
  tabu_search:
    id: tabu_search_ordering
    name: "Tabu-Search Ordering (Memory-Based Local Search)"
    category: local_search

    philosophy: |
      Like hill climbing but with memory to avoid revisiting
      recent solutions. From optimization (Glover): maintain a
      "tabu list" of forbidden moves to escape cycles and local
      optima. Can accept worse moves if all good moves are tabu.
      Memory guides search away from already-explored regions.

    when_to_use:
      - Local search cycles back to same solutions
      - Want smarter escape than random restarts
      - Combinatorial optimization
      - Job shop scheduling, graph coloring, TSP
      - When simulated annealing too random

    key_concepts:
      tabu_list: "Recently visited solutions or moves"
      tabu_tenure: "How long a move stays forbidden"
      aspiration: "Override tabu if move is exceptionally good"
      intensification: "Focus on good region"
      diversification: "Force exploration of new regions"

    algorithm:
      initialize: "Start solution, empty tabu list"
      loop:
        1_generate_neighbors: "All possible moves"
        2_filter_tabu: "Remove moves in tabu list"
        3_evaluate: "Score remaining moves"
        4_select_best: "Take best non-tabu move (even if worse)"
        5_update_tabu: "Add move to tabu list"
        6_aspiration: "Override tabu if solution is best ever"
        7_manage_list: "Remove old entries (FIFO, tenure)"
      terminate: "After iterations or no improvement"

    prioritization_rules:
      1_avoid_recent:
        rule: "Don't undo recent moves"
        mechanism: "Tabu list forbids recent moves"
        reason: "Prevents cycling"

      2_accept_worse_if_needed:
        rule: "If all good moves are tabu, take best worse one"
        effect: "Escapes local optima"

      3_aspiration_criteria:
        rule: "Override tabu if move leads to best-ever solution"
        reason: "Don't forbid genuinely good discoveries"

      4_tune_tenure:
        rule: "Tabu tenure affects search behavior"
        short: "More intensification (local focus)"
        long: "More diversification (explore widely)"

    tabu_list_options:
      solution_based: "Forbid entire solutions"
      move_based: "Forbid specific moves (more common)"
      attribute_based: "Forbid moves with certain attributes"

    anti_patterns:
      - "Tabu tenure too short (still cycles)"
      - "Tabu tenure too long (over-constrained)"
      - "No aspiration criteria (miss good solutions)"
      - "Not tracking enough history"

    example:
      context: "Graph coloring optimization"
      process:
        step_1:
          current: "Coloring with 5 conflicts"
          neighbors: "Recolor vertex v from red to blue"
          tabu_list: "[]"
          best_move: "v: redâ†’blue, reduces to 3 conflicts"
          action: "Accept, add to tabu"
        step_2:
          current: "3 conflicts"
          tabu_list: "[v: blueâ†’red]"  # reverse is forbidden
          best_move: "w: greenâ†’red, reduces to 2"
          action: "Accept"
        step_5:
          current: "2 conflicts (stuck)"
          all_good_moves: "Tabu"
          action: "Take best tabu move with aspiration"
        final: "0 conflicts found"
      rationale: "Memory prevents cycling back to 5 conflicts"

    source: "Metaheuristics - Tabu Search (Glover)"

  # ----------------------------------------
  # VARIATION 57: BIDIRECTIONAL-SEARCH ORDERING
  # ----------------------------------------
  bidirectional_search:
    id: bidirectional_search_ordering
    name: "Bidirectional-Search Ordering (Meet in the Middle)"
    category: graph_traversal

    philosophy: |
      Search from both start and goal simultaneously, stop when
      they meet. From pathfinding: two smaller searches are faster
      than one big one. If BFS takes O(b^d), two half-depth searches
      take O(2 Ã— b^(d/2)) which is much smaller for large d.

    when_to_use:
      - Know both start and goal states
      - Goal is reversible (can search backward)
      - Large search depth
      - Pathfinding, puzzle solving
      - When unidirectional search is too slow

    key_concepts:
      forward_search: "From start toward goal"
      backward_search: "From goal toward start"
      frontier: "Current boundary of each search"
      meeting: "When frontiers intersect"
      path_reconstruction: "Combine forward + backward paths"

    algorithm:
      initialize:
        forward: "Start from initial state"
        backward: "Start from goal state"
      loop:
        1_expand_forward: "One step of forward search"
        2_check_meeting: "Does forward frontier intersect backward?"
        3_expand_backward: "One step of backward search"
        4_check_meeting: "Does backward frontier intersect forward?"
      when_meet: "Reconstruct path through meeting point"

    prioritization_rules:
      1_alternate_directions:
        rule: "Expand forward and backward alternately"
        variant: "Or expand smaller frontier first"

      2_check_intersection:
        rule: "After each expansion, check for meeting"
        method: "Hash table lookup of other frontier"

      3_ensure_optimality:
        rule: "Don't stop at first meeting (might not be shortest)"
        correct: "Continue until shortest guaranteed"

      4_reconstruct_path:
        rule: "Combine forward path + backward path at meeting"
        output: "Complete path from start to goal"

    complexity_improvement:
      unidirectional: "O(b^d) nodes"
      bidirectional: "O(2 Ã— b^(d/2)) nodes"
      example: "b=10, d=10: 10B vs 200K nodes"

    requirements:
      reversible_goal: "Can generate predecessors of goal"
      single_goal: "Or small number of goals"
      hash_table: "To detect frontier intersection"

    anti_patterns:
      - "Goal not reversible (can't search backward)"
      - "Multiple/abstract goals (no clear backward search)"
      - "Forgetting to check optimality at meeting"
      - "When depth is small (overhead not worth it)"

    example:
      context: "Finding path between two cities on map"
      setup:
        start: "New York"
        goal: "Los Angeles"
        edge_count: "Thousands of roads"
      bidirectional:
        forward_frontier: "NY â†’ cities 1 hop away"
        backward_frontier: "LA â†’ cities 1 hop away"
        expand_alternately: "Each grows toward other"
        meeting: "Frontiers meet in Kansas City"
      path: "NY â†’ ... â†’ Kansas City â†’ ... â†’ LA"
      savings: "Explored 10% of nodes compared to unidirectional"

    source: "AI/Pathfinding - Bidirectional Search"

  # ----------------------------------------
  # VARIATION 58: UNIFORM-COST ORDERING
  # ----------------------------------------
  uniform_cost:
    id: uniform_cost_ordering
    name: "Uniform-Cost Ordering (Dijkstra's Algorithm)"
    category: queue_scheduling

    philosophy: |
      Always expand the node with lowest path cost so far.
      From shortest path: like BFS but for weighted graphs.
      Guarantees optimal path when all edges have non-negative
      costs. Uses priority queue ordered by g(n) - cost from
      start to node n.

    when_to_use:
      - Weighted graphs with non-negative costs
      - Need optimal (lowest cost) path
      - No heuristic available (or don't trust it)
      - Road networks, network routing
      - When A* heuristic is hard to design

    key_concepts:
      g_n: "Cost from start to node n"
      priority_queue: "Ordered by g(n), lowest first"
      relaxation: "Update cost if better path found"
      optimal: "First time goal is popped, path is optimal"

    algorithm:
      initialize: "g(start)=0, all others=âˆž, PQ=[start]"
      loop:
        1_extract_min: "Pop node with lowest g"
        2_goal_test: "If goal, return path (optimal)"
        3_expand: "For each neighbor"
        4_relax: "If g(current) + edge < g(neighbor), update"
        5_add_to_pq: "Add/update neighbor in priority queue"
      return: "Path when goal popped"

    prioritization_rules:
      1_cost_priority:
        rule: "Always expand lowest g(n) node"
        mechanism: "Priority queue (min-heap)"

      2_relax_edges:
        rule: "Update g(n) if better path found"
        formula: "g(n) = min(g(n), g(parent) + cost(parent, n))"

      3_goal_at_extraction:
        rule: "Test for goal when popping, not when adding"
        reason: "Might find shorter path later"

      4_never_re_expand:
        rule: "Once expanded, node's cost is final"
        precondition: "Only true for non-negative edges"

    comparison:
      vs_bfs: "BFS for unweighted, UCS for weighted"
      vs_a_star: "A* adds heuristic h(n) to guide search"
      vs_dijkstra: "Same algorithm, different presentation"

    anti_patterns:
      - "Using with negative edge weights (use Bellman-Ford)"
      - "Not using priority queue (inefficient)"
      - "Testing goal at insertion (suboptimal)"
      - "Re-expanding settled nodes (wasteful)"

    example:
      context: "Finding cheapest flight route"
      graph:
        "NYCâ†’Chicago": "$150"
        "NYCâ†’Denver": "$300"
        "Chicagoâ†’Denver": "$100"
        "Chicagoâ†’LA": "$250"
        "Denverâ†’LA": "$150"
      uniform_cost_search:
        step_1: "Start NYC, g=0"
        step_2: "Expand NYC: Chicago(150), Denver(300)"
        step_3: "Pop Chicago(150), expand: Denver(250), LA(400)"
        step_4: "Pop Denver(250), expand: LA(400) - no update"
        step_5: "Pop LA(400) - GOAL REACHED"
      optimal_path: "NYC â†’ Chicago â†’ LA, cost $400"
      note: "NYCâ†’Denverâ†’LA = $450, correctly rejected"

    source: "Graph Algorithms - Dijkstra's Algorithm, Uniform Cost Search"

  # ========================================
  # EXPLORATION PROCEDURE ORDERINGS
  # From: Multi-armed Bandits, RL, Quality-Diversity
  # Variations 59-68
  # ========================================

  # ----------------------------------------
  # VARIATION 59: EPSILON-GREEDY ORDERING
  # ----------------------------------------
  epsilon_greedy:
    id: epsilon_greedy_ordering
    name: "Epsilon-Greedy Ordering"
    category: bandit_exploration

    philosophy: |
      With probability Îµ explore randomly, with probability 1-Îµ
      exploit best known option. From reinforcement learning:
      simplest exploration strategy that guarantees eventual
      discovery of all options while primarily using current best.
      Îµ decays over time as confidence increases.

    when_to_use:
      - Need guaranteed exploration of all options
      - Have reasonable estimate of best action
      - Want simple, tunable exploration
      - Early stages of learning new domain
      - A/B testing, feature experiments

    key_concepts:
      epsilon: "Probability of random exploration (0 to 1)"
      exploitation: "Choose best known option (1-Îµ probability)"
      exploration: "Choose random option (Îµ probability)"
      decay: "Decrease Îµ over time as learning progresses"

    prioritization_rules:
      1_roll_random:
        rule: "Generate random number 0-1"
        determines: "Explore or exploit this decision"

      2_if_explore:
        rule: "If rand < Îµ, select random option"
        reason: "Guaranteed to try all options eventually"

      3_if_exploit:
        rule: "If rand >= Îµ, select best known option"
        reason: "Use accumulated knowledge"

      4_decay_epsilon:
        rule: "Decrease Îµ over time"
        schedule: "Îµ(t) = Îµâ‚€ / (1 + t/decay_rate)"
        reason: "Less exploration needed as confidence grows"

    variants:
      fixed_epsilon: "Îµ stays constant throughout"
      linear_decay: "Îµ decreases linearly to minimum"
      exponential_decay: "Îµ = Îµâ‚€ * decay^t"
      adaptive: "Adjust Îµ based on reward variance"

    anti_patterns:
      - "Îµ = 0 (no exploration, stuck in local optimum)"
      - "Îµ = 1 (pure random, no learning)"
      - "Never decaying Îµ (over-exploring when confident)"
      - "Treating all non-best options as equal"

    example:
      context: "Testing marketing strategies"
      strategies: ["Email A", "Email B", "Email C", "Email D"]
      epsilon: 0.2
      iterations:
        iter_1: "Roll 0.15 < 0.2, explore: random pick Email C"
        iter_2: "Roll 0.85 > 0.2, exploit: best known (Email A)"
        iter_3: "Roll 0.05 < 0.2, explore: random pick Email D"
        iter_4: "Roll 0.92 > 0.2, exploit: best known (Email A)"
      result: "80% best option, 20% random discovery"
      rationale: "Simple balance of learning and earning"

    source: "RL Exploration - Epsilon-Greedy (Sutton & Barto)"

  # ----------------------------------------
  # VARIATION 60: THOMPSON SAMPLING ORDERING
  # ----------------------------------------
  thompson_sampling:
    id: thompson_sampling_ordering
    name: "Thompson Sampling Ordering (Probability Matching)"
    category: bandit_exploration

    philosophy: |
      Sample from posterior belief about each option's quality,
      then choose the option whose sample is highest. From Bayesian
      bandits: naturally balances exploration-exploitation by
      exploring uncertain options proportionally to their probability
      of being optimal. Elegant, efficient, and often optimal.

    when_to_use:
      - Can model uncertainty as probability distribution
      - Want principled exploration-exploitation balance
      - Rewards are stochastic
      - Sequential decision making with learning
      - A/B testing, clinical trials, ad selection

    key_concepts:
      posterior: "Updated belief after observing outcomes"
      sampling: "Draw random value from each option's posterior"
      probability_matching: "Select proportional to optimality probability"
      beta_distribution: "Common prior for binary rewards"

    algorithm:
      for_each_option:
        - "Maintain posterior distribution over true reward"
        - "Sample Î¸áµ¢ from posterior for option i"
      select: "Choose option with highest sampled Î¸áµ¢"
      update: "Observe reward, update posterior via Bayes rule"

    prioritization_rules:
      1_maintain_posteriors:
        rule: "Track belief distribution for each option"
        example: "Beta(Î±, Î²) where Î±=successes+1, Î²=failures+1"

      2_sample_from_each:
        rule: "Draw one sample from each posterior"
        effect: "Uncertain options have high variance samples"

      3_select_max_sample:
        rule: "Choose option with highest sampled value"
        property: "Natural probability matching"

      4_update_posterior:
        rule: "After observing outcome, update via Bayes"
        formula: "Posterior âˆ Likelihood Ã— Prior"

    comparison:
      vs_epsilon_greedy: "More principled, adapts exploration automatically"
      vs_ucb: "Similar performance, different philosophy"
      vs_softmax: "Better theoretical guarantees"

    anti_patterns:
      - "Using point estimates instead of sampling"
      - "Not updating posteriors properly"
      - "Wrong prior distribution for reward type"
      - "Insufficient samples from posterior"

    example:
      context: "Choosing which feature to build next"
      options:
        feature_A: "Beta(8, 2) - 80% success rate estimate"
        feature_B: "Beta(2, 2) - 50% but very uncertain"
        feature_C: "Beta(5, 5) - 50% moderately confident"
      samples:
        sample_A: "Draw from Beta(8,2) â†’ 0.72"
        sample_B: "Draw from Beta(2,2) â†’ 0.81 (lucky draw!)"
        sample_C: "Draw from Beta(5,5) â†’ 0.55"
      decision: "Build Feature B (highest sample)"
      insight: "Uncertain options naturally get explored"
      rationale: "Explore uncertain options proportional to their promise"

    source: "Bayesian Bandits - Thompson Sampling (Thompson 1933)"

  # ----------------------------------------
  # VARIATION 61: SOFTMAX BOLTZMANN ORDERING
  # ----------------------------------------
  softmax_boltzmann:
    id: softmax_boltzmann_ordering
    name: "Softmax/Boltzmann Ordering (Temperature-Based)"
    category: bandit_exploration

    philosophy: |
      Convert value estimates to selection probabilities using
      softmax with temperature parameter. From statistical mechanics:
      high temperature = uniform random, low temperature = greedy.
      Allows graded preferences where better options are more likely
      but not guaranteed. Smooth exploration-exploitation tradeoff.

    when_to_use:
      - Have value estimates for each option
      - Want graded preferences, not all-or-nothing
      - Need tunable exploration via temperature
      - Options have similar values
      - Prefer smooth probability distribution

    key_concepts:
      temperature: "Controls exploration (Tâ†’âˆž uniform, Tâ†’0 greedy)"
      softmax: "P(a) = exp(Q(a)/T) / Î£exp(Q(i)/T)"
      annealing: "Decrease temperature over time"
      action_values: "Q(a) = estimated value of action a"

    algorithm:
      for_each_option:
        - "Calculate Q(a) - estimated value"
        - "Compute exp(Q(a)/T)"
      normalize: "Divide each by sum to get probabilities"
      sample: "Select action according to probability distribution"

    prioritization_rules:
      1_compute_values:
        rule: "Estimate Q(a) for each option"
        method: "Running average, learned estimate, etc."

      2_apply_temperature:
        rule: "Divide values by temperature T"
        effect: "T high = flatten differences, T low = exaggerate"

      3_softmax_to_probabilities:
        rule: "exp(Q/T) / Î£exp(Qáµ¢/T)"
        property: "Higher values get higher probability"

      4_sample_action:
        rule: "Draw from resulting distribution"
        effect: "Better options more likely, not guaranteed"

    temperature_effects:
      T_very_high: "Near uniform random (pure exploration)"
      T_moderate: "Probability proportional to quality"
      T_low: "Strong preference for best option"
      T_zero: "Pure greedy (no exploration)"

    comparison:
      vs_epsilon_greedy: "Smoother, considers all values"
      vs_thompson: "Less principled but simpler"
      vs_ucb: "Stochastic vs deterministic"

    anti_patterns:
      - "Fixed temperature (should anneal)"
      - "Temperature too high (pure random)"
      - "Temperature too low too fast (premature convergence)"
      - "Not normalizing probabilities"

    example:
      context: "Selecting tasks to work on"
      task_values:
        task_A: "Q = 8.0 (high estimated value)"
        task_B: "Q = 6.0 (medium value)"
        task_C: "Q = 4.0 (lower value)"
      temperature: 2.0
      calculation:
        exp_A: "exp(8/2) = exp(4) = 54.6"
        exp_B: "exp(6/2) = exp(3) = 20.1"
        exp_C: "exp(4/2) = exp(2) = 7.4"
        sum: "82.1"
      probabilities:
        P_A: "54.6/82.1 = 66.5%"
        P_B: "20.1/82.1 = 24.5%"
        P_C: "7.4/82.1 = 9.0%"
      rationale: "Graded exploration proportional to value"

    source: "Statistical Mechanics - Boltzmann Distribution, RL Softmax"

  # ----------------------------------------
  # VARIATION 62: CURIOSITY-DRIVEN ORDERING
  # ----------------------------------------
  curiosity_driven:
    id: curiosity_driven_ordering
    name: "Curiosity-Driven Ordering (Intrinsic Motivation)"
    category: learning_discovery

    philosophy: |
      Prioritize tasks that maximize information gain or prediction
      error - things that surprise you teach you the most. From
      developmental robotics: agents with intrinsic curiosity explore
      efficiently without external rewards. Learning progress itself
      is the reward. Explore what you don't yet understand.

    when_to_use:
      - Sparse or no external rewards
      - Learning is the goal, not just task completion
      - Need to discover unknown unknowns
      - Environment has rich, learnable structure
      - Autonomous exploration without guidance

    key_concepts:
      prediction_error: "Difference between expected and actual outcome"
      information_gain: "Reduction in uncertainty from observation"
      learning_progress: "Rate of improvement in predictions"
      intrinsic_reward: "Self-generated reward for discovery"

    algorithm:
      for_each_option:
        - "Predict outcome if option is chosen"
        - "Estimate prediction error or information gain"
      select: "Choose option with highest curiosity signal"
      execute: "Take action, observe actual outcome"
      update: "Improve predictive model with new data"

    prioritization_rules:
      1_predict_outcomes:
        rule: "For each option, predict what will happen"
        model: "Forward model, world model, etc."

      2_estimate_curiosity:
        rule: "Calculate prediction error or uncertainty"
        options:
          prediction_error: "||predicted - actual||"
          uncertainty: "Variance in prediction"
          learning_progress: "Î”(prediction accuracy)"

      3_select_most_curious:
        rule: "Choose option maximizing curiosity signal"
        property: "Automatically explores unknown areas"

      4_avoid_noise:
        rule: "Distinguish learnable from random"
        problem: "TV static has high error but no learning"

    variants:
      prediction_error: "Raw error as curiosity"
      learning_progress: "Improvement rate as curiosity"
      information_gain: "Bayesian surprise"
      empowerment: "Maximize influence on environment"

    anti_patterns:
      - "Seeking pure noise (unlearnable randomness)"
      - "Ignoring diminishing returns on familiar areas"
      - "No mechanism to exploit what's learned"
      - "Curiosity about irrelevant features"

    example:
      context: "Exploring a new codebase"
      areas:
        authentication: "Prediction error: 0.2 (well understood)"
        database_layer: "Prediction error: 0.8 (mysterious)"
        api_routes: "Prediction error: 0.5 (partially known)"
        config: "Prediction error: 0.1 (simple, understood)"
      curiosity_ranking:
        1: "database_layer (highest uncertainty)"
        2: "api_routes (moderate uncertainty)"
        3: "authentication (low uncertainty)"
        4: "config (understood)"
      decision: "Start exploring database_layer"
      rationale: "Learn most where prediction error is highest"

    source: "Developmental Robotics - Intrinsic Motivation (Schmidhuber, Oudeyer)"

  # ----------------------------------------
  # VARIATION 63: NOVELTY SEARCH ORDERING
  # ----------------------------------------
  novelty_search:
    id: novelty_search_ordering
    name: "Novelty Search Ordering (Behavioral Diversity)"
    category: diversity_search

    philosophy: |
      Completely ignore the objective. Instead, prioritize behaviors
      that are different from what you've done before. From evolutionary
      computation: paradoxically, ignoring fitness can find solutions
      faster by avoiding deceptive local optima. Diversity drives
      discovery. The stepping stones to great solutions are often
      not themselves great solutions.

    when_to_use:
      - Objective is deceptive (local optima everywhere)
      - Don't know what good solutions look like
      - Want to explore solution space thoroughly
      - Creative exploration, idea generation
      - The path to the goal is indirect

    key_concepts:
      behavior_characterization: "Description of what solution does"
      novelty_metric: "Distance from previously seen behaviors"
      archive: "Collection of diverse behaviors found"
      stepping_stones: "Solutions that enable finding better ones"

    algorithm:
      for_each_candidate:
        - "Characterize its behavior (not its fitness)"
        - "Compute distance to all archived behaviors"
        - "Novelty = average distance to k-nearest"
      select: "Choose most novel behavior"
      archive: "Add to archive if sufficiently novel"

    prioritization_rules:
      1_characterize_behavior:
        rule: "Describe what the solution does, not how good it is"
        example: "Robot: end position, path shape, interactions"

      2_compute_novelty:
        rule: "Distance to k-nearest neighbors in archive"
        metric: "Euclidean in behavior space"

      3_select_most_novel:
        rule: "Prioritize behaviors unlike any seen before"
        property: "Explores entire behavior space"

      4_maintain_archive:
        rule: "Store diverse behaviors for comparison"
        pruning: "Keep sparsely distributed samples"

    comparison:
      vs_fitness: "Ignores objective entirely"
      vs_curiosity: "Novelty in behavior space, not prediction error"
      vs_random: "Structured diversity, not random"

    anti_patterns:
      - "Using fitness as novelty metric (defeats purpose)"
      - "Behavior space too high-dimensional"
      - "Archive too small (limited diversity reference)"
      - "Never exploiting discovered solutions"

    example:
      context: "Exploring business model options"
      archive: ["subscription SaaS", "marketplace", "freemium"]
      candidates:
        consulting: "Behavior: high-touch, time-based pricing"
        enterprise_SaaS: "Behavior: similar to archived subscription"
        hardware_product: "Behavior: physical, manufacturing"
        data_licensing: "Behavior: B2B, usage-based"
      novelty_scores:
        consulting: "7.5 (very different from archive)"
        enterprise_SaaS: "2.1 (similar to subscription)"
        hardware: "8.2 (completely different)"
        data_licensing: "6.8 (moderately different)"
      ranking: "hardware > consulting > data_licensing > enterprise_SaaS"
      rationale: "Explore radically different options first"

    source: "Evolutionary Computation - Novelty Search (Lehman & Stanley)"

  # ----------------------------------------
  # VARIATION 64: GO-EXPLORE ORDERING
  # ----------------------------------------
  go_explore:
    id: go_explore_ordering
    name: "Go-Explore Ordering (Return-then-Explore)"
    category: diversity_search

    philosophy: |
      Remember promising states, return to them deterministically,
      then explore from there. From hard-exploration RL: solves
      detachment problem where agents forget promising frontiers.
      First go back to interesting areas, then explore. Archive
      serves as explicit memory of exploration frontier.

    when_to_use:
      - Exploration frontier is easily forgotten
      - Can return to previous states cheaply
      - Sparse rewards, hard exploration
      - Long horizons with many dead ends
      - Need systematic coverage of state space

    key_concepts:
      archive: "Memory of interesting states visited"
      cell: "Discretized state representation"
      return_phase: "Go back to archived state (no exploration)"
      explore_phase: "Random exploration from that state"
      detachment: "Problem of forgetting promising frontiers"

    algorithm:
      archive_step:
        - "Discretize states into cells"
        - "Store first/best trajectory to each cell"
      return_phase:
        - "Select promising cell from archive"
        - "Replay trajectory to return to that state"
      explore_phase:
        - "From returned state, explore randomly"
        - "If new cell found, add to archive"

    prioritization_rules:
      1_maintain_archive:
        rule: "Store trajectory to each unique cell"
        update: "Replace if new trajectory is shorter/better"

      2_select_promising_cell:
        rule: "Choose cell for exploration"
        criteria: "Novelty, recency, potential"

      3_return_deterministically:
        rule: "Go back to cell without exploring"
        method: "Replay stored trajectory"

      4_explore_from_frontier:
        rule: "Random actions from returned state"
        goal: "Discover adjacent cells"

    comparison:
      vs_curiosity: "Explicit memory vs learned model"
      vs_random: "Systematic frontier coverage"
      vs_novelty_search: "State-based vs behavior-based"

    anti_patterns:
      - "No archive (just like random exploration)"
      - "Can't return to states (need determinism or reset)"
      - "Archive too coarse (miss important states)"
      - "Never pruning archive (memory explodes)"

    example:
      context: "Exploring a complex configuration space"
      archive:
        cell_1: "Base config - 5 steps to reach"
        cell_2: "Optimized memory - 12 steps"
        cell_3: "Parallel mode - 8 steps"
        cell_4: "GPU enabled - 15 steps"
      iteration:
        select: "Cell 4 (GPU) - least explored neighbors"
        return: "Replay 15 steps to reach GPU config"
        explore: "Try random config changes from there"
        discover: "Found Cell 5: GPU + distributed"
        archive: "Add Cell 5 with 18-step trajectory"
      rationale: "Systematically expand from promising frontiers"

    source: "Hard-Exploration RL - Go-Explore (Uber AI, Ecoffet et al. 2019)"

  # ----------------------------------------
  # VARIATION 65: MAP-ELITES ORDERING
  # ----------------------------------------
  map_elites:
    id: map_elites_ordering
    name: "MAP-Elites Ordering (Quality-Diversity Illumination)"
    category: diversity_search

    philosophy: |
      Fill a map of behavior space with the best solution at each
      point. From quality-diversity: don't just find one optimum,
      illuminate the entire space of possibilities. Return a diverse
      archive of high-quality solutions. The map reveals how
      performance varies across behavioral dimensions.

    when_to_use:
      - Want diverse high-quality solutions, not just one
      - Can define meaningful behavioral dimensions
      - Need to understand solution landscape
      - Building repertoire of options
      - Seeking robust coverage of possibilities

    key_concepts:
      behavior_descriptor: "Dimensions defining solution types"
      cell: "Region in behavior space"
      elite: "Best solution found for that cell"
      qd_score: "Sum of fitness across all cells"
      illumination: "Revealing performance across space"

    algorithm:
      initialize: "Random solutions, place in map by behavior"
      iterate:
        - "Select random elite from map"
        - "Mutate to create offspring"
        - "Evaluate offspring fitness and behavior"
        - "Place in appropriate cell if better than current elite"
      result: "Map of diverse high-quality solutions"

    prioritization_rules:
      1_define_behavior_space:
        rule: "Choose meaningful dimensions (2-10)"
        example: "Robot locomotion: speed Ã— stability"

      2_discretize_into_cells:
        rule: "Grid the behavior space"
        tradeoff: "Fine grid = more diversity, slower fill"

      3_compete_within_cells:
        rule: "Only compare solutions in same cell"
        effect: "Local competition preserves diversity"

      4_maximize_qd_score:
        rule: "Goal: fill map with high-quality solutions"
        metric: "Î£ fitness of all elites"

    variants:
      cvt_map_elites: "Centroidal Voronoi tessellation instead of grid"
      deep_grid: "Hierarchical behavior discretization"
      cma_me: "CMA-ES for offspring generation"

    anti_patterns:
      - "Behavior dimensions not meaningful"
      - "Grid too coarse (lose diversity)"
      - "Grid too fine (never fill map)"
      - "Ignoring quality (just novelty search)"

    example:
      context: "Exploring API design options"
      behavior_dimensions:
        x_axis: "Number of endpoints (1-20)"
        y_axis: "Authentication complexity (1-5)"
      map_cells:
        "(5, 2)": "5 endpoints, simple auth - fitness: 0.8"
        "(10, 3)": "10 endpoints, moderate auth - fitness: 0.75"
        "(3, 1)": "3 endpoints, no auth - fitness: 0.6"
        "(15, 4)": "15 endpoints, complex auth - fitness: 0.7"
      result: "Portfolio of API designs, each best in its niche"
      use: "Pick design matching deployment context"
      rationale: "Illuminate trade-off space with best options"

    source: "Quality-Diversity - MAP-Elites (Mouret & Clune 2015)"

  # ----------------------------------------
  # VARIATION 66: LEVY FLIGHT ORDERING
  # ----------------------------------------
  levy_flight:
    id: levy_flight_ordering
    name: "LÃ©vy Flight Ordering (Heavy-Tailed Exploration)"
    category: diversity_search

    philosophy: |
      Explore locally most of the time, but occasionally take very
      long jumps to distant areas. From optimal foraging: LÃ©vy
      flights are mathematically optimal for finding sparse,
      randomly distributed targets. Many small steps + rare big
      leaps beats uniform random walk or pure local search.

    when_to_use:
      - Targets are sparse and randomly distributed
      - Local search gets stuck
      - Don't know where good solutions are
      - Need to balance thorough local search with global jumps
      - Foraging, search, optimization in unknown landscapes

    key_concepts:
      power_law: "Step length ~ x^(-Î¼), Î¼ â‰ˆ 2 optimal"
      heavy_tail: "Occasional very long steps"
      superdiffusion: "Spreads faster than random walk"
      scale_free: "Same pattern at all scales"

    algorithm:
      at_each_step:
        - "Draw step length from power-law distribution"
        - "Draw random direction"
        - "Move by that vector"
        - "Evaluate new position"
      distribution: "P(step = L) âˆ L^(-Î¼)"

    prioritization_rules:
      1_sample_step_length:
        rule: "Draw from power-law: L ~ U^(-1/(Î¼-1))"
        effect: "Most steps small, some very large"

      2_sample_direction:
        rule: "Uniform random direction"
        property: "Isotropic exploration"

      3_move_and_evaluate:
        rule: "Take step, evaluate fitness at new location"
        update: "Remember best found"

      4_tune_exponent:
        rule: "Î¼ â‰ˆ 2 often optimal"
        range: "1 < Î¼ â‰¤ 3 for valid LÃ©vy flights"

    comparison:
      vs_brownian: "Brownian is diffusive, LÃ©vy is superdiffusive"
      vs_random_restart: "LÃ©vy jumps are probabilistic, not scheduled"
      vs_local_search: "LÃ©vy escapes local optima via long jumps"

    anti_patterns:
      - "Targets densely clustered (Brownian better)"
      - "Î¼ too small (nearly ballistic, overshoots)"
      - "Î¼ too large (degrades to Brownian)"
      - "Ignoring found solutions (no exploitation)"

    example:
      context: "Exploring hyperparameter space"
      current_position: "learning_rate=0.01, batch_size=32"
      levy_steps:
        step_1: "L=0.002 (small): lr=0.012, batch=33"
        step_2: "L=0.001 (small): lr=0.011, batch=34"
        step_3: "L=0.05 (large!): lr=0.001, batch=128"
        step_4: "L=0.003 (small): lr=0.002, batch=125"
      pattern: "Mostly local refinement, occasional big jumps"
      rationale: "Efficiently cover sparse solution landscape"

    source: "Optimal Foraging Theory - LÃ©vy Flight Hypothesis"

  # ----------------------------------------
  # VARIATION 67: UCB EXPLORATION ORDERING
  # ----------------------------------------
  ucb_exploration:
    id: ucb_exploration_ordering
    name: "UCB Exploration Ordering (Optimism Under Uncertainty)"
    category: bandit_exploration

    philosophy: |
      Choose the option with highest upper confidence bound on
      its value: estimated value + exploration bonus. From bandits:
      be optimistic about uncertain options - they might be great.
      Options tried fewer times get higher bonus. Automatically
      balances exploration and exploitation with theoretical guarantees.

    when_to_use:
      - Can estimate confidence intervals
      - Want regret guarantees
      - Options have been tried different amounts
      - Need principled exploration without randomness
      - Deterministic action selection preferred

    key_concepts:
      ucb: "UCB(a) = Q(a) + câˆš(ln(t)/n(a))"
      exploration_bonus: "Decreases as option is tried more"
      optimism: "Assume uncertain options are good until proven otherwise"
      regret_bound: "O(âˆš(KT ln T)) for K arms, T rounds"

    algorithm:
      for_each_option:
        - "Calculate mean reward estimate Q(a)"
        - "Calculate exploration bonus câˆš(ln(t)/n(a))"
        - "UCB(a) = Q(a) + bonus"
      select: "Choose option with highest UCB"
      update: "Observe reward, update Q(a) and n(a)"

    prioritization_rules:
      1_compute_mean_estimate:
        rule: "Q(a) = average reward from option a"
        update: "Incremental: Q â† Q + (r - Q)/n"

      2_compute_exploration_bonus:
        rule: "Bonus = câˆš(ln(t)/n(a))"
        property: "High for rarely-tried options"

      3_select_max_ucb:
        rule: "Choose argmax UCB(a)"
        effect: "Optimistic about uncertain options"

      4_tune_exploration_constant:
        rule: "c controls exploration-exploitation trade-off"
        typical: "c = âˆš2 for UCB1"

    variants:
      ucb1: "Original, c = âˆš2"
      ucb_tuned: "Uses variance estimate"
      klucb: "Kullback-Leibler based bounds"
      bayesian_ucb: "Uses posterior for intervals"

    anti_patterns:
      - "c too low (under-explore)"
      - "c too high (over-explore, slow convergence)"
      - "Not updating counts/estimates"
      - "Using with non-stationary rewards without windowing"

    example:
      context: "Selecting which approach to try"
      options:
        approach_A: "Tried 100x, mean=0.7, UCB=0.7+0.1=0.80"
        approach_B: "Tried 10x, mean=0.6, UCB=0.6+0.4=1.00"
        approach_C: "Tried 50x, mean=0.75, UCB=0.75+0.15=0.90"
      selection: "Approach B (highest UCB despite lower mean)"
      reason: "Uncertainty bonus outweighs lower estimate"
      next_round: "After trying B, its UCB will decrease"
      rationale: "Be optimistic about things you haven't tried much"

    source: "Multi-Armed Bandits - UCB (Auer et al. 2002)"

  # ----------------------------------------
  # VARIATION 68: QUALITY-DIVERSITY ORDERING
  # ----------------------------------------
  quality_diversity:
    id: quality_diversity_ordering
    name: "Quality-Diversity Ordering (NSLC/QD Balance)"
    category: diversity_search

    philosophy: |
      Optimize for both quality AND behavioral diversity simultaneously.
      From QD algorithms: local competition only among similar
      solutions preserves diversity while still improving quality.
      Don't sacrifice diversity for fitness or vice versa.
      The result is a repertoire of diverse, high-quality solutions.

    when_to_use:
      - Need multiple good solutions, not just one
      - Solutions serve different purposes/contexts
      - Want robust portfolio of options
      - Diversity has intrinsic value
      - Building repertoire for deployment

    key_concepts:
      local_competition: "Only compete with behaviorally similar"
      niche: "Region of behavior space"
      pareto: "Trade-off between quality and diversity"
      repertoire: "Archive of diverse high-quality solutions"

    algorithm:
      evaluate_each_candidate:
        - "Measure fitness (quality)"
        - "Measure behavior descriptor (diversity)"
        - "Find its behavioral niche"
      local_tournament:
        - "Compare only with others in same niche"
        - "Keep best in each niche"
      archive: "Maintain diverse repertoire"

    prioritization_rules:
      1_dual_objectives:
        rule: "Consider both fitness and novelty"
        balance: "Neither dominates completely"

      2_local_competition:
        rule: "Solutions only compete within their niche"
        effect: "Preserves diverse niches"

      3_novelty_for_exploration:
        rule: "Novelty drives discovery of new niches"
        method: "Distance to k-nearest in archive"

      4_fitness_for_quality:
        rule: "Fitness ensures each niche has good solution"
        method: "Standard fitness evaluation"

    variants:
      nslc: "Novelty Search with Local Competition"
      qd_score: "Optimize sum of fitness across niches"
      multi_objective_qd: "Pareto front per niche"

    comparison:
      vs_pure_novelty: "QD also optimizes fitness within niches"
      vs_pure_fitness: "QD maintains diversity across niches"
      vs_map_elites: "NSLC uses continuous space, MAP-Elites uses grid"

    anti_patterns:
      - "Niche size too large (lose diversity)"
      - "Niche size too small (fragment population)"
      - "Ignoring fitness (pure novelty)"
      - "Ignoring novelty (premature convergence)"

    example:
      context: "Developing product line strategy"
      candidates:
        product_A: "Fitness=0.9, niche=enterprise"
        product_B: "Fitness=0.85, niche=enterprise"
        product_C: "Fitness=0.7, niche=SMB"
        product_D: "Fitness=0.8, niche=consumer"
      local_competition:
        enterprise_niche: "A beats B (0.9 > 0.85)"
        smb_niche: "C is only candidate (keeps)"
        consumer_niche: "D is only candidate (keeps)"
      repertoire: "[A, C, D] - best in each niche"
      rationale: "Diverse portfolio of best-in-class for each market"

    source: "Quality-Diversity - NSLC, QD Algorithms (Lehman & Stanley, Mouret)"

  # ----------------------------------------
  # VARIATION 69: SONATA-FORM ORDERING
  # ----------------------------------------
  sonata_form:
    id: sonata_form_ordering
    name: "Sonata-Form Ordering (Exposition-Development-Recapitulation)"
    category: music_composition_performance

    philosophy: |
      Structure work in three movements: introduce themes clearly (exposition),
      explore and transform them through conflict (development), then resolve
      by returning to original themes with new understanding (recapitulation).
      From classical music: this form creates satisfying narrative arc through
      tension and resolution. The recapitulation isn't mere repetition - it's
      the same material transformed by the journey.

    when_to_use:
      - Complex projects that benefit from thematic coherence
      - Presentations or documents that need narrative arc
      - Problem-solving where initial understanding must evolve
      - Teaching where concepts are introduced, challenged, then reinforced
      - Strategic planning with vision, exploration, and synthesis phases

    key_concepts:
      exposition: "State main themes clearly - what are we working with?"
      bridge_transition: "Connect themes, set up development"
      development: "Transform, conflict, explore implications"
      retransition: "Signal return to home key"
      recapitulation: "Return to themes, now understood differently"
      coda: "Final conclusive material"

    algorithm:
      exposition_phase:
        - "State primary theme (main idea/approach)"
        - "Transition to secondary theme (contrasting idea)"
        - "Present secondary theme (alternative perspective)"
        - "Closing section summarizes both themes"
      development_phase:
        - "Fragment themes into smaller motifs"
        - "Explore different keys (contexts/applications)"
        - "Create tension through transformation"
        - "Build to climax of complexity/conflict"
      recapitulation_phase:
        - "Return to primary theme (now evolved)"
        - "Secondary theme appears in home key (unified)"
        - "Synthesize learnings into coherent whole"
        - "Coda provides definitive closure"

    prioritization_rules:
      1_establish_themes:
        rule: "State core ideas clearly before exploring"
        reason: "Audience needs to know what will be developed"

      2_create_contrast:
        rule: "Secondary theme should contrast with primary"
        reason: "Dialectic tension drives development"

      3_develop_through_transformation:
        rule: "Middle section transforms, doesn't just repeat"
        reason: "Development creates depth and insight"

      4_return_transformed:
        rule: "Recapitulation shows themes in new light"
        reason: "The journey must change the material"

    variants:
      sonata_allegro: "Standard fast movement form"
      sonatina: "Shortened form, lighter development"
      sonata_rondo: "Combines sonata with rondo elements"
      double_exposition: "Two expositions (concerto form)"

    comparison:
      vs_linear: "Sonata returns to beginning, linear doesn't"
      vs_tension_arc: "More structured thematic development"
      vs_build_measure_learn: "Emphasizes thematic coherence over iteration"

    anti_patterns:
      - "Development that loses connection to themes"
      - "Recapitulation that's mere repetition"
      - "Skipping development (rushed resolution)"
      - "Too many themes (loses coherence)"

    example:
      context: "Strategic planning presentation"
      sonata_structure:
        exposition:
          primary_theme: "Our vision: become market leader in X"
          transition: "But the landscape is changing..."
          secondary_theme: "Competitor disruption threatens position"
          closing: "We need both growth AND defense"
        development:
          fragmentation: "Break down each threat and opportunity"
          modulation: "Explore scenarios in different markets"
          climax: "Key decision point: invest or retreat"
        recapitulation:
          primary_return: "Vision reaffirmed with specific strategy"
          secondary_resolved: "Competitive response integrated"
          coda: "Clear action items and timeline"
      rationale: "Themes introduced, explored through conflict, resolved"

    source: "Classical Music Form - Sonata-Allegro (Haydn, Mozart, Beethoven)"

  # ----------------------------------------
  # VARIATION 70: THEME-AND-VARIATIONS ORDERING
  # ----------------------------------------
  theme_and_variations:
    id: theme_and_variations_ordering
    name: "Theme-and-Variations Ordering (Core + Elaborations)"
    category: music_composition_performance

    philosophy: |
      Present a clear theme, then systematically explore variations that
      preserve the essence while transforming surface features. From music:
      the theme remains recognizable through rhythm, melody, harmony, or
      texture changes. Each variation reveals new aspects of the theme.
      This creates both unity (same theme) and diversity (different treatments).

    when_to_use:
      - Teaching a concept through multiple examples
      - Exploring one idea from many angles
      - Building product variations from core platform
      - Documentation with progressive complexity
      - Brainstorming that explores a central concept

    key_concepts:
      theme: "The core idea/pattern to be varied"
      variation: "Transformation that preserves essential identity"
      parameter: "What aspect changes (tempo, key, texture, etc.)"
      progressive_difficulty: "Variations often increase in complexity"
      finale: "Often returns to theme or synthesizes variations"

    algorithm:
      state_theme:
        - "Present core idea in clearest form"
        - "Ensure theme is memorable and well-defined"
      create_variations:
        - "Identify parameters to vary (tempo, style, context)"
        - "Design each variation to highlight theme differently"
        - "Sequence from simpler to more elaborate"
        - "Maintain recognizable connection to theme"
      conclude:
        - "Return to original theme (transformed by journey)"
        - "Or synthesize insights from all variations"

    prioritization_rules:
      1_theme_first:
        rule: "Establish core idea before any variation"
        reason: "Variations only meaningful relative to theme"

      2_preserve_identity:
        rule: "Each variation must be recognizable as 'about' the theme"
        reason: "Coherence comes from thematic unity"

      3_vary_systematically:
        rule: "Choose variation parameters deliberately"
        examples: "Context, scale, audience, constraints, style"

      4_progressive_complexity:
        rule: "Often increase elaboration through variations"
        reason: "Builds understanding and engagement"

      5_meaningful_return:
        rule: "End by illuminating theme from new perspective"
        reason: "Journey should create insight"

    variants:
      strict_variations: "Each variation uses same structure"
      free_variations: "More departures allowed"
      character_variations: "Each variation has distinct personality"
      double_variations: "Two themes, alternating variations"

    comparison:
      vs_scaffolded: "Theme-variations varies perspective, scaffolded adds complexity"
      vs_breadth_first: "Theme-variations has central focus, BFS explores equally"
      vs_sonata_form: "Theme-variations is more modular, less developmental conflict"

    anti_patterns:
      - "Variations that lose connection to theme"
      - "Theme unclear, making variations confusing"
      - "All variations too similar (no insight gained)"
      - "All variations too different (no coherence)"

    example:
      context: "Teaching API design principles"
      theme: "Design for the consumer, not the implementation"
      variations:
        var_1_naming: "Naming: use consumer vocabulary, not internal terms"
        var_2_errors: "Errors: return what consumers need, not stack traces"
        var_3_pagination: "Pagination: cursor-based for consumer use cases"
        var_4_versioning: "Versioning: stability for consumer, not your convenience"
        var_5_docs: "Documentation: consumer journeys, not endpoint lists"
      finale: "Return to theme - all decisions serve consumer"
      rationale: "Same principle, many applications - deepens understanding"

    source: "Classical Music Form - Theme and Variations (Bach, Brahms)"

  # ----------------------------------------
  # VARIATION 71: FUGUE-CONSTRUCTION ORDERING
  # ----------------------------------------
  fugue_construction:
    id: fugue_construction_ordering
    name: "Fugue-Construction Ordering (Subject-Answer-Countersubject)"
    category: music_composition_performance

    philosophy: |
      Introduce a subject, have other voices answer it, then weave them
      together in increasingly complex counterpoint. From baroque music:
      fugue creates richness through imitation and combination. Each voice
      has integrity while contributing to the whole. The magic happens
      when independent voices combine harmoniously.

    when_to_use:
      - Multi-stakeholder projects where each voice matters
      - Building systems with interacting independent components
      - Discussions that need to weave multiple perspectives
      - Team projects where parallel work must combine
      - Complex arguments with multiple supporting threads

    key_concepts:
      subject: "The main melodic idea, stated alone first"
      answer: "Subject restated by another voice (often in dominant key)"
      countersubject: "Companion melody that works with both"
      episode: "Transitional material connecting statements"
      stretto: "Overlapping entries, increasing intensity"
      pedal_point: "Sustained note while others move (creates resolution)"

    algorithm:
      exposition:
        - "State subject in first voice alone"
        - "Second voice answers while first adds countersubject"
        - "Third voice states subject while others continue"
        - "All voices established with distinct material"
      episodes:
        - "Develop fragments of subject/countersubject"
        - "Modulate to different keys (contexts)"
        - "Build complexity through combination"
      development:
        - "Subject in new keys (applications)"
        - "Inversion, augmentation, diminution of subject"
        - "Stretto: entries overlap, intensity builds"
      conclusion:
        - "Return to home key"
        - "Pedal point grounds the resolution"
        - "All voices synthesize in final statement"

    prioritization_rules:
      1_subject_alone_first:
        rule: "Main idea presented clearly before responses"
        reason: "Subject must be understood before combined"

      2_answer_builds:
        rule: "Each new voice adds to, doesn't replace"
        reason: "Polyphonic texture requires independence"

      3_countersubject_harmony:
        rule: "Secondary material must work with primary"
        reason: "Voices combine, must be compatible"

      4_stretto_for_climax:
        rule: "Compress entries for emotional peak"
        reason: "Overlapping creates intensity"

      5_ground_to_resolve:
        rule: "Pedal point or clear tonic ends the work"
        reason: "Complexity needs resolution"

    variants:
      double_fugue: "Two subjects, eventually combined"
      triple_fugue: "Three subjects woven together"
      fughetta: "Short, simplified fugue"
      choral_fugue: "Fugue sections in larger work"

    comparison:
      vs_parallel_maximizing: "Fugue weaves voices, parallel runs independently"
      vs_convergence_timing: "Fugue builds texture, convergence synchronizes"
      vs_divide_conquer: "Fugue combines voices, D&C splits then merges"

    anti_patterns:
      - "Voices that don't actually work together"
      - "Subject unclear, answers don't cohere"
      - "Homophonic collapse (one voice dominates)"
      - "No resolution (complexity without synthesis)"

    example:
      context: "Multi-team product development"
      fugue_structure:
        exposition:
          subject: "Engineering defines core architecture"
          answer: "Design responds with UI patterns that fit"
          countersubject: "Product adds user story framework"
        episodes:
          - "Explore how architecture serves different features"
          - "Modulate to different user segments"
        development:
          inversion: "User needs reshape architecture"
          stretto: "Multiple teams iterate rapidly together"
        conclusion:
          pedal: "Core principles ground the synthesis"
          final_statement: "Unified product vision from all voices"
      rationale: "Each team has voice; magic is in the combination"

    source: "Baroque Music Form - Fugue (J.S. Bach, Art of Fugue)"

  # ----------------------------------------
  # VARIATION 72: RONDO-FORM ORDERING
  # ----------------------------------------
  rondo_form:
    id: rondo_form_ordering
    name: "Rondo-Form Ordering (ABACA Pattern)"
    category: music_composition_performance

    philosophy: |
      Return repeatedly to a main theme (refrain) between contrasting
      episodes (couplets). From classical music: the rondo creates comfort
      through repetition of the familiar refrain, while couplets provide
      variety and exploration. The refrain is home base - you always return.

    when_to_use:
      - Presentations needing recurring key message
      - Multi-topic content with unifying theme
      - Training with practice-return-practice cycles
      - Projects with core deliverable and extensions
      - Communication that needs message reinforcement

    key_concepts:
      refrain_A: "Main theme, returns multiple times"
      couplet_B: "First contrasting episode"
      couplet_C: "Second contrasting episode (different from B)"
      return: "Refrain may vary slightly on each return"
      closure: "Final refrain often extended or elaborated"

    algorithm:
      simple_rondo_ABACA:
        - "A: State main theme/message"
        - "B: First contrasting topic"
        - "A: Return to main theme"
        - "C: Second contrasting topic"
        - "A: Final return, possibly elaborated"
      sonata_rondo_ABACABA:
        - "Larger form with more returns"
        - "B returns in home key later"

    prioritization_rules:
      1_strong_refrain:
        rule: "Main theme must be memorable and clear"
        reason: "Returns only effective if refrain is known"

      2_contrasting_episodes:
        rule: "Couplets should genuinely differ from refrain"
        reason: "Contrast makes returns satisfying"

      3_varied_returns:
        rule: "Refrain can evolve slightly on each return"
        reason: "Prevents tedium while maintaining recognition"

      4_decisive_final_return:
        rule: "Last statement of refrain provides closure"
        reason: "End on home base, resolved"

    variants:
      simple_rondo: "ABACA"
      five_part_rondo: "ABACABA"
      sonata_rondo: "Combines rondo with sonata development"
      ritornello: "Baroque ancestor of rondo"

    comparison:
      vs_theme_variations: "Rondo returns to same, variations transform"
      vs_inverted_pyramid: "Rondo reinforces, pyramid front-loads"
      vs_tension_arc: "Rondo punctuates, tension builds continuously"

    anti_patterns:
      - "Refrain too weak to anchor returns"
      - "Episodes too similar to refrain (no contrast)"
      - "Refrain unchanged (becomes tedious)"
      - "Too many couplets before returning"

    example:
      context: "All-hands company meeting"
      rondo_structure:
        A1_main_message: "Our priority this quarter: customer retention"
        B_financials: "Q3 results - revenue and growth numbers"
        A2_reinforce: "Remember: retention drives those numbers"
        C_product: "New features launching for retention"
        A3_call_to_action: "Your role in retention - specific asks"
      rationale: "Key message reinforced through returns, context in episodes"

    source: "Classical Music Form - Rondo (Mozart, Beethoven)"

  # ----------------------------------------
  # VARIATION 73: CALL-AND-RESPONSE ORDERING
  # ----------------------------------------
  call_and_response:
    id: call_and_response_ordering
    name: "Call-and-Response Ordering (Antiphonal Pattern)"
    category: music_composition_performance

    philosophy: |
      Alternate between a statement (call) and a reply (response) in a
      back-and-forth pattern. From African music and work songs: call
      and response creates engagement through participation. The response
      might echo, answer, complete, or contrast with the call. This pattern
      builds rhythm, community, and incremental progress.

    when_to_use:
      - Collaborative work requiring frequent check-ins
      - Teaching with immediate practice/feedback cycles
      - Writing dialogue or Q&A content
      - Review processes with proposal and critique
      - Iterative design with create and test cycles

    key_concepts:
      call: "Initial statement, question, or assertion"
      response: "Reply that relates to the call"
      leader_chorus: "One voice calls, many respond"
      echo: "Response repeats call"
      answer: "Response completes or contrasts call"
      overlap: "Response may begin before call ends"

    algorithm:
      basic_pattern:
        - "Leader states call"
        - "Responder(s) provide response"
        - "New call builds on previous exchange"
        - "Pattern continues, building momentum"
      variations:
        echo: "Response repeats call exactly"
        completion: "Response finishes call's thought"
        contrast: "Response provides counterpoint"
        elaboration: "Response extends call's idea"

    prioritization_rules:
      1_clear_call:
        rule: "Call must be distinct and complete enough to answer"
        reason: "Unclear calls get confused responses"

      2_meaningful_response:
        rule: "Response must relate to call, not ignore it"
        reason: "The pattern creates dialogue, not monologue"

      3_build_momentum:
        rule: "Each exchange should advance toward goal"
        reason: "Not just alternation, but progress"

      4_appropriate_timing:
        rule: "Response follows quickly enough to maintain rhythm"
        reason: "Delayed responses break the pattern's energy"

    variants:
      echo_response: "Response repeats call"
      antiphonal: "Two groups alternate"
      cumulative: "Each response adds to previous"
      question_answer: "Call asks, response answers"

    comparison:
      vs_build_measure_learn: "C&R is faster cycle, BML is full experiments"
      vs_fugue: "C&R alternates, fugue weaves simultaneously"
      vs_round_robin: "C&R has call-response structure, round robin is just turns"

    anti_patterns:
      - "Calls that can't be responded to"
      - "Responses that ignore the call"
      - "Breaking rhythm with long delays"
      - "No progression (just repetitive alternation)"

    example:
      context: "Code review process"
      call_and_response:
        call_1: "Developer: Here's my implementation of feature X"
        response_1: "Reviewer: Edge case Y isn't handled"
        call_2: "Developer: Added handling, what about Z?"
        response_2: "Reviewer: Z looks good, but performance concern"
        call_3: "Developer: Optimized, ready for final review"
        response_3: "Reviewer: Approved - ship it"
      rationale: "Each exchange advances toward completion"

    source: "African Music Tradition - Call and Response / Work Songs"

  # ----------------------------------------
  # VARIATION 74: CRESCENDO-BUILDING ORDERING
  # ----------------------------------------
  crescendo_building:
    id: crescendo_building_ordering
    name: "Crescendo-Building Ordering (Gradual Intensification)"
    category: music_composition_performance

    philosophy: |
      Start quietly and build gradually toward maximum intensity. From
      music dynamics: crescendo creates anticipation and emotional impact
      through patient accumulation. The power comes from the trajectory,
      not just the peak. Rushed crescendos lack impact; well-paced ones
      are irresistible.

    when_to_use:
      - Building toward major announcement or reveal
      - Persuasive arguments that need momentum
      - Training that builds to difficult challenges
      - Campaigns building to launch
      - Any presentation requiring emotional climax

    key_concepts:
      piano: "Starting state - soft, small, simple"
      crescendo: "Gradual increase in intensity"
      fortissimo: "Maximum intensity point"
      diminuendo: "Controlled decrease after peak"
      dynamics: "The full range from soft to loud"

    algorithm:
      build_phase:
        - "Start understated (lower than audience expects)"
        - "Add elements incrementally"
        - "Increase pace, intensity, stakes gradually"
        - "Each step noticeably more than previous"
      peak_phase:
        - "Hit maximum intensity at planned moment"
        - "Peak must feel like natural culmination"
        - "Don't overshoot or peak prematurely"
      resolution:
        - "Controlled diminuendo if needed"
        - "Or end at peak for maximum impact"

    prioritization_rules:
      1_patient_start:
        rule: "Begin lower than you think necessary"
        reason: "Need room to build; starting high leaves nowhere to go"

      2_gradual_increase:
        rule: "Each step incrementally more intense"
        reason: "Jumps feel unearned; gradual feels inevitable"

      3_pace_acceleration:
        rule: "Steps can come faster as you approach peak"
        reason: "Accelerando adds to building tension"

      4_calculated_peak:
        rule: "Know exactly where and when to hit fortissimo"
        reason: "Premature or late peaks lose impact"

      5_controlled_after:
        rule: "What follows peak must be intentional"
        reason: "Abrupt stops or rambling diminish effect"

    variants:
      subito_piano: "Sudden drop to quiet for contrast"
      terraced_dynamics: "Step increases (baroque style)"
      multiple_crescendos: "Build, release, build higher"
      sforzando_accent: "Sudden emphatic moments within crescendo"

    comparison:
      vs_tension_arc: "Crescendo is specifically about intensity/volume"
      vs_peak_targeting: "Crescendo is the method, peak is the destination"
      vs_momentum: "Momentum starts strong, crescendo starts soft"

    anti_patterns:
      - "Starting too loud (nowhere to build)"
      - "Uneven pacing (stops and starts)"
      - "Premature peak (deflates rest)"
      - "No peak (endless building exhausts audience)"
      - "Peak too late (audience already checked out)"

    example:
      context: "Product launch presentation"
      crescendo_structure:
        piano:
          - "Start with simple, relatable problem"
          - "Quiet, conversational tone"
        build:
          - "Reveal market size (slightly louder)"
          - "Show customer pain points (building)"
          - "Demonstrate failed solutions (tension)"
          - "Hint at your approach (anticipation)"
        crescendo:
          - "Faster reveals of features"
          - "Customer testimonials"
          - "Key metrics and traction"
        fortissimo:
          - "THE BIG REVEAL - major announcement"
          - "Maximum energy, visual impact"
        diminuendo:
          - "Clear call to action"
          - "Q&A or next steps"
      rationale: "Audience carried by building momentum to peak"

    source: "Musical Dynamics - Crescendo/Decrescendo (Orchestral Tradition)"

  # ----------------------------------------
  # VARIATION 75: CONCERT-SETLIST ORDERING
  # ----------------------------------------
  concert_setlist:
    id: concert_setlist_ordering
    name: "Concert-Setlist Ordering (Performance Arc Design)"
    category: music_composition_performance

    philosophy: |
      Design sequence like a concert setlist: open strong to grab attention,
      vary energy to prevent fatigue, build to climactic moment, close
      memorably. From live performance: audiences need variety, peaks,
      and emotional journey. Front-load strong material, save best for
      last, and pace the valleys. The encore is earned, not assumed.

    when_to_use:
      - Planning full-day workshops or conferences
      - Sequencing product features for demo
      - Organizing portfolio or content collection
      - Any extended experience requiring sustained engagement
      - Events with multiple segments or speakers

    key_concepts:
      opener: "Strong start to hook audience"
      deep_cut: "Less familiar material for engaged fans"
      crowd_favorite: "Known hits that energize"
      ballad: "Slower moment for contrast and rest"
      build_to_closer: "Sequence leading to climax"
      encore: "Apparent end, then return with impact"

    algorithm:
      opening_block:
        - "Start with energy to grab attention"
        - "Second slot can be slightly riskier"
        - "Establish that this will be good"
      middle_block:
        - "Mix familiar and new material"
        - "Vary tempo and energy"
        - "Include rest moments (ballads)"
        - "Keep engagement through variety"
      closing_block:
        - "Build energy toward main set closer"
        - "Biggest crowd-pleasers near end"
        - "Main set ends on high note"
      encore_optional:
        - "Brief pause (let audience call for more)"
        - "Return with signature material"
        - "Final song leaves lasting impression"

    prioritization_rules:
      1_strong_opener:
        rule: "Don't bury strong material in middle"
        reason: "Must earn audience attention immediately"

      2_energy_management:
        rule: "Vary intensity to prevent fatigue"
        reason: "Constant high energy exhausts; constant low bores"

      3_strategic_placement:
        rule: "Save genuinely best for encore/close"
        reason: "Recency effect - what's last is remembered"

      4_rest_before_push:
        rule: "Slower number before final build"
        reason: "Contrast makes the peak more powerful"

      5_earned_encore:
        rule: "Main set must satisfy; encore is bonus"
        reason: "Encore after weak set feels manipulative"

    variants:
      festival_set: "Shorter, higher energy, no deep cuts"
      acoustic_set: "Stripped down, intimate pacing"
      greatest_hits: "All crowd favorites, minimal risk"
      album_play: "Sequential, as intended order"

    comparison:
      vs_energy_envelope: "Setlist is more about selection and variety"
      vs_crescendo: "Setlist has multiple peaks, not just one build"
      vs_rondo: "Setlist doesn't necessarily return to same opener"

    anti_patterns:
      - "Opening with obscure material"
      - "All high energy (exhausting)"
      - "All slow material (boring)"
      - "Best material in middle (forgotten)"
      - "Weak closer (bad last impression)"
      - "Encore better than main set (set was too cautious)"

    example:
      context: "Full-day training workshop"
      setlist_structure:
        opener: "Interactive exercise - high energy, immediate engagement"
        slot_2: "Core concept 1 - substantial but accessible"
        slot_3: "Hands-on practice - keep energy up"
        mid_morning_ballad: "Reflective Q&A - lower intensity rest"
        pre_lunch: "Challenging concept - they're alert"
        post_lunch: "Activity - fight the food coma"
        afternoon: "Mix of teaching and practice"
        build_to_close: "Capstone project - bringing it together"
        closer: "Key takeaways with energy"
        encore: "Surprise bonus content for those who stayed engaged"
      rationale: "Audience can't sustain 8 hours at same intensity"

    source: "Live Music Performance - Concert/Tour Planning"

  # ========================================
  # MILITARY TACTICS & STRATEGY VARIATIONS
  # ========================================

  # ----------------------------------------
  # VARIATION 76: OODA LOOP ORDERING
  # ----------------------------------------
  ooda_loop:
    id: ooda_loop_ordering
    name: "OODA Loop Ordering (Observe-Orient-Decide-Act)"
    category: military_strategy

    philosophy: |
      Cycle rapidly through Observe-Orient-Decide-Act loops, faster than
      the environment or adversary can adapt. From John Boyd's fighter
      pilot theory: victory goes to whoever completes decision cycles
      fastest. The Orient phase is critical - it's where mental models
      are updated and mismatches with reality are corrected. Speed of
      iteration beats quality of any single iteration.

    when_to_use:
      - Competitive or adversarial situations
      - Rapidly changing environments
      - Need to maintain initiative
      - Information is incomplete but time-sensitive
      - Want to disrupt opponent's decision making

    key_concepts:
      observe: "Gather raw information from environment"
      orient: "Analyze, synthesize, update mental models"
      decide: "Select course of action from alternatives"
      act: "Execute the decision"
      tempo: "Speed of cycling through the loop"
      inside_loop: "Completing cycles faster than adversary"

    algorithm:
      continuous_loop:
        - "OBSERVE: Gather current state information"
        - "ORIENT: Update mental model, analyze implications"
        - "DECIDE: Choose next action from options"
        - "ACT: Execute quickly, don't over-plan"
        - "REPEAT: Immediately begin next cycle"
      key_principle: "Orient is the schwerpunkt - most important phase"

    prioritization_rules:
      1_observe_first:
        rule: "Always start with fresh observation"
        reason: "Acting on stale information leads to poor decisions"

      2_orient_deeply:
        rule: "Invest most effort in orientation/analysis"
        reason: "This is where competitive advantage is built"

      3_decide_quickly:
        rule: "Make good-enough decisions fast"
        reason: "Perfect decisions too late are worthless"

      4_act_immediately:
        rule: "Execute without hesitation once decided"
        reason: "Delay erodes the value of the decision"

      5_maximize_tempo:
        rule: "Complete cycles faster than environment changes"
        reason: "Faster cycles = staying ahead of the situation"

    variants:
      single_loop: "One person cycling through OODA"
      nested_loops: "Multiple loops at different time scales"
      team_ooda: "Distributed sensing, centralized orientation"
      implicit_guidance: "Experienced practitioners skip explicit decide"

    comparison:
      vs_waterfall: "OODA is continuous, waterfall is sequential"
      vs_pdca: "OODA emphasizes speed and competition"
      vs_agile: "OODA includes adversarial/competitive framing"

    anti_patterns:
      - "Skipping observation (acting on assumptions)"
      - "Shallow orientation (not updating mental models)"
      - "Analysis paralysis in decide phase"
      - "Slow action (losing tempo advantage)"
      - "Not closing the loop (no feedback from action)"

    example:
      context: "Startup responding to competitor announcement"
      ooda_cycle:
        observe: "Competitor announced new feature targeting our users"
        orient: |
          - Analyze: What does this mean for our position?
          - Synthesize: Their feature is superficial, ours is deeper
          - Update model: Market wants speed, not depth initially
        decide: "Ship stripped-down version in 2 weeks, iterate after"
        act: "Mobilize team, cut scope, ship fast"
        next_cycle: "Begin observing customer reaction immediately"
      tempo: "2-week cycles vs competitor's 3-month cycles"
      rationale: "Faster decision cycles let us adapt while they're committed"

    source: "Military Strategy - Boyd's OODA Loop (John Boyd, 1976)"

  # ----------------------------------------
  # VARIATION 77: SCHWERPUNKT ORDERING
  # ----------------------------------------
  schwerpunkt:
    id: schwerpunkt_ordering
    name: "Schwerpunkt Ordering (Main Effort Focus)"
    category: military_strategy

    philosophy: |
      Identify the decisive point and concentrate overwhelming effort there.
      From German military doctrine: schwerpunkt (focus of effort) is where
      you mass resources to achieve breakthrough. Everything else is secondary
      or economy of force. Success at the schwerpunkt creates cascading
      effects that make other problems irrelevant.

    when_to_use:
      - Resources are limited relative to total requirements
      - One area determines overall success or failure
      - Need decisive breakthrough rather than incremental progress
      - Multiple fronts competing for attention
      - Want to avoid spreading too thin

    key_concepts:
      schwerpunkt: "The decisive point requiring concentration"
      hauptangriff: "Main attack/effort"
      nebenangriff: "Supporting/secondary effort"
      economy_of_force: "Minimum necessary elsewhere"
      breakthrough: "Decisive success at the focal point"
      exploitation: "Following up breakthrough success"

    algorithm:
      identify_schwerpunkt:
        - "Analyze situation for decisive point"
        - "Where would breakthrough change everything?"
        - "What are competitors/obstacles weakest at?"
      concentrate:
        - "Mass majority of resources at schwerpunkt"
        - "Accept risk elsewhere"
        - "Maintain minimum viable coverage of other areas"
      execute:
        - "Achieve breakthrough at focal point"
        - "Exploit success rapidly"
        - "Don't dilute by reinforcing secondary efforts"

    prioritization_rules:
      1_identify_decisive_point:
        rule: "Find where success would be transformative"
        question: "If we win here, does everything else become easier?"

      2_concentrate_resources:
        rule: "Put 70%+ of effort on schwerpunkt"
        reason: "Superiority at one point beats mediocrity everywhere"

      3_accept_risk_elsewhere:
        rule: "Deliberately under-resource secondary areas"
        reason: "Cannot be strong everywhere - accept trade-offs"

      4_exploit_breakthrough:
        rule: "When schwerpunkt succeeds, pour through the gap"
        reason: "Victory is amplified by rapid exploitation"

      5_shift_schwerpunkt_if_needed:
        rule: "If breakthrough elsewhere, shift focus"
        reason: "Schwerpunkt follows opportunity"

    comparison:
      vs_balanced_approach: "Schwerpunkt deliberately unbalances"
      vs_portfolio: "Portfolio spreads bets, schwerpunkt concentrates"
      vs_iteration: "Schwerpunkt seeks decisive outcome, not incremental"

    anti_patterns:
      - "Spreading resources evenly (peanut butter strategy)"
      - "Multiple schwerpunkte (contradiction in terms)"
      - "Reinforcing secondary efforts at expense of main"
      - "Not exploiting breakthrough success"
      - "Schwerpunkt on wrong point (fatal error)"

    example:
      context: "Startup with limited runway competing against incumbents"
      analysis:
        possible_fronts: ["Feature parity", "Price", "Specific niche", "Support quality"]
        schwerpunkt_selection: "Specific niche where incumbents are weakest"
      resource_allocation:
        schwerpunkt: "80% of engineering on niche-specific features"
        economy_of_force: "20% on minimum viable for other areas"
      execution:
        breakthrough: "Become clearly best choice for target niche"
        exploitation: "Use niche dominance to expand adjacently"
      rationale: "Can't beat big players everywhere; dominate one point first"

    source: "Military Strategy - German Schwerpunkt Doctrine (19th-20th c.)"

  # ----------------------------------------
  # VARIATION 78: AUFTRAGSTAKTIK ORDERING
  # ----------------------------------------
  auftragstaktik:
    id: auftragstaktik_ordering
    name: "Auftragstaktik Ordering (Mission Tactics / Commander's Intent)"
    category: military_strategy

    philosophy: |
      Define the intent and desired end-state, then let executors determine
      how to achieve it. From German mission command: tell subordinates what
      to accomplish and why, not how. Local decision-makers have better
      information about their situation. Initiative and adaptation are more
      valuable than central coordination. Trust replaces detailed orders.

    when_to_use:
      - Distributed execution with local variability
      - Situation is complex and evolving
      - Central planning can't anticipate all conditions
      - Want to encourage initiative and ownership
      - Communication bandwidth is limited

    key_concepts:
      commanders_intent: "Desired end-state and purpose (the why)"
      freedom_of_action: "Autonomy in how to achieve intent"
      two_levels_up: "Understand purpose 2 levels above your own"
      initiative: "Act on opportunities without waiting for orders"
      einheit: "Unity of effort despite decentralized execution"

    algorithm:
      communicate_intent:
        - "State desired end-state clearly"
        - "Explain purpose and context (the why)"
        - "Specify boundaries and constraints"
        - "Define what success looks like"
      empower_execution:
        - "Let executors decide specific actions"
        - "Don't micromanage or over-specify"
        - "Trust local judgment within boundaries"
      enable_adaptation:
        - "Executors adapt to local conditions"
        - "Seize opportunities aligned with intent"
        - "Report back, but don't wait for permission"

    prioritization_rules:
      1_define_intent_first:
        rule: "Clarify end-state before any detailed planning"
        reason: "Intent guides all subsequent decisions"

      2_provide_context:
        rule: "Explain why this intent matters (two levels up)"
        reason: "Enables intelligent adaptation to situations"

      3_specify_boundaries:
        rule: "Define what must NOT happen (constraints)"
        reason: "Freedom within limits, not unlimited freedom"

      4_trust_execution:
        rule: "Don't prescribe methods; judge by results"
        reason: "Local knowledge beats central planning"

      5_reward_initiative:
        rule: "Celebrate adaptive action within intent"
        reason: "Encourages future initiative"

    variants:
      pure_auftragstaktik: "Only intent, no specified methods"
      bounded_auftragstaktik: "Intent + constraints + available resources"
      nested_intent: "Each level interprets and passes down intent"

    comparison:
      vs_befehlstaktik: "Auftragstaktik is intent, befehlstaktik is detailed orders"
      vs_micromanagement: "Polar opposite - macro intent vs micro control"
      vs_agile: "Similar to agile product vision guiding sprint decisions"

    anti_patterns:
      - "Specifying how (defeats the purpose)"
      - "Intent so vague it provides no guidance"
      - "Not providing enough context (two levels up)"
      - "Punishing initiative that fails"
      - "Changing intent frequently (destroys trust)"

    example:
      context: "Product team building new customer feature"
      commanders_intent:
        end_state: "Customers can self-serve account changes without support tickets"
        purpose: "Reduce support load 40% and improve customer satisfaction"
        constraints: ["Must maintain audit trail", "Cannot expose sensitive data", "Ship within Q2"]
        success_criteria: "Support tickets for account changes drop 40%"
      execution:
        team_autonomy: "Team decides UI, architecture, rollout approach"
        adaptation: "Team discovers billing changes are 60% of tickets, focuses there"
        initiative: "Team adds self-serve feature not originally planned but aligned with intent"
      rationale: "Team closest to problem knows best how to solve it"

    source: "Military Strategy - Prussian/German Auftragstaktik (19th c.)"

  # ----------------------------------------
  # VARIATION 79: ECONOMY OF FORCE ORDERING
  # ----------------------------------------
  economy_of_force:
    id: economy_of_force_ordering
    name: "Economy of Force Ordering (Minimum Necessary Allocation)"
    category: military_strategy

    philosophy: |
      Allocate minimum necessary resources to secondary efforts, preserving
      maximum for the main effort. From military doctrine: no part of the
      force should be left without purpose, but not every objective deserves
      equal resources. Accept calculated risk in less critical areas. The art
      is determining what minimum viable effort is for non-critical tasks.

    when_to_use:
      - Resources insufficient for all objectives
      - Must maintain presence in multiple areas
      - Some objectives are clearly more important
      - Need to free resources for concentration elsewhere
      - Accepting risk in exchange for opportunity

    key_concepts:
      minimum_necessary: "Least resources to maintain position"
      calculated_risk: "Deliberate acceptance of risk in secondary areas"
      force_preservation: "Don't waste resources on unimportant objectives"
      holding_action: "Maintain without advancing"
      shaping_operation: "Secondary effort that enables main effort"

    algorithm:
      categorize_objectives:
        - "Identify main effort (schwerpunkt)"
        - "Identify supporting efforts (enable main)"
        - "Identify holding tasks (maintain, don't advance)"
        - "Identify potential abandonment (truly unimportant)"
      allocate_minimum:
        - "For holding tasks: what's minimum to maintain?"
        - "For supporting: what's needed to enable main effort?"
        - "Remainder concentrates on main effort"
      accept_risk:
        - "Explicitly document what might fail"
        - "Plan for degraded performance in secondary areas"
        - "Have contingencies if risks materialize"

    prioritization_rules:
      1_categorize_all_tasks:
        rule: "Every task is main, supporting, holding, or abandon"
        reason: "Can't economize without categorization"

      2_question_holding_tasks:
        rule: "What's the minimum that actually maintains position?"
        trap: "Tendency to over-resource 'just in case'"

      3_supporting_enables_main:
        rule: "Supporting tasks sized to enable, not excel"
        reason: "Supporting excellence doesn't help if main fails"

      4_document_accepted_risk:
        rule: "Explicitly state what might fail due to economy"
        reason: "Conscious risk-taking, not negligent under-resourcing"

      5_no_orphan_resources:
        rule: "Every resource must have purpose"
        reason: "Idle resources are wasted resources"

    comparison:
      vs_balanced_portfolio: "Economy deliberately unbalances"
      vs_schwerpunkt: "Economy is complement - what happens elsewhere"
      vs_triage: "Economy maintains everything; triage abandons"

    anti_patterns:
      - "Even distribution of resources (no economy)"
      - "Under-resourcing main effort"
      - "Economy so severe that holding positions collapse"
      - "Not accepting any risk (defeats purpose)"
      - "Resources sitting idle (no purpose assigned)"

    example:
      context: "Engineering team with 10 engineers, 5 active products"
      categorization:
        main_effort: "New flagship product (determines company future)"
        supporting: "API infrastructure (enables flagship)"
        holding: "Product B and C (mature, maintain only)"
        minimal: "Legacy product D (sunset path)"
      allocation:
        flagship: "5 engineers (50%) - concentrate for breakthrough"
        api_infrastructure: "2 engineers (20%) - enable flagship"
        products_b_c: "2 engineers (20%) - bugs and critical only"
        legacy_d: "1 engineer (10%) - keep running, no features"
      accepted_risk: "Products B and C may lose features to competitors"
      rationale: "Cannot excel at 5 products with 10 engineers; choose where to win"

    source: "Military Strategy - Economy of Force Principle (Clausewitz)"

  # ----------------------------------------
  # VARIATION 80: CONCENTRATION OF FORCE ORDERING
  # ----------------------------------------
  concentration_of_force:
    id: concentration_of_force_ordering
    name: "Concentration of Force Ordering (Lanchester's Laws)"
    category: military_strategy

    philosophy: |
      Achieve local superiority by concentrating forces at decisive points.
      From Lanchester's Laws: in modern combat, fighting power scales with
      the square of numbers. A 2:1 advantage yields 4:1 effectiveness.
      Concentration creates disproportionate advantage. Never engage in fair
      fights - always seek local superiority through concentration.

    when_to_use:
      - Competition follows square law dynamics (winner-take-all)
      - Multiple engagement points with choice of where to fight
      - Concentration is physically/logistically possible
      - Local superiority matters more than broad coverage
      - Can afford to be weak elsewhere

    key_concepts:
      lanchesters_square_law: "Effectiveness proportional to (force) squared"
      local_superiority: "Concentrate to outnumber at engagement point"
      defeat_in_detail: "Attack enemy segments separately before they combine"
      interior_lines: "Central position enables concentration"
      force_multiplier: "Advantages that increase effective strength"

    algorithm:
      analyze_engagement_points:
        - "Where will decisive engagements occur?"
        - "What are relative strengths at each point?"
        - "Can we achieve local superiority somewhere?"
      plan_concentration:
        - "Mass forces at chosen engagement point"
        - "Sequence engagements to concentrate serially"
        - "Avoid dispersed fighting across all points"
      execute_locally:
        - "Achieve decisive local victory"
        - "Exploit before enemy can reconcentrate"
        - "Shift to next engagement point"

    prioritization_rules:
      1_identify_decisive_points:
        rule: "Find where concentrated effort can achieve breakthrough"
        question: "Where does local victory cascade to overall victory?"

      2_mass_for_superiority:
        rule: "Concentrate until you have clear local advantage"
        ratio: "3:1 often cited as attack success threshold"

      3_sequence_engagements:
        rule: "Fight one battle at a time with concentrated force"
        reason: "Serial concentration beats parallel dilution"

      4_defeat_in_detail:
        rule: "Attack enemy segments before they can combine"
        opportunity: "Enemy dispersed = opportunity to concentrate against each"

      5_avoid_fair_fights:
        rule: "Never engage without local superiority"
        reason: "Fair fights are expensive; unfair fights are decisive"

    variants:
      spatial_concentration: "Physical massing at one location"
      temporal_concentration: "Sequential effort at same point"
      capability_concentration: "Mass specific capability vs spread skills"

    comparison:
      vs_distributed: "Concentration opposes distributed/parallel approaches"
      vs_economy_of_force: "Concentration is where resources go; economy is where they don't"
      vs_portfolio: "Concentration bets big; portfolio spreads risk"

    anti_patterns:
      - "Dispersing evenly (guarantees no local superiority)"
      - "Fighting on all fronts simultaneously"
      - "Engaging before concentration achieved"
      - "Not exploiting local victory before enemy reconcentrates"
      - "Concentrating at non-decisive point"

    example:
      context: "Sales team targeting enterprise accounts"
      analysis:
        total_targets: "100 potential enterprise accounts"
        sales_capacity: "10 enterprise reps"
        competitor: "Has 30 reps across same 100 accounts"
      strategy:
        even_distribution: "1 rep per 10 accounts = always outnumbered"
        concentration: "10 reps on 20 highest-value accounts"
      execution:
        wave_1: "All 10 reps saturate top 20 accounts (local 10:6 advantage)"
        wave_2: "After winning wave 1, shift to next 20"
      result: "Win 15 of top 20 vs. even distribution winning 3 of top 20"
      rationale: "Square law dynamics favor concentrated effort"

    source: "Military Strategy - Lanchester's Laws (F.W. Lanchester, 1916)"

  # ----------------------------------------
  # VARIATION 81: INTERIOR LINES ORDERING
  # ----------------------------------------
  interior_lines:
    id: interior_lines_ordering
    name: "Interior Lines Ordering (Central Position Advantage)"
    category: military_strategy

    philosophy: |
      Operate from a central position to engage dispersed opponents
      sequentially. From Napoleonic strategy: interior lines allow faster
      concentration against any single threat. The central force can mass
      against one opponent, defeat them, then turn to face another before
      they can combine. Position enables concentration; concentration enables
      defeat in detail.

    when_to_use:
      - Multiple opponents/challenges that are separated
      - Central position available between them
      - Can move/respond faster than opponents can combine
      - Sequential engagement is feasible
      - Want to fight smaller battles rather than one large one

    key_concepts:
      interior_lines: "Operating between separated opponents"
      exterior_lines: "Opponents encircling the central position"
      defeat_in_detail: "Beat opponents separately before they unite"
      central_position: "Hub from which to concentrate against any spoke"
      movement_advantage: "Shorter distances from center to any point"

    algorithm:
      establish_central_position:
        - "Position resources between threat sources"
        - "Ensure faster response time to any single threat"
        - "Maintain ability to concentrate quickly"
      sequence_engagements:
        - "Identify which opponent to engage first"
        - "Concentrate against them before others can help"
        - "Achieve decisive result, then pivot"
      exploit_position:
        - "Use position advantage to dictate tempo"
        - "Force opponents to react to you, not vice versa"
        - "Prevent opponents from combining"

    prioritization_rules:
      1_secure_central_position:
        rule: "Establish position that enables rapid concentration"
        advantage: "Interior lines = shorter movement to any point"

      2_prevent_combination:
        rule: "Engage before separated opponents can unite"
        danger: "Combined opponents eliminate interior lines advantage"

      3_defeat_weakest_first:
        rule: "Often start with most vulnerable opponent"
        reason: "Quick victory frees resources for next engagement"

      4_defeat_most_dangerous_first:
        rule: "Alternative: neutralize biggest threat first"
        reason: "Reduces risk even if harder"

      5_maintain_tempo:
        rule: "Move fast enough to prevent recombination"
        reason: "Speed preserves interior lines advantage"

    comparison:
      vs_exterior_lines: "Interior is concentrated; exterior is encircling"
      vs_parallel_engagement: "Interior sequences; parallel fights all at once"
      vs_concentration: "Interior lines enable concentration"

    anti_patterns:
      - "Engaging multiple opponents simultaneously (negates advantage)"
      - "Moving too slowly (allows opponent combination)"
      - "Abandoning central position prematurely"
      - "Partial engagement (not defeating before pivoting)"
      - "Central position without movement advantage"

    example:
      context: "Startup facing competitive pressure from two larger players"
      situation:
        competitor_a: "Enterprise-focused, slow to move downmarket"
        competitor_b: "Consumer-focused, slow to move upmarket"
        startup: "Mid-market position between them"
      interior_lines_strategy:
        central_position: "Own mid-market definitively"
        first_engagement: "Expand toward consumer (weaker enterprise competition there)"
        second_engagement: "After consumer win, expand toward enterprise"
      execution:
        phase_1: "Build consumer-friendly features (Competitor A can't follow quickly)"
        phase_2: "After consumer share, add enterprise features (from position of strength)"
      rationale: "Central position lets us engage each competitor where they're weak"

    source: "Military Strategy - Napoleonic Interior Lines (Jomini, Napoleon)"

  # ----------------------------------------
  # VARIATION 82: CULMINATING POINT ORDERING
  # ----------------------------------------
  culminating_point:
    id: culminating_point_ordering
    name: "Culminating Point Ordering (Know When to Stop)"
    category: military_strategy

    philosophy: |
      Every attack reaches a culminating point where the attacker's strength
      is exhausted and further advance becomes dangerous. From Clausewitz:
      the offense weakens as it advances (lengthening supply lines, casualties,
      fatigue) while defense strengthens. Recognize and stop at the culminating
      point; don't overextend into vulnerability. Victory transitions to defense.

    when_to_use:
      - Extended campaigns with finite resources
      - Success creates new vulnerabilities
      - Diminishing returns on continued effort
      - Need to consolidate before advancing further
      - Risk of overextension is real

    key_concepts:
      culminating_point: "Where offensive strength equals defensive task"
      overextension: "Advancing past culminating point = vulnerability"
      strategic_pause: "Stopping to consolidate and regenerate"
      diminishing_force: "Attack strength decreases with advance"
      transition_to_defense: "Winner must defend gains"

    algorithm:
      monitor_offensive_strength:
        - "Track resources consumed vs. remaining"
        - "Monitor supply lines / support infrastructure"
        - "Assess team fatigue and morale"
      recognize_culmination:
        - "Can we still achieve decisive outcomes?"
        - "Are we losing more than gaining?"
        - "Is further advance creating vulnerabilities?"
      transition_appropriately:
        - "Stop at or before culminating point"
        - "Consolidate gains before further advance"
        - "Rebuild strength for next offensive"

    prioritization_rules:
      1_track_offensive_strength:
        rule: "Continuously monitor resources and momentum"
        metrics: "Budget burn rate, team energy, technical debt"

      2_anticipate_culmination:
        rule: "Plan for where culmination will occur"
        reason: "Surprised culmination leads to overextension"

      3_recognize_symptoms:
        rule: "Watch for signs of approaching culmination"
        symptoms: ["Slowing progress", "Rising costs", "Increasing errors", "Team fatigue"]

      4_stop_before_crisis:
        rule: "Stop at culminating point, not past it"
        danger: "Overextension creates vulnerability to counterattack"

      5_consolidate_then_resume:
        rule: "Pause, consolidate gains, rebuild strength"
        reason: "Fresh offense beats exhausted advance"

    variants:
      tactical_culmination: "Single engagement runs out of steam"
      operational_culmination: "Campaign reaches sustainable limit"
      strategic_culmination: "Overall effort needs consolidation"

    comparison:
      vs_momentum: "Culmination warns against endless momentum"
      vs_fail_fast: "Culmination is about stopping success, not failure"
      vs_exploitation: "Exploitation must respect culmination limit"

    anti_patterns:
      - "Ignoring signs of culmination (overextending)"
      - "Stopping too early (before achieving decisive result)"
      - "Not planning for defense after offense"
      - "Confusing tactical pause with strategic retreat"
      - "Continuing offensive out of pride/momentum"

    example:
      context: "Startup rapid growth phase"
      situation:
        growth_offensive: "Tripled headcount, 5x'd customers in 18 months"
        symptoms:
          - "New hire quality declining"
          - "Onboarding failing - people unproductive"
          - "Technical debt accumulating"
          - "Customer support overwhelmed"
          - "Team morale dropping"
      culminating_point_recognition: "Further growth will create more problems than value"
      response:
        stop_hiring: "Pause new headcount"
        consolidate: "Focus on onboarding existing team"
        fix_debt: "Address technical and organizational debt"
        stabilize: "Get support and operations under control"
        resume_growth: "After 6 months consolidation, resume hiring"
      rationale: "Growth past culminating point would have led to implosion"

    source: "Military Strategy - Clausewitz's Culminating Point (On War)"

  # ----------------------------------------
  # VARIATION 83: CENTER OF GRAVITY ORDERING
  # ----------------------------------------
  center_of_gravity:
    id: center_of_gravity_ordering
    name: "Center of Gravity Ordering (Attack the Source of Power)"
    category: military_strategy

    philosophy: |
      Identify and attack the enemy's center of gravity - the source of their
      strength and cohesion. From Clausewitz: the center of gravity is the hub
      of all power and movement, on which everything depends. Attacking it
      directly can collapse the entire system. Conversely, protect your own
      center of gravity. Strategic analysis begins with identifying what
      really matters.

    when_to_use:
      - Need to understand what to attack or defend
      - Complex system with many components
      - Want maximum effect from limited resources
      - Analyzing competitive or adversarial situations
      - Looking for leverage points

    key_concepts:
      center_of_gravity: "Source of power, strength, and will"
      critical_capabilities: "What COG enables the system to do"
      critical_requirements: "What COG needs to function"
      critical_vulnerabilities: "Requirements that can be attacked"
      direct_vs_indirect: "Attack COG directly or through requirements"

    algorithm:
      identify_center_of_gravity:
        - "What is the source of the system's power?"
        - "What would collapse the system if removed?"
        - "What do all capabilities depend on?"
      analyze_critical_factors:
        - "Critical Capabilities: What can COG do?"
        - "Critical Requirements: What does COG need?"
        - "Critical Vulnerabilities: Which requirements are attackable?"
      plan_approach:
        - "Direct: Attack COG itself if accessible"
        - "Indirect: Attack critical requirements"
        - "Defend: Protect your own COG"

    prioritization_rules:
      1_identify_cog_first:
        rule: "Cannot attack effectively without knowing true COG"
        trap: "Attacking symptoms instead of cause"

      2_trace_critical_chain:
        rule: "COG -> Capabilities -> Requirements -> Vulnerabilities"
        method: "Work backward from observed capabilities"

      3_attack_vulnerabilities:
        rule: "Often can't attack COG directly - attack requirements"
        reason: "Vulnerabilities are accessible weaknesses in requirements"

      4_protect_own_cog:
        rule: "Understand and defend your own center of gravity"
        reason: "You're also vulnerable to COG analysis"

      5_verify_correct_cog:
        rule: "Test hypothesis - would destroying this collapse the system?"
        validation: "If system survives, wrong COG identified"

    variants:
      military_cog: "Army, leadership, capital city, alliance"
      business_cog: "Core product, key customers, key people, brand"
      personal_cog: "Time, energy, relationships, skills"

    comparison:
      vs_swot: "COG analysis is deeper, focused on source of power"
      vs_root_cause: "Similar - finding what really matters"
      vs_vital_few: "COG is the most vital of the vital few"

    anti_patterns:
      - "Attacking symptoms instead of center of gravity"
      - "Multiple COGs (by definition there's one primary)"
      - "Confusing critical capability with COG"
      - "Not protecting your own COG"
      - "Static COG analysis (COG can shift)"

    example:
      context: "Competitive analysis for market entry"
      competitor_analysis:
        apparent_strengths: ["Large sales team", "Brand recognition", "Feature set"]
        cog_analysis:
          center_of_gravity: "Exclusive distribution partnerships"
          critical_capability: "Reach customers through trusted channel"
          critical_requirement: "Partners remain exclusive and motivated"
          critical_vulnerability: "Partners frustrated by low margins"
      strategy:
        indirect_attack: "Offer partners better margin to switch allegiance"
        direct_attack: "Build direct channel that bypasses partners"
      own_cog_protection: "Our COG is engineering talent - protect retention"
      rationale: "Attack their source of power, not their surface capabilities"

    source: "Military Strategy - Clausewitz's Center of Gravity (On War)"

  # ----------------------------------------
  # VARIATION 84: PHASES OF OPERATIONS ORDERING
  # ----------------------------------------
  phases_of_operations:
    id: phases_of_operations_ordering
    name: "Phases of Operations Ordering (Shape-Decisive-Sustain)"
    category: military_strategy

    philosophy: |
      Structure campaigns into distinct phases with different objectives and
      methods. From joint military doctrine: operations proceed through Shape
      (set conditions), Decisive (achieve objectives), and Sustain (maintain
      gains) phases. Each phase has different priorities, resource allocations,
      and success criteria. Phase transitions are critical decision points.

    when_to_use:
      - Long campaigns with distinct stages
      - Different phases need different approaches
      - Need clear transition criteria
      - Want to avoid premature transition
      - Building toward decisive moment

    key_concepts:
      phase_0_shape: "Set conditions for success"
      phase_1_deter: "Prevent conflict through positioning"
      phase_2_seize_initiative: "Begin decisive operations"
      phase_3_dominate: "Achieve decisive objectives"
      phase_4_stabilize: "Establish security"
      phase_5_enable: "Transfer to civilian control"
      transition_criteria: "Conditions that trigger phase change"

    algorithm:
      simplified_phases:
        shape: |
          - Build capabilities and relationships
          - Gather intelligence
          - Set conditions for decisive phase
          - Position resources
        decisive: |
          - Execute main effort
          - Achieve breakthrough/decision
          - Apply maximum appropriate force
        sustain: |
          - Consolidate gains
          - Transition to steady state
          - Prevent rollback
      phase_transitions:
        shape_to_decisive: "Conditions set, ready for main effort"
        decisive_to_sustain: "Objectives achieved, need consolidation"

    prioritization_rules:
      1_complete_shaping:
        rule: "Don't start decisive phase until conditions are set"
        reason: "Premature decisive action wastes resources"

      2_recognize_decisive_moment:
        rule: "Know when to transition from shape to decisive"
        criteria: "Conditions favor success, opportunity present"

      3_execute_decisively:
        rule: "In decisive phase, commit fully"
        reason: "Half-measures in decisive phase lead to failure"

      4_transition_to_sustain:
        rule: "Don't continue decisive operations past objectives"
        trap: "Victory can be lost in transition"

      5_sustain_adequately:
        rule: "Commit enough to sustain to prevent rollback"
        common_failure: "Under-resourcing sustain phase"

    variants:
      military_phases: "Full 0-5 phase model"
      business_phases: "Shape (prepare) -> Decisive (launch) -> Sustain (maintain)"
      startup_phases: "Build -> Launch -> Scale -> Sustain"

    comparison:
      vs_waterfall: "Phases are strategic intent, not project management"
      vs_agile: "Phases can contain iterative work within them"
      vs_campaigns: "Phases are divisions within a campaign"

    anti_patterns:
      - "Skipping shape phase (decisive action fails)"
      - "Staying in shape too long (analysis paralysis)"
      - "Premature transition to sustain (decisive incomplete)"
      - "Under-resourcing sustain (gains slip away)"
      - "Not defining transition criteria (phases blur)"

    example:
      context: "Launching new product in competitive market"
      phases:
        shape:
          objectives: ["Build product", "Hire team", "Establish partnerships", "Beta test"]
          duration: "6 months"
          success_criteria: "Product ready, team hired, partners committed"
        decisive:
          objectives: ["Public launch", "Acquire first 1000 customers", "Establish market presence"]
          duration: "3 months"
          success_criteria: "1000 customers, positive unit economics, brand recognized"
        sustain:
          objectives: ["Maintain growth", "Defend against competition", "Optimize operations"]
          duration: "Ongoing"
          success_criteria: "Consistent growth, profitable operations"
      transitions:
        shape_to_decisive: "Product launched publicly"
        decisive_to_sustain: "Initial customer target met, growth engine working"
      rationale: "Different phases need different priorities and resources"

    source: "Military Strategy - Joint Operations Phasing (US Joint Doctrine)"

  # ========================================
  # PROJECT MANAGEMENT ORDERING VARIATIONS
  # ========================================

  # ----------------------------------------
  # VARIATION 85: PERT ORDERING
  # ----------------------------------------
  pert:
    id: pert_ordering
    name: "PERT Ordering (Program Evaluation and Review Technique)"
    category: project_management

    philosophy: |
      Model task durations as probability distributions rather than point
      estimates. From project management: acknowledge uncertainty by using
      three-point estimates (optimistic, most likely, pessimistic) and
      calculate expected durations with standard deviations. Order based
      on probabilistic critical paths, not deterministic ones. Focus
      attention on high-variance activities that pose schedule risk.

    when_to_use:
      - Task durations are uncertain
      - First-time or novel projects
      - Need to estimate completion probability
      - Stakeholders want confidence intervals, not point estimates
      - R&D projects, new product development
      - Government/defense contracts requiring formal planning

    key_concepts:
      three_point_estimate: "O (optimistic), M (most likely), P (pessimistic)"
      expected_duration: "Te = (O + 4M + P) / 6 (beta distribution mean)"
      standard_deviation: "sigma = (P - O) / 6"
      variance: "sigma squared for each activity on critical path"
      project_variance: "Sum of variances on critical path"
      z_score: "For calculating completion probability at target date"

    algorithm:
      estimate_each_task:
        - "Gather three estimates: optimistic, most likely, pessimistic"
        - "Calculate Te = (O + 4M + P) / 6"
        - "Calculate sigma = (P - O) / 6"
      build_network:
        - "Create precedence network with dependencies"
        - "Use expected durations for path calculations"
      find_critical_path:
        - "Calculate ES, EF, LS, LF for each activity"
        - "Critical path has zero slack"
      assess_risk:
        - "Sum variances along critical path"
        - "Calculate probability of meeting target dates"
        - "Identify high-variance activities for attention"

    prioritization_rules:
      1_critical_path_first:
        rule: "Activities on probabilistic critical path get priority"
        reason: "These determine expected project completion"

      2_high_variance_attention:
        rule: "Activities with high sigma need early attention"
        reason: "Reduce uncertainty through early learning"

      3_near_critical_monitoring:
        rule: "Paths within 1-2 sigma of critical need monitoring"
        reason: "May become critical due to variance"

      4_parallel_where_possible:
        rule: "Start parallel activities at earliest start times"
        reason: "Exploit slack to absorb variance"

    variants:
      classic_pert: "Original beta distribution approach"
      pert_cpm_hybrid: "PERT estimates with CPM crashing"
      monte_carlo_pert: "Simulation-based probability assessment"
      generalized_pert: "Different distributions per activity"

    comparison:
      vs_cpm: "PERT handles uncertainty, CPM uses point estimates"
      vs_ccpm: "PERT uses statistical buffers, CCPM uses project buffer"
      vs_agile: "PERT plans entire project, Agile iterates"

    anti_patterns:
      - "Treating expected duration as commitment"
      - "Using single point estimates instead of three"
      - "Ignoring variance in schedule reporting"
      - "Not recalculating as project progresses"
      - "Anchoring on optimistic estimates"

    example:
      context: "Software platform development project"
      tasks:
        design: "O=2w, M=3w, P=6w -> Te=3.33w, sigma=0.67w"
        backend: "O=4w, M=6w, P=12w -> Te=6.67w, sigma=1.33w"
        frontend: "O=3w, M=4w, P=7w -> Te=4.33w, sigma=0.67w"
        testing: "O=2w, M=3w, P=4w -> Te=3w, sigma=0.33w"
      critical_path: "Design -> Backend -> Testing (13w expected)"
      project_variance: "0.45 + 1.78 + 0.11 = 2.34 (sigma = 1.53w)"
      probability_assessment: |
        Target: 15 weeks
        Z = (15 - 13) / 1.53 = 1.31
        P(completion <= 15w) = 90.5%
      ordering: "Start backend early (highest variance), monitor closely"
      rationale: "Probabilistic analysis reveals true schedule risk"

    source: "Project Management - PERT (US Navy, 1958)"

  # ----------------------------------------
  # VARIATION 86: CRITICAL PATH METHOD (CPM)
  # ----------------------------------------
  critical_path:
    id: critical_path_ordering
    name: "Critical Path Method (CPM) Ordering"
    category: project_management

    philosophy: |
      Identify and protect the longest path through the project network.
      From DuPont/Remington Rand: the critical path determines minimum
      project duration - any delay on it delays the entire project.
      Focus resources and attention on critical activities. Use slack
      on non-critical paths as buffer. Mathematical precision enables
      optimization of time-cost tradeoffs.

    when_to_use:
      - Well-understood projects with predictable durations
      - Construction, manufacturing, repeatable processes
      - Need to identify which tasks have schedule flexibility
      - Time-cost optimization is important
      - Dependencies are clear and stable
      - Want to know exact impact of delays

    key_concepts:
      critical_path: "Longest path through network (zero slack)"
      slack_float: "How much a task can delay without affecting project"
      forward_pass: "Calculate earliest start/finish times"
      backward_pass: "Calculate latest start/finish times"
      es_ef_ls_lf: "Earliest/Latest Start/Finish for each activity"
      free_float: "Delay without affecting successor's earliest start"
      total_float: "Delay without affecting project completion"

    algorithm:
      build_network:
        - "List all activities with durations"
        - "Define dependencies (predecessors)"
        - "Create network diagram (AON or AOA)"
      forward_pass:
        - "ES(first) = 0"
        - "ES(activity) = max(EF of predecessors)"
        - "EF = ES + Duration"
      backward_pass:
        - "LF(last) = EF(last)"
        - "LF(activity) = min(LS of successors)"
        - "LS = LF - Duration"
      identify_critical_path:
        - "Slack = LS - ES (or LF - EF)"
        - "Critical activities have Slack = 0"
        - "Critical path connects start to finish through critical activities"

    prioritization_rules:
      1_protect_critical_path:
        rule: "Critical path activities get highest priority"
        reason: "Any delay here delays entire project"

      2_monitor_near_critical:
        rule: "Paths with small slack need attention"
        reason: "Can become critical if delayed"

      3_use_slack_wisely:
        rule: "Non-critical tasks can slip within their float"
        reason: "But once, not repeatedly"

      4_resource_conflicts:
        rule: "When resources conflict, favor critical path"
        reason: "Never delay critical for non-critical"

    variants:
      aon: "Activity-on-Node (precedence diagramming)"
      aoa: "Activity-on-Arrow (arrow diagramming)"
      cpm_cost: "Time-cost tradeoff analysis"
      resource_cpm: "With resource constraints"

    comparison:
      vs_pert: "CPM uses single duration estimates, deterministic"
      vs_ccpm: "CPM protects each task, CCPM pools buffers"
      vs_agile: "CPM front-loads planning, Agile plans iteratively"

    anti_patterns:
      - "Padding every task estimate (hidden buffers)"
      - "Ignoring resource constraints in scheduling"
      - "Not updating critical path as project progresses"
      - "Confusing total float with free float"
      - "Scheduling non-critical work to latest start"

    example:
      context: "Office renovation project"
      tasks:
        permits: "Duration: 2w, Dependencies: none"
        demolition: "Duration: 1w, Dependencies: permits"
        electrical: "Duration: 2w, Dependencies: demolition"
        plumbing: "Duration: 2w, Dependencies: demolition"
        drywall: "Duration: 1w, Dependencies: electrical, plumbing"
        painting: "Duration: 1w, Dependencies: drywall"
        flooring: "Duration: 1w, Dependencies: painting"
      forward_pass:
        permits: "ES=0, EF=2"
        demolition: "ES=2, EF=3"
        electrical: "ES=3, EF=5"
        plumbing: "ES=3, EF=5"
        drywall: "ES=5, EF=6"
        painting: "ES=6, EF=7"
        flooring: "ES=7, EF=8"
      backward_pass:
        flooring: "LF=8, LS=7"
        painting: "LF=7, LS=6"
        drywall: "LF=6, LS=5"
        electrical: "LF=5, LS=3, Slack=0 (CRITICAL)"
        plumbing: "LF=5, LS=3, Slack=0 (CRITICAL)"
        demolition: "LF=3, LS=2, Slack=0 (CRITICAL)"
        permits: "LF=2, LS=0, Slack=0 (CRITICAL)"
      critical_path: "Permits -> Demolition -> Electrical/Plumbing -> Drywall -> Painting -> Flooring"
      rationale: "Both trades are critical - delay either and project is late"

    source: "Project Management - CPM (DuPont/Remington Rand, 1957)"

  # ----------------------------------------
  # VARIATION 87: CRITICAL CHAIN PROJECT MANAGEMENT
  # ----------------------------------------
  critical_chain:
    id: critical_chain_ordering
    name: "Critical Chain Project Management (CCPM) Ordering"
    category: project_management

    philosophy: |
      Focus on resource constraints, not just task dependencies. From
      Goldratt's Theory of Constraints: the critical chain is the longest
      path considering BOTH dependencies AND resource contention. Remove
      safety from individual tasks and pool it in strategic buffers.
      Manage buffers, not tasks. Student syndrome and Parkinson's Law
      waste embedded safety - centralize it instead.

    when_to_use:
      - Resources are shared across tasks/projects
      - Historical tendency to pad estimates
      - Multitasking is degrading productivity
      - Projects consistently late despite "safe" estimates
      - Want to reduce work-in-progress
      - Managing portfolio of projects

    key_concepts:
      critical_chain: "Longest path considering resource constraints"
      project_buffer: "Pooled safety at end of critical chain"
      feeding_buffer: "Protection where non-critical joins critical"
      resource_buffer: "Alerting resources before critical tasks"
      buffer_management: "Monitor buffer consumption vs project progress"
      relay_race: "Pass work like baton, no early starts, fast handoffs"
      student_syndrome: "People start late if they have safety margin"
      parkinsons_law: "Work expands to fill available time"

    algorithm:
      remove_hidden_safety:
        - "Cut aggressive estimates (50% confidence, not 90%)"
        - "Move safety from tasks to buffers"
      identify_critical_chain:
        - "Build network with dependencies"
        - "Add resource constraints (same person can't do two things)"
        - "Find longest path considering both"
      add_buffers:
        - "Project buffer: ~50% of critical chain at end"
        - "Feeding buffers: where non-critical feeds critical"
        - "Resource buffers: alerts before critical tasks"
      execute_relay_race_style:
        - "Start tasks ASAP when predecessor complete"
        - "No early starts (focus), fast finishes"
        - "Hand off immediately when done"

    prioritization_rules:
      1_critical_chain_dominates:
        rule: "Critical chain tasks have absolute priority"
        reason: "Buffer consumption must be minimized"

      2_feeding_chain_protection:
        rule: "Feeding chains complete before their buffer is consumed"
        reason: "Don't starve the critical chain"

      3_no_multitasking:
        rule: "Work on one task until done, then move to next"
        reason: "Multitasking destroys throughput"

      4_buffer_based_prioritization:
        rule: "When buffers are consumed, escalate attention"
        reason: "Green/yellow/red buffer status drives action"

    buffer_management:
      green: "< 33% buffer consumed - on track"
      yellow: "33-67% buffer consumed - monitor closely"
      red: "> 67% buffer consumed - take action"

    variants:
      single_project: "Classic CCPM for one project"
      multi_project: "Drum resource across project portfolio"
      simplified: "Just project buffer, no feeding buffers"
      virtual_drum: "Capacity-constrained resource scheduling"

    comparison:
      vs_cpm: "CCPM includes resources, pools buffers"
      vs_pert: "CCPM uses behavioral insight, not just statistics"
      vs_agile: "CCPM manages full project, Agile manages increments"

    anti_patterns:
      - "Allowing multitasking on critical chain"
      - "Not cutting task estimates when adding buffers"
      - "Treating buffer consumption as failure"
      - "Starting tasks early (wastes focus)"
      - "Not tracking buffer penetration"
      - "Ignoring resource contention"

    example:
      context: "Product development with shared engineering resources"
      traditional_plan:
        design: "4 weeks (padded to 6 for safety)"
        prototype: "3 weeks (padded to 5)"
        testing: "2 weeks (padded to 3)"
        total: "14 weeks (with hidden safety)"
      ccpm_plan:
        design: "4 weeks (aggressive, 50% confidence)"
        prototype: "3 weeks (aggressive)"
        testing: "2 weeks (aggressive)"
        project_buffer: "4.5 weeks (50% of chain)"
        total: "13.5 weeks but with visible buffer"
      resource_constraint: "Senior engineer needed for both design and testing"
      critical_chain: "Design -> Prototype -> Testing (engineer constraint)"
      execution: |
        Track buffer consumption vs work completed.
        If 50% work done but 60% buffer consumed -> Yellow, investigate.
        If 50% work done but 30% buffer consumed -> Green, on track.
      rationale: "Pooled buffer is more efficient than hidden individual padding"

    source: "Theory of Constraints - Critical Chain (Goldratt, 1997)"

  # ----------------------------------------
  # VARIATION 88: AGILE/SCRUM SPRINT PLANNING
  # ----------------------------------------
  agile_sprint:
    id: agile_sprint_ordering
    name: "Agile/Scrum Sprint Planning Ordering"
    category: project_management

    philosophy: |
      Deliver value incrementally in fixed timeboxes. From Agile/Scrum:
      order work by business value within sprint capacity. Highest value
      items first, ensuring each sprint delivers something useful.
      Embrace change - reorder backlog between sprints as learning occurs.
      Working software over comprehensive documentation. Sustainable pace
      over heroic pushes.

    when_to_use:
      - Requirements are uncertain or evolving
      - Can deliver value incrementally
      - Stakeholders available for regular feedback
      - Team can self-organize
      - Prefer frequent delivery over big-bang release
      - Learning and adaptation are valuable

    key_concepts:
      product_backlog: "Ordered list of all work, by value"
      sprint_backlog: "Work committed for current sprint"
      velocity: "Historical capacity in story points"
      user_stories: "Requirements from user perspective"
      story_points: "Relative effort estimation"
      definition_of_done: "Criteria for completion"
      sprint_goal: "Overarching objective for the sprint"
      potentially_shippable: "Each sprint produces releasable increment"

    algorithm:
      maintain_product_backlog:
        - "Product Owner orders by business value"
        - "Keep top items refined and ready"
        - "Stories sized to fit within sprint"
      sprint_planning:
        - "Select sprint goal (theme/objective)"
        - "Pull stories from top of backlog"
        - "Continue until velocity capacity reached"
        - "Team breaks stories into tasks"
      sprint_execution:
        - "Work through sprint backlog items"
        - "Daily standup for coordination"
        - "No scope changes during sprint"
      inspect_and_adapt:
        - "Sprint review: demonstrate working software"
        - "Sprint retrospective: improve process"
        - "Reorder backlog based on learning"

    prioritization_rules:
      1_value_first:
        rule: "Highest business value at top of backlog"
        reason: "Maximize value delivered early"

      2_respect_velocity:
        rule: "Don't overcommit beyond historical capacity"
        reason: "Sustainable pace, reliable delivery"

      3_dependencies_within_sprint:
        rule: "If A depends on B, do B earlier in sprint"
        reason: "Avoid blocked work"

      4_emergent_design:
        rule: "Build simplest thing that works, refactor later"
        reason: "Avoid over-engineering with incomplete information"

    variants:
      scrum: "Fixed sprints, ceremonies, roles"
      kanban: "Continuous flow, WIP limits, no sprints"
      scrumban: "Scrum ceremonies with Kanban flow"
      safe: "Scaled Agile Framework for enterprise"
      xp: "Extreme Programming practices"

    comparison:
      vs_waterfall: "Agile iterates, waterfall phases once"
      vs_cpm: "Agile embraces change, CPM locks plan"
      vs_ccpm: "Agile short cycles, CCPM full project buffer"

    anti_patterns:
      - "Treating sprint commitments as contracts"
      - "Allowing scope creep during sprint"
      - "Not having potentially shippable increment"
      - "Skipping retrospectives"
      - "Backlog not ordered by value"
      - "Sprints with no clear goal"

    example:
      context: "E-commerce platform development"
      product_backlog:
        1_user_registration: "Value: 100, Points: 8"
        2_product_catalog: "Value: 90, Points: 13"
        3_shopping_cart: "Value: 85, Points: 8"
        4_checkout: "Value: 80, Points: 13"
        5_order_history: "Value: 40, Points: 5"
        6_recommendations: "Value: 30, Points: 13"
      team_velocity: "20 points per sprint"
      sprint_1_plan:
        goal: "Enable users to browse and register"
        items: "[user_registration (8), product_catalog (13)] = 21 points"
        stretch: "Slightly over velocity but stories are independent"
      sprint_2_plan:
        goal: "Enable purchasing"
        items: "[shopping_cart (8), checkout (13)] = 21 points"
      outcome: "After 2 sprints, users can register, browse, and purchase"
      rationale: "Each sprint delivers working, valuable functionality"

    source: "Agile - Scrum Guide (Schwaber & Sutherland), XP (Beck)"

  # ----------------------------------------
  # VARIATION 89: EARNED VALUE MANAGEMENT
  # ----------------------------------------
  earned_value:
    id: earned_value_ordering
    name: "Earned Value Management (EVM) Ordering"
    category: project_management

    philosophy: |
      Integrate scope, schedule, and cost into unified performance
      measurement. From EVM: track not just what you've spent but what
      you've earned (value of work completed). Compare planned value,
      earned value, and actual cost to detect variances early. Use
      performance indices to forecast final cost and completion date.
      Order work to maximize early earned value and enable accurate
      forecasting.

    when_to_use:
      - Need integrated cost/schedule control
      - Contract requires EVM reporting
      - Want early warning of overruns
      - Large projects with formal governance
      - Government, defense, aerospace projects
      - Need to forecast completion cost and date

    key_concepts:
      planned_value: "PV - budgeted cost of work scheduled"
      earned_value: "EV - budgeted cost of work performed"
      actual_cost: "AC - actual cost of work performed"
      schedule_variance: "SV = EV - PV (negative is behind)"
      cost_variance: "CV = EV - AC (negative is overrun)"
      schedule_performance_index: "SPI = EV / PV (< 1 is behind)"
      cost_performance_index: "CPI = EV / AC (< 1 is overrun)"
      estimate_at_completion: "EAC = BAC / CPI (forecasted total cost)"
      estimate_to_complete: "ETC = EAC - AC (remaining cost)"

    algorithm:
      establish_baseline:
        - "Define work breakdown structure (WBS)"
        - "Budget each work package"
        - "Create time-phased budget (PV curve)"
      track_progress:
        - "Measure work completed (percent complete or milestones)"
        - "Calculate EV = % complete x budget"
        - "Record AC from accounting"
      analyze_variances:
        - "SV = EV - PV (schedule performance)"
        - "CV = EV - AC (cost performance)"
        - "SPI = EV / PV, CPI = EV / AC"
      forecast_and_act:
        - "EAC = BAC / CPI (or other formula)"
        - "TCPI = (BAC - EV) / (BAC - AC) (required performance)"
        - "Take corrective action based on trends"

    prioritization_rules:
      1_baseline_sequence:
        rule: "Follow planned sequence unless variance indicates otherwise"
        reason: "Baseline is the approved plan"

      2_earned_value_maximization:
        rule: "Complete high-value work packages early"
        reason: "Earn value to demonstrate progress"

      3_variance_response:
        rule: "If SPI < 1, accelerate critical path work"
        reason: "Recovery requires focus on what matters"

      4_cpi_protection:
        rule: "If CPI < 1, scrutinize remaining work costs"
        reason: "Cost trends tend to persist"

    variants:
      basic_evm: "PV, EV, AC with simple variances"
      advanced_evm: "Forecasting, TCPI, schedule adherence"
      earned_schedule: "ES - time-based schedule analysis"
      agile_evm: "Story points as earned value"

    comparison:
      vs_traditional_tracking: "EVM integrates scope/time/cost"
      vs_agile: "EVM is plan-driven, Agile is adaptive"
      vs_cpm: "EVM adds cost dimension to schedule"

    anti_patterns:
      - "Tracking cost without earned value"
      - "Percent complete without objective measures"
      - "Not baselining before tracking"
      - "Ignoring variance trends"
      - "Blaming rather than correcting"

    example:
      context: "Software development project - 6 months, $600K budget"
      month_3_status:
        planned_value: "$300K (50% of budget through month 3)"
        work_completed: "40% complete"
        earned_value: "$240K (40% x $600K)"
        actual_cost: "$280K (spent so far)"
      variance_analysis:
        schedule_variance: "SV = $240K - $300K = -$60K (behind schedule)"
        cost_variance: "CV = $240K - $280K = -$40K (over budget)"
        spi: "0.80 (only 80% of planned work done)"
        cpi: "0.86 (only 86 cents of value per dollar spent)"
      forecast:
        eac: "$600K / 0.86 = $698K (forecasted total cost)"
        overrun: "$98K projected overrun"
      ordering_response: |
        1. Identify critical path work packages
        2. Prioritize high-value, low-risk completions
        3. Defer or cut scope on low-value items
        4. Staff augmentation for critical tasks
      rationale: "EVM reveals problems early enough to take action"

    source: "Project Management - EVM (DoD, ANSI/EIA-748)"

  # ----------------------------------------
  # VARIATION 90: RESOURCE LEVELING ORDERING
  # ----------------------------------------
  resource_leveling:
    id: resource_leveling_ordering
    name: "Resource Leveling Ordering"
    category: project_management

    philosophy: |
      Smooth resource demand over time to match availability. From
      operations research: the ideal schedule on paper may require
      resources you don't have when you need them. Delay or split
      tasks within their float to level resource usage. Accept longer
      duration to avoid resource overloads and the chaos they cause.
      Steady workload beats peaks and valleys.

    when_to_use:
      - Resources are constrained and shared
      - Schedule has flexibility (slack exists)
      - Want to avoid overtime or temporary staff
      - Resource availability varies over time
      - Hiring/firing costs are high
      - Prefer steady state to boom/bust

    key_concepts:
      resource_histogram: "Demand over time for each resource"
      resource_limit: "Maximum available per time period"
      overallocation: "Demand exceeds availability"
      leveling_delay: "Moving tasks later to reduce peaks"
      splitting: "Breaking task across non-contiguous periods"
      slack_consumption: "Using float to delay non-critical tasks"
      resource_smoothing: "Reduce variation without extending project"

    algorithm:
      build_initial_schedule:
        - "Create schedule ignoring resource limits"
        - "Identify resource demand per period"
        - "Find overallocated periods"
      identify_candidates_for_delay:
        - "List tasks with positive float"
        - "Prioritize tasks that reduce peak when delayed"
      apply_leveling:
        - "Delay tasks within their float"
        - "If still overallocated, extend project or split"
        - "Iterate until feasible"
      verify_feasibility:
        - "Check resource histogram against limits"
        - "Ensure dependencies still satisfied"

    prioritization_rules:
      1_critical_path_sacred:
        rule: "Never delay critical path for leveling"
        reason: "Would extend project duration"

      2_delay_high_float_first:
        rule: "Tasks with most slack are best leveling candidates"
        reason: "More flexibility to shift"

      3_level_constrained_resources:
        rule: "Focus on bottleneck resources first"
        reason: "They cause most problems"

      4_minimize_project_extension:
        rule: "Prefer delays within float to project extension"
        reason: "Meet original deadline if possible"

    variants:
      within_float: "Only use available slack (no extension)"
      unlimited: "Extend project as needed to level"
      smoothing: "Reduce variance without exceeding limits"
      priority_based: "Level based on task/resource priorities"

    comparison:
      vs_cpm: "CPM ignores resources, leveling adds them"
      vs_ccpm: "CCPM considers resources in critical chain"
      vs_fast_tracking: "Leveling extends time, fast-tracking compresses"

    anti_patterns:
      - "Leveling critical path tasks"
      - "Ignoring resource constraints in planning"
      - "Over-leveling (too conservative)"
      - "Not considering task splitting"
      - "Leveling without checking dependencies"

    example:
      context: "Construction project with 3 electricians"
      original_schedule:
        week_1: "Task A needs 2 electricians"
        week_2: "Task B needs 3 electricians, Task C needs 2 electricians"
        week_3: "Task D needs 1 electrician"
      problem: "Week 2 needs 5 electricians, only 3 available"
      analysis:
        task_b: "Critical path, no float - cannot delay"
        task_c: "Has 1 week float - can delay to week 3"
      leveled_schedule:
        week_1: "Task A (2 electricians)"
        week_2: "Task B (3 electricians) - at capacity"
        week_3: "Task C (2 electricians) + Task D (1 electrician)"
      result: "No overallocation, project duration unchanged"
      rationale: "Use float intelligently to match resource supply"

    source: "Operations Research - Resource-Constrained Scheduling"

  # ----------------------------------------
  # VARIATION 91: FAST-TRACKING AND CRASHING
  # ----------------------------------------
  fast_tracking_crashing:
    id: fast_tracking_crashing_ordering
    name: "Fast-Tracking and Crashing Ordering"
    category: project_management

    philosophy: |
      Compress schedule when time is more valuable than cost or risk.
      From schedule compression: fast-tracking does activities in parallel
      that were planned sequentially (adds risk). Crashing adds resources
      to shorten duration (adds cost). Choose compression based on which
      cost you can better afford. Compress critical path only - compressing
      non-critical work doesn't help overall duration.

    when_to_use:
      - Must meet immovable deadline
      - Time-to-market is critical
      - Budget is available for acceleration
      - Some activities can truly be parallelized
      - Rework risk is acceptable for speed
      - Opportunity cost of delay exceeds compression cost

    key_concepts:
      fast_tracking: "Overlapping sequential activities"
      crashing: "Adding resources to shorten duration"
      crash_cost: "Additional cost per unit time saved"
      normal_duration: "Time with normal resources"
      crash_duration: "Minimum possible time with max resources"
      cost_slope: "(Crash cost - Normal cost) / (Normal time - Crash time)"
      diminishing_returns: "Each day saved costs more than the last"

    algorithm:
      identify_compression_need:
        - "Determine required completion date"
        - "Calculate current critical path duration"
        - "Gap = Current - Required"
      evaluate_fast_tracking:
        - "Find sequential activities that could overlap"
        - "Assess rework risk if done in parallel"
        - "Calculate time saved vs risk increase"
      evaluate_crashing:
        - "For each critical activity, find crash cost slope"
        - "Rank by cost per day saved (cheapest first)"
        - "Note crash limits (can't crash below minimum)"
      apply_compression:
        - "Start with cheapest options"
        - "Compress until target met or options exhausted"
        - "Monitor for new critical paths emerging"

    prioritization_rules:
      1_critical_path_only:
        rule: "Only compress critical path activities"
        reason: "Compressing non-critical doesn't help"

      2_cheapest_crashing_first:
        rule: "Crash activities with lowest cost slope"
        reason: "Minimize total compression cost"

      3_fast_track_low_risk:
        rule: "Overlap activities with minimal information transfer"
        reason: "Reduce rework probability"

      4_watch_for_new_critical:
        rule: "Re-evaluate critical path after each compression"
        reason: "Other paths may become critical"

    variants:
      pure_fast_tracking: "Only overlap, no additional resources"
      pure_crashing: "Only add resources, maintain sequence"
      hybrid: "Combine both techniques"
      selective: "Fast-track some, crash others based on characteristics"

    comparison:
      vs_resource_leveling: "Opposite directions - compression vs smoothing"
      vs_ccpm: "Compression adds risk, CCPM removes hidden safety"
      vs_agile: "Compression is plan adjustment, Agile is scope flexibility"

    anti_patterns:
      - "Crashing all activities (only critical helps)"
      - "Fast-tracking with high rework risk"
      - "Not rechecking critical path"
      - "Crashing beyond crash limit"
      - "Assuming linear cost/time relationship"
      - "Ignoring team burnout from crashing"

    example:
      context: "Product launch - need to cut 3 weeks from 12-week schedule"
      current_critical_path:
        design: "4 weeks, crash to 3 weeks for $20K"
        development: "5 weeks, crash to 4 weeks for $30K"
        testing: "3 weeks, crash to 2 weeks for $40K"
      compression_options:
        fast_track_design_dev: |
          Overlap design and development by 1 week.
          Risk: development may need rework if design changes.
          Cost: Potential rework $10K, saves 1 week.
        crash_design: "Cost slope: $20K/week"
        crash_development: "Cost slope: $30K/week"
        crash_testing: "Cost slope: $40K/week"
      recommended_compression:
        step_1: "Fast-track design/development overlap (1 week, $10K risk)"
        step_2: "Crash design by 1 week ($20K)"
        step_3: "Crash development by 1 week ($30K)"
        total: "3 weeks saved, $60K additional cost/risk"
      decision: "If market opportunity worth > $60K, proceed with compression"
      rationale: "Cheapest compression first until target met"

    source: "Project Management - Schedule Compression Techniques"

  # ========================================
  # PEDAGOGY & EDUCATIONAL THEORY ORDERINGS
  # ========================================

  # ----------------------------------------
  # VARIATION 92: SPIRAL CURRICULUM ORDERING
  # ----------------------------------------
  spiral_curriculum:
    id: spiral_curriculum_ordering
    name: "Spiral Curriculum Ordering (Bruner)"
    category: pedagogy_educational

    philosophy: |
      Revisit the same topics repeatedly at increasing levels of depth
      and sophistication. From Bruner's cognitive psychology: any subject
      can be taught to any learner in some honest form. Start with intuitive
      understanding, then progressively formalize. Each pass through the
      spiral reinforces prior learning while adding complexity. The learner
      develops both breadth and depth simultaneously.

    when_to_use:
      - Teaching complex topics with many interconnections
      - Learner needs to build intuition before formalization
      - Content has natural levels of sophistication
      - Long-term retention is important
      - Building towards expert understanding over time

    key_concepts:
      spiral: "Same topic revisited at multiple points"
      increasing_depth: "Each visit adds sophistication"
      enactive_iconic_symbolic: "Physical to visual to abstract progression"
      prerequisite_revisit: "Earlier understanding scaffolds later depth"

    algorithm:
      identify_core_concepts:
        - "List fundamental ideas that recur throughout domain"
        - "These become spiral threads revisited at each level"
      define_depth_levels:
        - "Level 1: Intuitive/concrete understanding"
        - "Level 2: Procedural/applied understanding"
        - "Level 3: Formal/theoretical understanding"
        - "Level 4: Critical/creative mastery"
      sequence_passes:
        - "Pass 1: All concepts at Level 1"
        - "Pass 2: All concepts at Level 2 (reinforces L1)"
        - "Pass 3: All concepts at Level 3 (reinforces L2)"
        - "Continue until target depth reached"

    prioritization_rules:
      1_breadth_before_depth:
        rule: "Cover all topics shallowly before any topic deeply"
        reason: "Builds connected mental model, reveals relationships"

      2_concrete_before_abstract:
        rule: "Start with physical/enactive, then iconic, then symbolic"
        reason: "Intuition grounds formal understanding"

      3_revisit_with_new_lens:
        rule: "Each pass applies new conceptual framework"
        reason: "Same material, deeper insight"

      4_spacing_between_passes:
        rule: "Time between revisits allows consolidation"
        reason: "Spaced practice strengthens retention"

    variants:
      bruner_original: "Enactive to Iconic to Symbolic progression"
      van_hiele: "Levels of geometric reasoning"
      solo_taxonomy: "Prestructural to Extended Abstract"
      bloom_revisited: "Remember to Create across multiple passes"

    comparison:
      vs_linear: "Linear does A completely, then B; spiral revisits A, B, A, B"
      vs_mastery: "Mastery waits for 100%; spiral moves on and returns"
      vs_scaffolded: "Scaffolding builds one topic; spiral cycles through many"

    anti_patterns:
      - "Staying at shallow level forever (no depth)"
      - "Rushing to abstraction without intuitive base"
      - "Forgetting to return (becomes linear)"
      - "Too many concepts in spiral (cognitive overload)"

    example:
      context: "Teaching programming fundamentals"
      spiral_threads:
        - "Variables and data"
        - "Control flow"
        - "Functions"
        - "Data structures"
      pass_1_intuitive:
        - "Variables: Boxes holding values"
        - "Control flow: Decision points and loops as flowcharts"
        - "Functions: Named recipe cards"
        - "Data structures: Organizing information in lists"
      pass_2_procedural:
        - "Variables: Types, scope, assignment operations"
        - "Control flow: if/else, for/while syntax"
        - "Functions: Parameters, return values, calling"
        - "Data structures: Arrays, dictionaries, methods"
      pass_3_formal:
        - "Variables: Memory allocation, references vs values"
        - "Control flow: Computational complexity, recursion"
        - "Functions: Higher-order functions, closures"
        - "Data structures: Big-O, implementation trade-offs"
      rationale: "Each pass deepens all concepts while reinforcing connections"

    source: "Cognitive Psychology - Jerome Bruner, Spiral Curriculum (1960)"

  # ----------------------------------------
  # VARIATION 93: MASTERY LEARNING ORDERING
  # ----------------------------------------
  mastery_learning:
    id: mastery_learning_ordering
    name: "Mastery Learning Ordering (Bloom)"
    category: pedagogy_educational

    philosophy: |
      Do not proceed to the next topic until the current one is mastered.
      From Bloom's research: given enough time and appropriate instruction,
      virtually all students can achieve mastery. The key variable is not
      aptitude but time-on-task. Sequential progression with gates ensures
      no gaps accumulate. Gaps compound; mastery prevents this cascade.

    when_to_use:
      - Skills are strictly hierarchical (B requires A)
      - Gaps would cause cascading failure
      - Quality matters more than speed
      - Can provide varied instruction until mastery achieved
      - Formative assessment is available

    key_concepts:
      mastery_threshold: "Criterion for good enough (typically 80-90%)"
      formative_assessment: "Check understanding before moving on"
      corrective_feedback: "Different approach if mastery not achieved"
      learning_time_variable: "Time varies, mastery is constant"

    algorithm:
      for_each_unit:
        - "Teach unit content"
        - "Assess for mastery"
        - "If mastered: proceed to next unit"
        - "If not mastered: provide corrective instruction"
        - "Re-assess until mastery achieved"
        - "Only then proceed"

    prioritization_rules:
      1_prerequisite_mastery:
        rule: "Cannot start unit N+1 until unit N is mastered"
        reason: "Prevents accumulating gaps"

      2_mastery_criterion:
        rule: "Define explicit threshold (80-90%)"
        reason: "Clear, measurable gate"
        examples:
          - "80% on unit test"
          - "Complete 4 of 5 practice problems correctly"
          - "Demonstrate skill without assistance"

      3_varied_instruction:
        rule: "Offer multiple paths to mastery"
        reason: "Different learners need different approaches"
        options:
          - "Additional examples"
          - "Peer tutoring"
          - "Alternative explanations"
          - "More practice problems"

      4_immediate_feedback:
        rule: "Quick assessment turnaround"
        reason: "Enables rapid correction before moving on"

    variants:
      pure_mastery: "100% mastery required (strict)"
      criterion_referenced: "Explicit performance standards"
      personalized_system: "Keller Plan - self-paced"
      competency_based: "Demonstrate skill, not seat time"

    comparison:
      vs_spiral: "Mastery gates each topic; spiral revisits without gates"
      vs_time_boxed: "Mastery varies time; time-boxed varies achievement"
      vs_curve_grading: "Mastery is criterion-referenced, not norm-referenced"

    anti_patterns:
      - "Proceeding without mastery (gaps accumulate)"
      - "Mastery threshold too low (false mastery)"
      - "Mastery threshold too high (perfectionism blocks progress)"
      - "Single instruction method only"
      - "Ignoring time constraints entirely"

    example:
      context: "Learning mathematics - algebra unit"
      units:
        1: "Solving one-step equations"
        2: "Solving two-step equations"
        3: "Solving multi-step equations"
        4: "Word problems"
      mastery_sequence:
        unit_1:
          attempt_1: "70% on assessment - not mastered"
          intervention: "Additional practice with guided examples"
          attempt_2: "85% on re-assessment - MASTERED"
        unit_2:
          attempt_1: "82% on assessment - MASTERED"
        unit_3:
          attempt_1: "60% on assessment - not mastered"
          intervention_1: "Peer tutoring session"
          attempt_2: "72% - not mastered"
          intervention_2: "One-on-one teacher explanation"
          attempt_3: "88% - MASTERED"
        unit_4: "Only accessible after units 1-3 mastered"
      rationale: "Each unit builds on solid foundation; no gaps to cause later failure"

    source: "Educational Psychology - Benjamin Bloom, Mastery Learning (1968)"

  # ----------------------------------------
  # VARIATION 94: COGNITIVE LOAD ORDERING
  # ----------------------------------------
  cognitive_load:
    id: cognitive_load_ordering
    name: "Cognitive Load Ordering (Sweller)"
    category: pedagogy_educational

    philosophy: |
      Sequence learning to manage the three types of cognitive load:
      intrinsic (inherent complexity), extraneous (poor design), and
      germane (schema construction). From cognitive load theory: working
      memory is limited; overload prevents learning. Order material to
      minimize extraneous load, manage intrinsic load, and maximize
      germane load. The goal is optimal challenge, not minimal challenge.

    when_to_use:
      - Material has high intrinsic complexity
      - Learners are novices (no schemas to automate)
      - Need to prevent cognitive overload
      - Instructional design optimization
      - Technical or procedural training

    key_concepts:
      intrinsic_load: "Inherent complexity of material itself"
      extraneous_load: "Load from poor presentation (reduce this)"
      germane_load: "Load from building schemas (increase this)"
      working_memory: "Limited capacity (~7 items, degrades with complexity)"
      schema: "Organized knowledge structure that reduces load"
      element_interactivity: "How many elements must be processed together"

    algorithm:
      assess_intrinsic_load:
        - "Count interacting elements in material"
        - "High interactivity = high intrinsic load"
      sequence_by_load:
        - "Start with low element interactivity"
        - "Build schemas that reduce effective load"
        - "Gradually increase interactivity"
      reduce_extraneous:
        - "Integrate related information spatially"
        - "Avoid split attention"
        - "Remove redundant information"

    prioritization_rules:
      1_simple_to_complex:
        rule: "Order by element interactivity, lowest first"
        reason: "Build schemas before adding complexity"
        measure: "Count elements that must be held simultaneously"

      2_isolated_before_interacting:
        rule: "Learn elements separately before combining"
        reason: "Each element becomes automatic, reducing load"
        technique: "Isolated elements effect"

      3_integrate_information:
        rule: "Present related info together, not split"
        reason: "Split attention increases extraneous load"
        example: "Label on diagram, not in separate legend"

      4_worked_examples_first:
        rule: "Examples before practice problems"
        reason: "Studying examples has lower load than problem solving"
        transition: "Gradually fade to independent practice"

    load_types:
      intrinsic:
        definition: "Cannot be reduced without simplifying content"
        management: "Sequence from low to high; build schemas first"
        examples: "Grammar rules, programming syntax, math procedures"
      extraneous:
        definition: "Can be reduced through better design"
        management: "Eliminate unnecessary processing"
        examples: "Split attention, redundancy, unclear instructions"
      germane:
        definition: "Desirable load from learning"
        management: "Maximize once extraneous is minimized"
        examples: "Comparing examples, self-explanation, elaboration"

    variants:
      element_interactivity: "Sequence by interaction count"
      completion_strategy: "Partial solutions to complete"
      segmentation: "Break continuous content into segments"
      pretraining: "Teach vocabulary/components before procedures"

    comparison:
      vs_mastery: "Mastery checks achievement; cognitive load manages process"
      vs_spiral: "Spiral revisits; cognitive load sequences by complexity"
      vs_scaffolded: "Both manage complexity; cognitive load is more principled"

    anti_patterns:
      - "Presenting everything at once (overload)"
      - "Starting with complex cases"
      - "Split attention (text far from diagram)"
      - "Redundant narration of on-screen text"
      - "Too much novelty without schemas"

    example:
      context: "Teaching SQL queries"
      cognitive_load_sequence:
        phase_1_low_load:
          content: "Single table SELECT"
          elements: "SELECT, column, FROM, table (4 elements)"
          technique: "Worked examples with integrated labels"
        phase_2_medium_load:
          content: "Adding WHERE clause"
          elements: "Previous + WHERE, condition (6 elements)"
          technique: "Completion problems (fill in WHERE)"
        phase_3_higher_load:
          content: "Two-table JOIN"
          elements: "Previous + JOIN, ON, second table (9 elements)"
          technique: "Paired examples (correct vs incorrect)"
        phase_4_high_load:
          content: "Subqueries and aggregation"
          elements: "Multiple interacting concepts"
          prerequisite: "Single queries automated as schema"
      rationale: "Each phase builds schemas that reduce effective load of next phase"

    source: "Cognitive Psychology - John Sweller, Cognitive Load Theory (1988)"

  # ----------------------------------------
  # VARIATION 95: WORKED EXAMPLES ORDERING
  # ----------------------------------------
  worked_examples:
    id: worked_examples_ordering
    name: "Worked Examples Ordering (Fading Effect)"
    category: pedagogy_educational

    philosophy: |
      Begin with fully worked examples, then progressively remove steps
      until learner solves independently. From cognitive load research:
      studying worked examples is more effective than problem solving for
      novices because it reduces extraneous cognitive load. As expertise
      grows, worked examples become redundant and independent practice
      becomes more effective. The transition is gradual, not sudden.

    when_to_use:
      - Teaching procedural skills
      - Learners are novices in domain
      - Problems have clear solution steps
      - Want to reduce cognitive load during learning
      - Building from modeling to independence

    key_concepts:
      worked_example: "Complete solution with all steps shown"
      fading: "Progressively removing steps"
      completion_problem: "Partial solution, learner finishes"
      example_problem_pairs: "Example followed by similar problem"
      expertise_reversal: "Worked examples hurt experts"

    algorithm:
      phase_1_worked_examples:
        - "Present complete solutions with all steps"
        - "Learner studies, not solves"
        - "Emphasize self-explanation"
      phase_2_completion_problems:
        - "Provide partial solution"
        - "Learner completes remaining steps"
        - "Gradually remove more steps"
      phase_3_independent_practice:
        - "Learner solves from scratch"
        - "Worked examples now redundant"

    prioritization_rules:
      1_examples_before_practice:
        rule: "Always worked example before similar practice"
        reason: "Reduces cognitive load, shows expert process"
        ratio: "Start with 2:1 examples to problems"

      2_progressive_fading:
        rule: "Remove steps gradually, not all at once"
        pattern:
          - "Full example"
          - "Example with last step removed"
          - "Example with last 2 steps removed"
          - "Full problem (all steps removed)"

      3_similar_structure:
        rule: "Practice problems structurally similar to examples"
        reason: "Transfer requires matching deep structure"

      4_self_explanation_prompts:
        rule: "Ask learner to explain why each step"
        reason: "Prevents passive reading, builds understanding"

    fading_levels:
      level_0: "Full worked example (0 steps removed)"
      level_1: "Remove final step only"
      level_2: "Remove final 2-3 steps"
      level_3: "Remove middle steps (given start and end)"
      level_4: "Provide first step only"
      level_5: "Full problem (all steps removed)"

    variants:
      backward_fading: "Remove last steps first (most common)"
      forward_fading: "Remove first steps first"
      middle_out: "Remove middle, keep start and end"
      self_paced: "Learner requests examples vs problems"

    comparison:
      vs_discovery_learning: "Examples are explicit; discovery is implicit"
      vs_pure_practice: "Examples first; pure practice starts with problems"
      vs_mastery: "Both gate progress; worked examples specifies HOW to learn"

    anti_patterns:
      - "Problems before examples (high load for novices)"
      - "Removing too many steps too fast"
      - "Worked examples for experts (expertise reversal)"
      - "Passive example reading without self-explanation"
      - "Examples not matched to practice problems"

    example:
      context: "Teaching algebraic equation solving"
      worked_example_sequence:
        example_1_full:
          problem: "Solve: 3x + 5 = 14"
          step_1: "Subtract 5 from both sides: 3x = 9"
          step_2: "Divide both sides by 3: x = 3"
          step_3: "Check: 3(3) + 5 = 14"
        example_2_last_step_removed:
          problem: "Solve: 2x + 7 = 15"
          step_1: "Subtract 7 from both sides: 2x = 8"
          step_2: "(Student completes: x = ?)"
        example_3_two_steps_removed:
          problem: "Solve: 4x + 3 = 19"
          step_1: "(Student completes both steps)"
        example_4_full_problem:
          problem: "Solve: 5x + 2 = 27"
          steps: "(Student solves independently)"
      rationale: "Gradual fading builds skill while managing cognitive load"

    source: "Educational Psychology - Worked Example Effect, Fading (Renkl, Atkinson)"

  # ----------------------------------------
  # VARIATION 96: FADING SCAFFOLDS ORDERING
  # ----------------------------------------
  fading_scaffolds:
    id: fading_scaffolds_ordering
    name: "Fading Scaffolds Ordering (Gradual Release)"
    category: pedagogy_educational

    philosophy: |
      Provide maximum support initially, then systematically remove
      supports as learner capability grows. From Vygotsky's zone of
      proximal development: learners can accomplish more with assistance
      than alone. Scaffolding bridges the gap. But scaffolds must fade
      or learners become dependent. The goal is independence, achieved
      through gradual release of responsibility.

    when_to_use:
      - Learner cannot succeed independently yet
      - Task is in zone of proximal development
      - Want to build self-regulation and independence
      - Training with eventual autonomous performance
      - Skills that initially require support

    key_concepts:
      scaffold: "Temporary support structure removed after use"
      zpd: "Zone of proximal development - achievable with help"
      fading: "Gradual removal of support"
      responsibility_transfer: "From teacher to learner"
      contingent_support: "Support matched to current need"

    algorithm:
      phase_1_i_do:
        - "Instructor demonstrates with full explanation"
        - "Learner observes and asks questions"
        - "All cognitive work done by instructor"
      phase_2_we_do:
        - "Instructor and learner collaborate"
        - "Instructor provides prompts and hints"
        - "Learner attempts with immediate feedback"
      phase_3_you_do_guided:
        - "Learner performs with instructor available"
        - "Support on request only"
        - "Instructor fades to observer"
      phase_4_you_do_independent:
        - "Learner performs without support"
        - "Scaffolds completely removed"

    prioritization_rules:
      1_assess_current_level:
        rule: "Determine what learner can do alone vs with help"
        reason: "Scaffold within ZPD, not below or above"
        zones:
          actual: "What learner can do independently"
          proximal: "What learner can do with help"
          beyond: "Not yet achievable even with help"

      2_provide_contingent_support:
        rule: "Match support to current performance"
        reason: "Too much support = dependence; too little = failure"
        adjustment: "Increase support on failure, decrease on success"

      3_gradual_fading:
        rule: "Remove supports incrementally, not suddenly"
        sequence:
          - "Full modeling"
          - "Guided practice with hints"
          - "Independent practice with feedback"
          - "Autonomous performance"

      4_maintain_challenge:
        rule: "As supports fade, difficulty can increase"
        reason: "Constant level of challenge within capability"

    scaffold_types:
      procedural: "Step-by-step instructions"
      conceptual: "Organizing frameworks, schemas"
      strategic: "Problem-solving approaches"
      metacognitive: "Self-monitoring prompts"
      social: "Peer collaboration, expert access"

    fading_techniques:
      reducing_prompts: "Fewer hints over time"
      increasing_delays: "Wait longer before helping"
      removing_structure: "Less prescribed format"
      raising_standards: "Higher success criteria"
      transferring_monitoring: "Self-check replaces external check"

    comparison:
      vs_worked_examples: "Examples are specific scaffold type; fading is broader"
      vs_mastery: "Both control progression; fading specifies support structure"
      vs_direct_instruction: "Scaffolding is interactive; direct is one-way"

    anti_patterns:
      - "Never fading (learned helplessness)"
      - "Fading too fast (frustration, failure)"
      - "Scaffolding below ZPD (boring, wasted)"
      - "Scaffolding above ZPD (impossible, frustrating)"
      - "Fixed scaffolds regardless of performance"

    example:
      context: "Teaching essay writing"
      scaffolded_sequence:
        phase_1_i_do:
          activity: "Teacher writes essay aloud, explaining choices"
          support: "100% - full modeling"
          learner_role: "Observer, note-taker"
        phase_2_we_do:
          activity: "Co-construct essay together"
          support: "70% - teacher provides structure, student fills"
          tools: "Outline template, sentence starters, peer discussion"
        phase_3_you_do_guided:
          activity: "Student writes with checklist and feedback"
          support: "30% - checklist, revision prompts, available help"
          fading: "Checklist removed after 3 successful essays"
        phase_4_you_do_independent:
          activity: "Student writes without supports"
          support: "0% - fully independent"
          assessment: "Demonstrate skill without scaffolds"
      rationale: "Each phase reduces support while maintaining success"

    source: "Educational Psychology - Vygotsky (ZPD), Wood (Scaffolding), Pearson (Gradual Release)"

  # ----------------------------------------
  # VARIATION 97: INTERLEAVED PRACTICE ORDERING
  # ----------------------------------------
  interleaved_practice:
    id: interleaved_practice_ordering
    name: "Interleaved Practice Ordering (Mixing)"
    category: pedagogy_educational

    philosophy: |
      Mix different types of problems rather than practicing one type
      at a time. From learning science: interleaving is harder during
      practice but produces better long-term retention and transfer.
      Blocked practice (AAABBBCCC) feels easier but produces less
      durable learning than interleaved (ABCABCABC). The difficulty
      is desirable because it forces discrimination and retrieval.

    when_to_use:
      - Multiple related skills to learn
      - Long-term retention is important
      - Transfer to novel situations needed
      - Learner has basic proficiency in each skill
      - Can tolerate lower immediate performance

    key_concepts:
      interleaving: "Mixing different problem types ABCABC"
      blocking: "Grouping same type AAABBBCCC"
      discrimination: "Learning to identify problem type"
      retrieval_practice: "Recalling appropriate strategy"
      desirable_difficulty: "Harder practice = better learning"

    algorithm:
      after_initial_acquisition:
        - "Once basic skill learned (via blocking or examples)"
        - "Switch to interleaved practice"
      mixing_schedule:
        - "Alternate between 2-4 different problem types"
        - "Each problem requires identifying type first"
        - "No external cues about problem type"
      maintain_interleaving:
        - "Continue mixing even when performance drops"
        - "Lower practice performance is expected"
        - "Test performance will be higher"

    prioritization_rules:
      1_initial_blocking_ok:
        rule: "Brief blocked practice during initial learning"
        reason: "Need basic competence before interleaving helps"
        guideline: "2-4 examples per type, then switch to interleaving"

      2_mix_similar_types:
        rule: "Interleave related but distinct problem types"
        reason: "Forces discrimination between similar categories"
        examples:
          - "Geometry: area formulas for different shapes"
          - "Stats: when to use which test"
          - "Art: works by similar artists from same period"

      3_remove_type_cues:
        rule: "Don't signal which type of problem is next"
        reason: "Learner must identify type, not just apply strategy"
        anti_cue: "Avoid 'Now practice quadratic equations'"

      4_accept_lower_practice_performance:
        rule: "Interleaving feels harder and scores lower during practice"
        reason: "This difficulty is what produces better retention"
        trust: "Test performance will exceed blocked practice"

    interleaving_vs_blocking:
      during_practice:
        blocked: "Feels easy, high accuracy"
        interleaved: "Feels hard, lower accuracy"
      on_delayed_test:
        blocked: "Lower retention, less transfer"
        interleaved: "Higher retention, better transfer"
      why:
        blocked: "Retrieval is primed, no discrimination needed"
        interleaved: "Forces retrieval and type identification"

    variants:
      random_interleaving: "Fully random order"
      constrained_interleaving: "Guarantee each type appears regularly"
      spacing_interleaving: "Combine with spaced intervals"
      contextual_interference: "Related term from motor learning"

    comparison:
      vs_blocked: "Interleaving mixes; blocking groups"
      vs_spiral: "Both revisit; interleaving is within sessions, spiral across"
      vs_spaced: "Can combine - spaced interleaved practice is powerful"

    anti_patterns:
      - "Interleaving during initial acquisition (too hard)"
      - "Labeling problem types (removes discrimination)"
      - "Abandoning interleaving because it feels harder"
      - "Interleaving completely unrelated topics (no benefit)"

    example:
      context: "Math practice - solving for different variables"
      blocked_practice:
        session_1: "Solve for x: 10 problems in a row"
        session_2: "Solve for y: 10 problems in a row"
        session_3: "Solve for area: 10 problems in a row"
        feel: "Easy during practice"
        test_result: "65% after one week"
      interleaved_practice:
        session: |
          Problem 1: Solve for x
          Problem 2: Find area
          Problem 3: Solve for y
          Problem 4: Solve for x
          Problem 5: Find area
          (continue mixing)
        feel: "Harder during practice"
        test_result: "80% after one week"
      rationale: "Mixing forces learner to identify problem type each time"

    source: "Learning Science - Interleaving Effect (Rohrer, Taylor), Contextual Interference"

  # ----------------------------------------
  # VARIATION 98: SPACED REPETITION ORDERING
  # ----------------------------------------
  spaced_repetition:
    id: spaced_repetition_ordering
    name: "Spaced Repetition Ordering (Optimal Review)"
    category: pedagogy_educational

    philosophy: |
      Schedule review at expanding intervals to maximize retention with
      minimum effort. From memory research: forgetting follows predictable
      curves; optimal review happens just before forgetting. Each successful
      retrieval strengthens memory and extends the interval. The result is
      durable long-term memory with efficient time investment. Space, don't
      mass.

    when_to_use:
      - Large amounts of information to memorize
      - Long-term retention is the goal
      - Can track individual item performance
      - Willing to follow algorithm over intuition
      - Vocabulary, facts, procedures, concepts

    key_concepts:
      forgetting_curve: "Memory decays predictably over time"
      spacing_effect: "Spaced review beats massed review"
      retrieval_practice: "Testing strengthens memory more than re-reading"
      expanding_intervals: "Successful recall leads to longer interval"
      optimal_gap: "Review just before forgetting"

    algorithm:
      initial_learning:
        - "First encounter with material"
        - "Short initial interval (1 day)"
      spaced_review_loop:
        - "Test retrieval (not re-reading)"
        - "If correct: increase interval (1, 3, 7, 14, 30, 90 days)"
        - "If incorrect: reset to short interval"
        - "Repeat indefinitely for long-term retention"

    prioritization_rules:
      1_prioritize_due_items:
        rule: "Review items whose interval has elapsed"
        reason: "Reviewing before due wastes opportunity"
        scheduling: "Just-in-time review at optimal moment"

      2_expand_on_success:
        rule: "Double (or more) interval after successful recall"
        reason: "Memory is stronger, can wait longer"
        typical_intervals: "1d, 3d, 7d, 14d, 30d, 90d, 180d"

      3_reset_on_failure:
        rule: "Return to short interval if recall fails"
        reason: "Memory needs rebuilding"
        mercy: "May use partial reset instead of full"

      4_retrieval_not_recognition:
        rule: "Require production, not just recognition"
        reason: "Retrieval practice is the active ingredient"
        format: "Free recall > cued recall > recognition"

    interval_algorithms:
      leitner_box: "Cards move forward on success, back on failure"
      sm2: "SuperMemo algorithm with ease factor"
      fsrs: "Modern algorithm using forgetting curves"
      simple_doubling: "Double interval on success"

    variants:
      expanding_gap: "1, 3, 7, 14, 30... (growing)"
      uniform_gap: "Fixed interval (less efficient)"
      contracting_gap: "7, 5, 3, 1 (for cramming, less durable)"
      adaptive: "Algorithm adjusts based on performance history"

    comparison:
      vs_massed_practice: "Spaced is less intense but more durable"
      vs_interleaved: "Complementary - can use spaced interleaved practice"
      vs_mastery: "Both track performance; spaced optimizes review schedule"

    anti_patterns:
      - "Massed repetition (cramming)"
      - "Re-reading instead of retrieval"
      - "Ignoring due dates"
      - "Reviewing too early (wastes opportunity)"
      - "Fixed intervals regardless of performance"

    example:
      context: "Learning vocabulary (500 words)"
      spaced_repetition_sequence:
        day_1:
          new_words: "Learn 20 new words"
          reviews: "None yet"
        day_2:
          new_words: "Learn 20 new words"
          reviews: "Review yesterday's 20 (due: 1 day)"
        day_4:
          new_words: "Learn 20 new words"
          reviews: "Day 1 words due (interval was 3 days after success)"
        day_8:
          new_words: "Continue adding"
          reviews: "Day 1 words due again (interval 7 days)"
          failed_words: "Reset to 1 day interval"
        ongoing:
          pattern: "New words daily + all due reviews"
          efficiency: "Mature words reviewed rarely (90+ day intervals)"
          result: "500 words retained long-term with ~15 min/day"
      rationale: "Each word reviewed at optimal moment, not too soon or late"

    source: "Memory Research - Ebbinghaus, Spacing Effect, SuperMemo, Anki"

  # ----------------------------------------
  # VARIATION 99: DESIRABLE DIFFICULTIES ORDERING
  # ----------------------------------------
  desirable_difficulties:
    id: desirable_difficulties_ordering
    name: "Desirable Difficulties Ordering (Strategic Challenge)"
    category: pedagogy_educational

    philosophy: |
      Introduce difficulties that slow learning but improve retention and
      transfer. From Bjork's research: conditions that make learning feel
      hard often make it more durable. Easy, fluent learning creates
      illusion of mastery but fades quickly. Strategically adding friction
      (spacing, interleaving, testing, varying conditions) builds stronger
      memory traces. The difficulty must be desirable - challenging but
      achievable.

    when_to_use:
      - Long-term retention is the goal
      - Learner can tolerate temporary struggle
      - Transfer to new contexts needed
      - Want to counter illusions of competence
      - Building robust, flexible knowledge

    key_concepts:
      desirable: "Difficulty that enhances learning (not all difficulty)"
      undesirable: "Difficulty that impedes learning (too hard, irrelevant)"
      storage_strength: "How well encoded in memory"
      retrieval_strength: "How accessible right now"
      illusion_of_competence: "Feeling fluent does not equal actually knowing"

    algorithm:
      identify_desirable_difficulties:
        - "Spacing practice over time"
        - "Interleaving different topics"
        - "Testing instead of re-reading"
        - "Varying practice conditions"
        - "Generating answers before seeing them"
      implement_strategically:
        - "Add difficulties after initial acquisition"
        - "Ensure difficulty is surmountable"
        - "Explain to learners why it feels hard"

    prioritization_rules:
      1_fluency_is_misleading:
        rule: "Don't optimize for feeling of ease"
        reason: "Fluent learning often produces fragile knowledge"
        reframe: "Struggle is a feature, not a bug"

      2_introduce_after_acquisition:
        rule: "Basic competence first, then add difficulties"
        reason: "Difficulty must be achievable to be desirable"
        timing: "Not during initial learning phase"

      3_choose_productive_difficulties:
        rule: "Use evidence-based difficulties"
        desirable:
          - "Spacing (vs massing)"
          - "Interleaving (vs blocking)"
          - "Testing/retrieval (vs re-reading)"
          - "Varying conditions (vs constant)"
          - "Generation (vs reception)"
        undesirable:
          - "Unclear instructions"
          - "Irrelevant complexity"
          - "Beyond current capability"
          - "Excessive time pressure"

      4_explain_the_paradox:
        rule: "Tell learners why struggle helps"
        reason: "Otherwise they'll seek easier (worse) methods"
        message: "This feels hard because it's working"

    types_of_desirable_difficulty:
      spacing:
        description: "Distribute practice over time"
        why_hard: "Memory has decayed, must retrieve"
        why_good: "Retrieval strengthens memory"
      interleaving:
        description: "Mix different problem types"
        why_hard: "Must identify type, can't use momentum"
        why_good: "Builds discrimination and retrieval"
      testing:
        description: "Retrieve from memory, don't re-read"
        why_hard: "Effortful recall vs passive review"
        why_good: "Retrieval practice strengthens memory"
      variation:
        description: "Change practice conditions"
        why_hard: "Can't rely on constant context"
        why_good: "Builds flexible, transferable knowledge"
      generation:
        description: "Produce answer before seeing it"
        why_hard: "Must think, not just recognize"
        why_good: "Deeper processing, better retention"

    comparison:
      vs_easy_learning: "Desirable difficulties embrace struggle"
      vs_worked_examples: "Both valid - examples for novices, difficulties for consolidation"
      vs_mastery: "Mastery checks achievement; difficulties enhance durability"

    anti_patterns:
      - "Avoiding all difficulty (fragile learning)"
      - "Difficulty that's impossible (undesirable)"
      - "Difficulty during initial learning (too early)"
      - "Optimizing for practice performance (wrong metric)"
      - "Ignoring learner frustration signals"

    example:
      context: "Studying for professional certification exam"
      easy_but_fragile:
        method: "Re-read notes, highlight, review same day"
        feel: "Feels productive, familiar, confident"
        result: "50% retention after 1 month"
      desirably_difficult:
        method:
          spacing: "Study topics on day 1, 3, 7, 14"
          interleaving: "Mix different topic types each session"
          testing: "Practice questions without notes first"
          variation: "Study in different locations, times"
          generation: "Write answers before checking"
        feel: "Feels harder, more effortful, less confident"
        result: "85% retention after 1 month"
      rationale: "Struggle during learning = strength during testing"

    source: "Cognitive Psychology - Robert & Elizabeth Bjork, Desirable Difficulties"

# ============================================
# STRATEGIC DECEPTION ORDERINGS
# ============================================
# These variations are for LEGITIMATE competitive, adversarial, and
# performance contexts. They derive from magic/illusion, military
# doctrine, game theory, poker strategy, and negotiation tactics.

  # ----------------------------------------
  # VARIATION 100: MISDIRECTION ATTENTION ORDERING
  # ----------------------------------------
  misdirection_attention:
    id: misdirection_attention_ordering
    name: "Misdirection Attention Ordering (Magician's Technique)"
    category: strategic_deception

    philosophy: |
      Control where the audience or opponent directs attention through
      sequencing. From stage magic: attention follows motion, novelty,
      and perceived importance. The secret move occurs when attention
      is elsewhere. Structure actions so critical operations happen
      during moments of managed distraction.

      LEGITIMATE USES: Magic performance, presentation surprise reveals,
      competitive strategy, authorized red team testing.

    when_to_use:
      - Magic or illusion performance requiring hidden actions
      - Presentations where surprise reveal enhances impact
      - Competitive contexts where opponent is watching your moves
      - Authorized penetration testing against monitored systems
      - Negotiation where some preparation should be invisible

    key_concepts:
      off_beat: "Moment when attention naturally relaxes after a peak"
      large_motion_cover: "Big movement conceals small movement"
      time_misdirection: "Delay between secret action and its reveal"
      attention_anchor: "Object or action that holds attention"
      natural_action: "Disguising meaningful action as incidental"

    algorithm:
      1_identify_critical_action: "What must happen unnoticed?"
      2_create_attention_anchor: "What will hold their attention?"
      3_time_separation: "Separate secret from reveal temporally"
      4_layer_naturalness: "Make critical action look incidental"
      5_commit_fully: "Your own attention must match misdirection"

    prioritization_rules:
      1_attention_anchor_first:
        rule: "Establish what audience should watch before secret move"
        reason: "Attention must be captured before redirecting"

      2_off_beat_timing:
        rule: "Execute critical action during attention relaxation"
        reason: "Post-peak attention is at its lowest"
        timing: "Immediately after a climax moment"

      3_large_covers_small:
        rule: "Use larger motion to cover smaller secret motion"
        reason: "Eye tracks large motion preferentially"

      4_time_misdirection:
        rule: "Separate dirty work from effect temporally"
        reason: "Suspicion attaches to moments just before reveal"

      5_natural_motivation:
        rule: "Every action must have apparent innocent reason"
        reason: "Unmotivated action draws scrutiny"

    variants:
      henning_large_motion: "Big gesture covers small secret"
      tamariz_off_beat: "Action during attention relaxation"
      slydini_misdirection: "Direct eye contact during secret move"
      time_delay: "Separate method from effect by time"

    comparison:
      vs_forcing: "Misdirection hides action; forcing directs choice"
      vs_false_pattern: "Misdirection manages attention; false pattern manages expectation"
      vs_tempo_disruption: "Misdirection is attention control; tempo is rhythm control"

    anti_patterns:
      - "Looking at your own secret action (gaze betrayal)"
      - "Rushing the secret action (motion draws attention)"
      - "No cover for critical moment (action is visible)"
      - "Unnecessary secrecy (overcomplicating what could be open)"
      - "Misdirection without legitimate purpose (manipulation)"

    example:
      context: "Product launch presentation with surprise announcement"
      secret: "Major acquisition to announce"
      misdirection_sequence:
        1_attention_anchor: "Begin with detailed quarterly results (expected content)"
        2_build_to_peak: "Celebrate a specific product milestone achievement"
        3_off_beat_transition: "While applause continues, bring acquisition executive to stage"
        4_reveal: "'And speaking of growth, let me introduce our new partners...'"
        5_impact: "Surprise is maximized because attention was on results, not guests"
      rationale: "Audience expected financial review; hidden context (stage guest) revealed at optimal moment"

    source: "Magic Theory - Slydini, Tamariz (Magic Rainbow), Henning Nelms (Magic and Showmanship)"

  # ----------------------------------------
  # VARIATION 101: FORCING CHOICE ORDERING
  # ----------------------------------------
  forcing_choice:
    id: forcing_choice_ordering
    name: "Forcing Choice Ordering (Conjurer's Choice)"
    category: strategic_deception

    philosophy: |
      Structure choices to guide the subject toward a desired outcome
      while maintaining their sense of free choice. From magic forcing:
      present options where all paths lead to your target, or where the
      target choice is psychologically most attractive. The subject
      believes they chose freely.

      LEGITIMATE USES: UX design for desired user journeys, negotiation
      (creating acceptable offer ranges), teaching (guided discovery),
      game design, presentations.

    when_to_use:
      - Magic performance requiring specific card/object selection
      - UX design where certain user paths are optimal
      - Negotiation presenting multiple acceptable alternatives
      - Teaching through guided discovery (Socratic method)
      - Presentations steering toward desired conclusions

    key_concepts:
      equivoque: "Reinterpreting any choice as leading to target"
      psychological_force: "Making target choice most attractive"
      multiple_outs: "Every choice path leads to acceptable outcome"
      primacy_recency: "First and last items are most chosen"
      hobsons_choice: "Illusion of choice with only one real option"

    algorithm:
      1_define_target: "What outcome do you need?"
      2_map_all_paths: "How can each possible choice lead there?"
      3_layer_attractiveness: "Make target inherently appealing"
      4_prepare_equivoque: "Script for reinterpreting alternate choices"
      5_present_as_free: "Frame as genuine open choice"

    prioritization_rules:
      1_multiple_outs_first:
        rule: "Design so any choice is acceptable before narrowing"
        reason: "Reduces risk of unrecoverable branch"

      2_psychological_primacy:
        rule: "Place target at first or last position in list"
        reason: "Primacy and recency effects bias selection"

      3_contrast_framing:
        rule: "Frame non-target options as slightly less attractive"
        reason: "Relative value, not absolute, drives choice"

      4_confident_presentation:
        rule: "Present all options with equal apparent weight"
        reason: "Differential emphasis reveals preference"

      5_graceful_equivoque:
        rule: "If alternate chosen, reframe naturally to target"
        reason: "Awkward recovery reveals the force"

    variants:
      classic_force: "Timing and positioning to make target most likely"
      equivoque_elimination: "Reinterpret choices to eliminate non-targets"
      psychological_force: "Target made most psychologically attractive"
      multiple_outs: "Design so any choice works"
      choice_architecture: "Behavioral economics nudge design"

    comparison:
      vs_misdirection: "Forcing guides choice; misdirection hides action"
      vs_anchoring: "Forcing directs choice; anchoring sets reference point"
      vs_strategic_revelation: "Forcing controls choice; revelation controls information"

    anti_patterns:
      - "Revealing disappointment at 'wrong' choice"
      - "No backup for alternate selections"
      - "Force is too obvious (subject feels manipulated)"
      - "Unethical forcing (against subject's genuine interests)"
      - "Single path with no outs (high failure risk)"

    example:
      context: "Negotiation with vendor on contract terms"
      target: "3-year contract at $X/year"
      forcing_structure:
        option_A: "1-year at $X+30% (higher price, less commitment)"
        option_B: "3-year at $X (target - balanced)"
        option_C: "5-year at $X-10% (lower price, very long commitment)"
        positioning: "Present in order A, B, C (target in middle, reasonable)"
        framing: "'We're flexible on term length...'"
        psychology: "B appears as the reasonable middle ground"
      equivoque_preparation:
        if_A_chosen: "Accept; note 'we can revisit for longer term next year'"
        if_C_chosen: "Accept; you got commitment and discount"
      rationale: "All options acceptable; framing makes target most attractive"

    source: "Magic Theory - Equivoque, Psychological Forces; Behavioral Economics - Choice Architecture (Thaler & Sunstein)"

  # ----------------------------------------
  # VARIATION 102: SIGNAL MANIPULATION ORDERING
  # ----------------------------------------
  signal_manipulation:
    id: signal_manipulation_ordering
    name: "Signal Manipulation Ordering (Game Theory Signaling)"
    category: strategic_deception

    philosophy: |
      Strategically order and craft signals to shape opponent beliefs
      and behavior. From game theory: signals can be cheap talk (costless,
      thus potentially unreliable), costly signals (expensive, thus credible),
      or screening (designed to elicit revealing responses). Order signals
      to build or undermine credibility as strategy requires.

      LEGITIMATE USES: Negotiation, competitive business strategy, poker,
      job market signaling, deterrence.

    when_to_use:
      - Negotiation where credibility affects outcomes
      - Competitive situations with strategic opponents
      - Poker and betting games with information asymmetry
      - Deterrence (making threats credible)
      - Screening candidates or partners for hidden information

    key_concepts:
      cheap_talk: "Costless signals - easy to fake, thus suspect"
      costly_signal: "Expensive signal - hard to fake, thus credible"
      screening: "Action that elicits revealing response"
      pooling_equilibrium: "Different types send same signal"
      separating_equilibrium: "Different types send different signals"
      signal_jamming: "Adding noise to opponent's information"

    algorithm:
      1_assess_information_asymmetry: "What do you know that they don't, and vice versa?"
      2_determine_credibility_needs: "Must you be believed, or do you benefit from uncertainty?"
      3_design_signal_sequence: "Order from cheap to costly, or vice versa"
      4_prepare_for_screening: "What tests will opponent apply?"
      5_monitor_and_adapt: "Observe responses and adjust signals"

    prioritization_rules:
      1_costly_signals_for_credibility:
        rule: "When must be believed, lead with costly signals"
        reason: "Expensive-to-fake signals are credible"
        example: "Warranty backs quality claim (costly if false)"

      2_cheap_talk_for_exploration:
        rule: "Use cheap talk to test opponent response"
        reason: "Low cost to probe, can be retracted"

      3_screening_before_commitment:
        rule: "Design tests to reveal opponent type before you commit"
        reason: "Information reduces risk of bad partnerships"

      4_signal_jamming_when_hiding:
        rule: "When hiding type, add noise to prevent separation"
        reason: "Multiple signals harder to decode"

      5_consistency_maintenance:
        rule: "Keep signal sequence internally consistent"
        reason: "Inconsistency reveals deception"

    variants:
      credibility_building: "Lead with costly signals, establish trust"
      bluff_signaling: "Cheap talk signals false strength"
      screening_sequence: "Tests designed to separate types"
      signal_jamming: "Noise added to prevent opponent learning"
      counter_signaling: "High types under-signal to separate from medium"

    comparison:
      vs_false_pattern: "Signaling shapes beliefs about type; false patterns shape predictions"
      vs_tempo_disruption: "Signaling is about content; tempo is about rhythm"
      vs_leveling: "Signaling is first-order; leveling is about thinking levels"

    anti_patterns:
      - "Costly signals without resources to back them (bluff called)"
      - "Cheap talk when credibility required (not believed)"
      - "Inconsistent signals (reveals deception)"
      - "Ignoring opponent's screening (type revealed)"
      - "Signaling in bad faith outside competitive context"

    example:
      context: "Startup negotiating with potential acquirer"
      information_asymmetry:
        startup_knows: "True revenue trajectory, other interested parties"
        acquirer_knows: "Industry comps, integration costs"
      signaling_sequence:
        1_costly_signal: "Hire prestigious investment bank (expensive; signals serious)"
        2_screening: "Ask acquirer about integration plans (reveals their valuation)"
        3_cheap_talk: "Mention 'significant strategic interest' (can't be verified)"
        4_costly_reinforcement: "Share audited financials (expensive if false)"
        5_deadline: "Set deadline for term sheet (costly if you walk away)"
      rationale: "Build credibility with costly signals; extract information through screening"

    source: "Game Theory - Spence (Job Market Signaling), Milgrom & Roberts (Limit Pricing), Poker Theory"

  # ----------------------------------------
  # VARIATION 103: LAYERED DECEPTION ORDERING
  # ----------------------------------------
  layered_deception:
    id: layered_deception_ordering
    name: "Layered Deception Ordering (Magruder's Principle)"
    category: strategic_deception

    philosophy: |
      From military deception doctrine: it is easier to maintain an
      existing belief than to change it (Magruder's Principle), and
      the most effective deceptions exploit what the target already
      expects (Jones's Dilemma - deceivers must work with target's
      existing beliefs). Layer deceptions to reinforce expected patterns
      while hiding true intent.

      LEGITIMATE USES: Military deception (authorized), red team exercises,
      competitive business strategy, poker, magic performance.

    when_to_use:
      - Military or security operations requiring deception
      - Red team penetration testing against security teams
      - Competitive situations where opponent is analyzing you
      - Poker against observant opponents
      - Magic when audience is looking for the method

    key_concepts:
      magruders_principle: "Easier to maintain existing belief than create new one"
      jones_dilemma: "Deception must work with target's existing beliefs"
      cover_story: "False explanation that matches target expectations"
      feint: "Action that appears to commit to one direction"
      maskirovka: "Russian doctrine - comprehensive concealment and deception"
      double_bluff: "Revealing true intent as if it were deception"

    algorithm:
      1_understand_target_expectations: "What does opponent already believe?"
      2_design_consistent_cover: "Create story that matches their beliefs"
      3_layer_supporting_evidence: "Multiple independent 'confirmations'"
      4_prepare_true_action: "Plan actual intent hidden beneath layers"
      5_time_the_reveal: "True action emerges when commitment point passed"

    prioritization_rules:
      1_confirm_expectations_first:
        rule: "Initial actions should match target's existing model"
        reason: "Magruder - maintaining belief is easier than changing it"

      2_multiple_independent_sources:
        rule: "Layer confirming signals from different channels"
        reason: "Multiple sources increase credibility"

      3_feint_before_main_effort:
        rule: "Commit resources to false direction visibly"
        reason: "Commitment makes feint credible"

      4_exploit_jones_dilemma:
        rule: "Design deception to match what target wants to believe"
        reason: "Confirmation bias reinforces deception"

      5_true_action_at_commitment:
        rule: "Execute true intent when target has committed to false model"
        reason: "Recovery time is insufficient"

    variants:
      feint_and_strike: "Visible commitment to false direction, then true action"
      double_bluff: "Reveal true intent; opponent assumes it must be false"
      maskirovka: "Comprehensive multi-layer concealment and misdirection"
      honeypot: "Attractive target that is actually trap"
      dead_drop: "Information designed to be 'discovered' by opponent"

    comparison:
      vs_misdirection: "Layered is belief maintenance; misdirection is attention"
      vs_false_pattern: "Layered exploits expectations; false pattern creates them"
      vs_signal_manipulation: "Layered is comprehensive; signals are specific messages"

    anti_patterns:
      - "Deception contradicts target's strong prior beliefs (fails Jones)"
      - "Single-layer deception (too easy to penetrate)"
      - "Inconsistency between deception layers (reveals cover)"
      - "Deception used outside legitimate competitive/security context"
      - "Underestimating opponent's intelligence gathering"

    example:
      context: "Red team security exercise - testing corporate breach response"
      target_expectations: "IT security monitors network, suspects external attacks"
      layered_deception:
        layer_1_surface: "Generate typical external probe traffic (expected)"
        layer_2_feint: "Launch visible phishing campaign against executives"
        layer_3_confirm: "Allow one phishing attempt to be 'caught' and reported"
        layer_4_true_action: "Physical social engineering through maintenance access"
        timing: "True action while security focused on network/email threats"
      magruder_application: "Security team's belief in network/email threat vector is confirmed and maintained"
      rationale: "Each layer reinforces expected attack pattern; true vector is orthogonal"

    source: "Military Deception Doctrine - Magruder's Principle, Jones's Dilemma, FM 90-2 (Battlefield Deception)"

  # ----------------------------------------
  # VARIATION 104: TEMPO DISRUPTION ORDERING
  # ----------------------------------------
  tempo_disruption:
    id: tempo_disruption_ordering
    name: "Tempo Disruption Ordering (Rhythm Control)"
    category: strategic_deception

    philosophy: |
      Control the rhythm and pace of engagement to disrupt opponent's
      decision cycle. From Boyd's OODA loop: whoever cycles faster gains
      advantage. Tempo disruption includes both acceleration (moving
      faster than opponent can react) and deceleration (inducing false
      patience before sudden action). Varying tempo prevents pattern
      recognition.

      LEGITIMATE USES: Competitive strategy, poker, sports, negotiation
      pacing, military operations, presentations.

    when_to_use:
      - Competitive situations where opponent is pattern-matching
      - Poker/games where betting rhythm contains information
      - Negotiations that have stalled or need momentum change
      - Sports competition with rhythm-based opponents
      - Military operations seeking to disrupt enemy decision cycle

    key_concepts:
      ooda_loop: "Observe-Orient-Decide-Act cycle"
      inside_the_loop: "Acting before opponent completes their cycle"
      tempo_acceleration: "Speed up to outpace opponent reaction"
      tempo_deceleration: "Slow down to lull, then sudden action"
      rhythm_variation: "Unpredictable pacing prevents pattern matching"
      action_forcing: "Creating situations requiring opponent response"

    algorithm:
      1_assess_opponent_tempo: "How fast is their decision cycle?"
      2_determine_strategy: "Faster, slower, or variable?"
      3_establish_initial_rhythm: "Create pattern (to later break)"
      4_time_disruption: "Change tempo at critical decision point"
      5_exploit_disruption: "Act during opponent's adjustment period"

    prioritization_rules:
      1_establish_baseline:
        rule: "Create consistent tempo first"
        reason: "Disruption requires a pattern to disrupt"

      2_vary_unpredictably:
        rule: "Don't follow predictable acceleration/deceleration"
        reason: "Meta-pattern becomes new pattern to exploit"

      3_time_to_decision_points:
        rule: "Disrupt tempo when opponent must commit"
        reason: "Maximum impact at commitment moments"

      4_ooda_advantage:
        rule: "Complete your cycle before they complete theirs"
        reason: "Inside their loop means acting before they can react"

      5_recovery_exploitation:
        rule: "Act during opponent's tempo adjustment period"
        reason: "Adjustment consumes cognitive resources"

    variants:
      blitzkrieg_acceleration: "Overwhelming speed, no time for response"
      rope_a_dope_deceleration: "Absorb pressure, exhaust opponent, then explode"
      variable_tempo: "Unpredictable rhythm prevents pattern matching"
      false_urgency: "Create time pressure that doesn't exist"
      strategic_patience: "Wait for overextension before acting"

    comparison:
      vs_misdirection: "Tempo controls rhythm; misdirection controls attention"
      vs_ooda_loop: "Tempo disruption is specific application of OODA principle"
      vs_leveling: "Tempo is about speed; leveling is about prediction depth"

    anti_patterns:
      - "Constant high tempo (unsustainable, predictable)"
      - "Constant slow tempo (allows opponent to set pace)"
      - "Disruption without follow-through (wasted advantage)"
      - "Confusing your own team with tempo changes"
      - "Underestimating opponent's ability to adapt"

    example:
      context: "Poker tournament - heads up against aggressive opponent"
      opponent_pattern: "Fast, aggressive betting - puts pressure on"
      tempo_strategy:
        phase_1_absorb: "Play slowly, tank decisions, don't react to aggression"
        phase_2_establish: "Consistent slow rhythm; opponent adjusts, becomes impatient"
        phase_3_lull: "Continue slow play; opponent expects passive play"
        phase_4_disrupt: "Sudden aggressive 3-bet on strong hand"
        phase_5_exploit: "Opponent's adjustment period - uncertainty about your range"
      timing: "Tempo change on hand where you have position and strong holding"
      rationale: "Slow play established, sudden aggression maximally disruptive"

    source: "Military Strategy - Boyd's OODA Loop, Blitzkrieg Doctrine, Boxing Strategy (Ali 'Rope-a-Dope')"

  # ----------------------------------------
  # VARIATION 105: STRATEGIC REVELATION ORDERING
  # ----------------------------------------
  strategic_revelation:
    id: strategic_revelation_ordering
    name: "Strategic Revelation Ordering (Information Timing)"
    category: strategic_deception

    philosophy: |
      Control when information is revealed for maximum strategic effect.
      The same information has different impacts depending on timing,
      context, and recipient state. Early revelation may prevent action;
      late revelation may maximize surprise; staged revelation may shape
      interpretation. From Sun Tzu: "Let your plans be dark and
      impenetrable as night, and when you move, fall like a thunderbolt."

      LEGITIMATE USES: Product announcements, negotiation information
      disclosure, presentations, competitive strategy, poker.

    when_to_use:
      - Product/announcement timing for competitive advantage
      - Negotiations with staged information disclosure
      - Presentations building to key reveals
      - Competitive situations with information asymmetry
      - Legal strategy (disclosure timing)

    key_concepts:
      information_timing: "When information is revealed affects its impact"
      anchoring_effect: "First information shapes interpretation of later"
      primacy_recency: "First and last revelations have strongest impact"
      inoculation: "Early partial disclosure reduces impact of later full disclosure"
      surprise_value: "Unexpected information has greater psychological impact"
      commitment_timing: "Reveal after opponent committed for maximum effect"

    algorithm:
      1_inventory_information: "What do you know that others don't?"
      2_assess_impact_by_timing: "When would each revelation have maximum effect?"
      3_consider_opponent_decisions: "What will they commit to before knowing?"
      4_design_disclosure_sequence: "Order for strategic effect"
      5_prepare_contingencies: "If information leaks, what changes?"

    prioritization_rules:
      1_anchor_first:
        rule: "Lead with information that frames subsequent interpretation"
        reason: "Anchoring effect shapes all later processing"

      2_after_commitment:
        rule: "Reveal important information after opponent has committed"
        reason: "Switching costs make them continue despite new information"

      3_surprise_at_peak:
        rule: "Deliver surprise revelation at moment of maximum attention"
        reason: "Impact is proportional to attention at moment of reveal"

      4_inoculation_for_bad_news:
        rule: "Partial early disclosure for damaging information you can't hide"
        reason: "Reduces impact vs. opponent discovering and revealing"

      5_recency_for_action:
        rule: "Information requiring action should come last"
        reason: "Recency effect means most recent information drives decisions"

    variants:
      thunderbolt_reveal: "Complete surprise at maximum impact moment"
      staged_disclosure: "Graduated revelation to shape interpretation"
      anchoring_sequence: "Lead with frame-setting information"
      post_commitment_reveal: "Disclose after opponent has committed"
      inoculation_strategy: "Early partial reveal to defuse later exposure"
      information_drip: "Slow release to maintain engagement"

    comparison:
      vs_misdirection: "Revelation is about information timing; misdirection is attention"
      vs_signal_manipulation: "Revelation is about disclosure; signals are about credibility"
      vs_tension_arc: "Revelation is strategic; tension arc is narrative"

    anti_patterns:
      - "Revealing all information upfront (no strategic leverage)"
      - "Revelation timing that harms without strategic purpose"
      - "Poor security allowing uncontrolled leaks"
      - "Revelation that damages trust in ongoing relationships"
      - "Missing optimal revelation window (value decays)"

    example:
      context: "Tech company product launch vs competitor"
      information_inventory:
        feature_A: "Revolutionary new capability competitor lacks"
        pricing: "Aggressive pricing undercuts competitor"
        launch_date: "Ready before competitor's announced launch"
        partnerships: "Major integrations with popular platforms"
      strategic_revelation_sequence:
        step_1_inoculation: "Leak 'revolutionary changes coming' (creates anticipation)"
        step_2_timing: "Announce day before competitor's scheduled event"
        step_3_anchor: "Lead with partnerships (frames ecosystem strength)"
        step_4_thunderbolt: "Feature A reveal (maximum surprise)"
        step_5_close: "Pricing revealed last (recency drives purchase decision)"
      timing_rationale: "Competitor committed to their event timing; forced to react to our frame"

    source: "Sun Tzu (Art of War), Negotiation Theory - Strategic Information Disclosure, Product Launch Strategy"

  # ----------------------------------------
  # VARIATION 106: FALSE PATTERN ORDERING
  # ----------------------------------------
  false_pattern:
    id: false_pattern_ordering
    name: "False Pattern Ordering (Expectation Manipulation)"
    category: strategic_deception

    philosophy: |
      Establish a pattern that opponent learns to expect, then exploit
      that expectation. Humans are pattern-matching machines - we cannot
      help but learn regularities. By deliberately creating a pattern,
      you control what opponent expects; by breaking it strategically,
      you exploit that expectation. The pattern is the trap.

      LEGITIMATE USES: Poker, sports strategy, magic performance,
      competitive business (predictable behavior then surprise pivot),
      military feints.

    when_to_use:
      - Poker/games where opponent tracks betting patterns
      - Sports against opponents who study film/patterns
      - Magic where audience is looking for method
      - Competitive situations with pattern-analyzing opponents
      - When you can afford investment in false pattern establishment

    key_concepts:
      pattern_establishment: "Consistent behavior that creates expectation"
      pattern_exploitation: "Acting contrary when opponent commits to pattern"
      investment_cost: "Resources spent establishing false pattern"
      commitment_point: "When opponent acts on pattern prediction"
      optimal_break_timing: "When breaking pattern yields maximum advantage"
      meta_pattern_risk: "Opponent learning your pattern of breaking patterns"

    algorithm:
      1_design_pattern: "What consistent behavior will you display?"
      2_establish_with_repetition: "How many instances needed for learning?"
      3_monitor_opponent_adaptation: "Watch for signs they've learned it"
      4_identify_exploitation_moment: "When will they commit to prediction?"
      5_execute_break: "Act contrary at maximum leverage moment"
      6_assess_meta_risk: "Can they learn your breaking pattern?"

    prioritization_rules:
      1_credible_pattern_first:
        rule: "Pattern must make sense independently"
        reason: "Nonsensical patterns aren't learned"

      2_sufficient_repetition:
        rule: "Establish pattern with enough instances"
        reason: "Too few instances = not learned; too many = wasted opportunity"
        guideline: "3-5 repetitions typically sufficient"

      3_monitor_adaptation:
        rule: "Watch for behavioral signs opponent has learned"
        reason: "Breaking before learning = no exploitation"

      4_high_stakes_break:
        rule: "Break pattern when stakes justify establishment cost"
        reason: "Pattern investment must be recouped"

      5_meta_awareness:
        rule: "Don't establish pattern of breaking patterns"
        reason: "Meta-pattern becomes exploitable"

    variants:
      betting_pattern_trap: "Consistent betting range, then exploit assumption"
      service_pattern_tennis: "Predictable serve placement, then change"
      business_predictability: "Regular strategy signals, then surprise pivot"
      magic_sequence_break: "Same moves repeatedly, then variation"
      military_feint: "Consistent patrol patterns, then variation"

    comparison:
      vs_misdirection: "False pattern is expectation; misdirection is attention"
      vs_layered_deception: "False pattern is specific; layered is comprehensive"
      vs_tempo_disruption: "False pattern is content; tempo is rhythm"

    anti_patterns:
      - "Breaking pattern before opponent has learned it"
      - "Insufficient investment in pattern establishment"
      - "Pattern that doesn't make strategic sense (not learned)"
      - "Predictable pattern-breaking becomes meta-pattern"
      - "Pattern establishment cost exceeds exploitation value"

    example:
      context: "Poker - deep in tournament against observant opponent"
      pattern_design: "Always 3-bet with premium hands from button; flat call with speculative hands"
      establishment_sequence:
        hand_1: "Flat call with suited connectors (pattern)"
        hand_2: "3-bet with AK (pattern)"
        hand_3: "Flat call with small pair (pattern)"
        hand_4: "3-bet with QQ (pattern)"
        observation: "Opponent now expects: 3-bet = strong, flat = speculative"
      exploitation:
        hand_5: "Dealt 87 suited on button; opponent has deep stack"
        action: "3-bet (against pattern)"
        opponent_assumption: "Hero has premium hand"
        exploitation: "If flop is low/connected, can represent overpairs with big bets"
      rationale: "Pattern investment pays off when opponent folds better hand to aggression"

    source: "Poker Theory - Balancing and Exploitation, Sports Strategy - Film Study Exploitation, Military Deception"

  # ----------------------------------------
  # VARIATION 107: LEVELING METAGAME ORDERING
  # ----------------------------------------
  leveling_metagame:
    id: leveling_metagame_ordering
    name: "Leveling Metagame Ordering (Thinking Levels)"
    category: strategic_deception

    philosophy: |
      Operate one level above opponent's strategic thinking. From game
      theory and poker: Level 0 thinks only about their own cards;
      Level 1 thinks about what opponent has; Level 2 thinks about
      what opponent thinks you have; Level 3 thinks about what opponent
      thinks you think they have. The key is matching your level to
      one above your opponent's - going too deep is wasted.

      LEGITIMATE USES: Poker, negotiation, competitive strategy,
      game playing, auction bidding.

    when_to_use:
      - Poker or strategic games against thinking opponents
      - Negotiations where both sides are gaming each other
      - Competitive situations with strategic interaction
      - Auctions and bidding competitions
      - Any adversarial context with information asymmetry

    key_concepts:
      level_0: "What do I have? Play straightforwardly."
      level_1: "What do they have? Respond to their likely holdings."
      level_2: "What do they think I have? Exploit their model of me."
      level_3: "What do they think I think they have? Counter-exploit."
      level_matching: "One level above opponent is optimal"
      leveling_war: "Escalating levels leads to instability"

    algorithm:
      1_assess_opponent_level: "How sophisticated is their thinking?"
      2_operate_one_above: "Don't go too deep; one level up is sufficient"
      3_adjust_dynamically: "Opponent may level up after being exploited"
      4_avoid_leveling_wars: "Infinite regress is counterproductive"
      5_simplify_when_uncertain: "If level unknown, play fundamentally sound"

    prioritization_rules:
      1_assess_before_assuming:
        rule: "Determine opponent level through observation, not assumption"
        reason: "Overestimating leads to over-leveling; underestimating to exploitation"

      2_one_level_up:
        rule: "Operate exactly one level above opponent"
        reason: "Level 3 vs Level 0 opponent = wasted sophistication"

      3_dynamic_adjustment:
        rule: "Upgrade your level if opponent demonstrates they've leveled up"
        reason: "Static level becomes exploitable"

      4_fundamental_soundness:
        rule: "When uncertain, fall back to game-theoretically optimal play"
        reason: "GTO is unexploitable even if not maximally exploitative"

      5_avoid_infinite_regress:
        rule: "Don't chase infinite leveling depth"
        reason: "Beyond level 3-4, simplify and play balanced"

    variants:
      level_1_vs_level_0: "Simple exploitation of straightforward play"
      level_2_exploitation: "Exploiting opponent's model of you"
      level_3_counter_exploit: "Counter their exploitation attempt"
      gto_base: "Game-theory optimal as foundation, exploits as adjustments"
      mixed_strategy: "Randomization to prevent leveling exploitation"

    comparison:
      vs_false_pattern: "Leveling is about prediction depth; pattern is about expectations"
      vs_signal_manipulation: "Leveling is about thinking; signals are about credibility"
      vs_tempo_disruption: "Leveling is cognitive; tempo is rhythmic"

    anti_patterns:
      - "Over-leveling against unsophisticated opponent"
      - "Under-leveling against strong opponent"
      - "Assuming static opponent level (no adaptation)"
      - "Getting lost in infinite regress (analysis paralysis)"
      - "Ego-driven deep leveling (not strategic)"

    example:
      context: "Poker - River decision against specific opponent"
      situation: "Board shows possible flush; you have top pair"
      opponent_assessment:
        observation: "This opponent has folded to river bets frequently"
        inference: "Level 0-1 player - thinks about their own hand, maybe yours"
      your_level_2_thinking:
        their_level_1: "They think: 'Does he have the flush?'"
        your_adjustment: "They likely fold non-flush hands to big bets"
        action: "Bet large representing flush (they don't think about what you think)"
      contrast_if_level_2_opponent:
        their_thinking: "He knows I fold to flush bets, so he'd bluff here"
        your_level_3: "Check back; they might call with weak hand expecting bluff"
      rationale: "Match your level to one above theirs, not infinitely higher"

    source: "Game Theory - Cognitive Hierarchy Theory, Poker Theory - Levels of Thinking, Auction Theory"

# ============================================
# DETECTION & VERIFICATION ORDERINGS
# ============================================
# These variations are for detecting cheating, fraud, deception, and
# anomalies. They structure investigative and verification steps to
# maximize detection probability while minimizing false positives.

  # ----------------------------------------
  # VARIATION 108: FORENSIC AUDIT ORDERING
  # ----------------------------------------
  forensic_audit:
    id: forensic_audit_ordering
    name: "Forensic Audit Ordering (Red Flag Detection)"
    category: detection_verification

    philosophy: |
      Start with automated red flag detection to identify anomalies, then
      progressively narrow investigation scope through targeted analysis.
      The ordering follows the forensic accounting principle: cast a wide
      net first for statistical anomalies, then deep-dive on suspicious
      patterns. This prevents tunnel vision and ensures systematic coverage
      while efficiently allocating investigative resources.

    when_to_use:
      - Investigating potential financial fraud
      - Auditing large transaction datasets
      - Detecting embezzlement or asset misappropriation
      - Compliance audits requiring fraud detection
      - Insurance claim verification

    key_concepts:
      red_flags: "Warning signs that warrant further investigation"
      fraud_triangle: "Opportunity, pressure, rationalization - conditions for fraud"
      sampling_risk: "Possibility fraud exists in untested population"
      analytical_procedures: "Comparing data against expected patterns"
      substantive_testing: "Direct verification of account balances"

    algorithm:
      phase_1_pattern_analysis:
        - "Run statistical anomaly detection on full dataset"
        - "Apply Benford's Law to check digit distributions"
        - "Identify round number clustering (fabrication signal)"
        - "Check for duplicate entries, gaps in sequences"
        - "Analyze timing patterns (weekend, month-end, year-end)"
      phase_2_relationship_mapping:
        - "Map vendor/customer relationships to employees"
        - "Identify shell company indicators"
        - "Cross-reference addresses, phone numbers, bank accounts"
        - "Look for related-party transaction patterns"
      phase_3_targeted_sampling:
        - "Select high-risk transactions for substantive testing"
        - "Verify existence (confirm vendors/customers exist)"
        - "Verify authorization (check approval chains)"
        - "Verify documentation (match to physical evidence)"
      phase_4_confession_interview:
        - "Confront with evidence pattern, not specific allegation"
        - "Allow opportunity for explanation"
        - "Document admissions carefully"

    prioritization_rules:
      1_automated_first:
        rule: "Run automated detection before manual investigation"
        reason: "Broad coverage prevents sophisticated fraudsters from exploiting selective attention"

      2_unexpected_patterns:
        rule: "Prioritize unexpected over obviously suspicious"
        reason: "Sophisticated fraud hides in normal-looking transactions; obvious fraud is usually detected by controls"

      3_follow_the_money:
        rule: "Trace funds to ultimate beneficiary before alleging motive"
        reason: "Financial benefit identifies the perpetrator; motive is often misattributed"

      4_corroborate_before_confront:
        rule: "Build evidence case before interviewing suspect"
        reason: "Premature confrontation allows time to destroy evidence or prepare explanations"

    variants:
      occupational_fraud:
        focus: "Employee theft and asset misappropriation"
        additional_steps:
          - "Compare lifestyle to income"
          - "Check for unusual employee-vendor relationships"
      financial_statement_fraud:
        focus: "Management manipulation of financial reports"
        additional_steps:
          - "Revenue recognition analysis"
          - "Journal entry testing (especially manual, period-end)"
      corruption:
        focus: "Bribery and kickbacks"
        additional_steps:
          - "Bid-rigging pattern analysis"
          - "Commission and fee analysis"

    comparison:
      vs_traditional_audit: "Traditional audit assumes good faith; forensic audit assumes deception possible"
      vs_fail_fast: "Both identify problems early, but forensic preserves evidence chain"
      vs_random_sampling: "Forensic uses risk-based targeting, not random selection"

    anti_patterns:
      - "Starting with accusation before gathering evidence"
      - "Relying only on management representations"
      - "Focusing on individual transactions without pattern analysis"
      - "Ignoring red flags because perpetrator seems trustworthy"
      - "Alerting suspect before securing evidence"

    example:
      context: "Investigating suspected vendor fraud at company"
      steps:
        - "Interview purchasing manager"
        - "Review all vendor contracts manually"
        - "Run duplicate payment analysis"
        - "Check for round-number invoices"
        - "Verify vendor addresses"
        - "Cross-reference employee addresses with vendors"
      forensic_audit_order:
        1: "Run duplicate payment analysis (automated, broad coverage)"
        2: "Check for round-number invoice clustering (statistical anomaly)"
        3: "Cross-reference employee addresses with vendors (relationship mapping)"
        4: "Verify suspicious vendor addresses physically exist"
        5: "Review flagged vendor contracts (targeted substantive testing)"
        6: "Interview purchasing manager (only after evidence gathered)"
      rationale: "Build evidence systematically; don't tip off perpetrator until case is solid"

    source: "ACFE Fraud Examiners Manual; Forensic Accounting and Fraud Examination (Hopwood, Leiner, Young)"

  # ----------------------------------------
  # VARIATION 109: BENFORD ANOMALY ORDERING
  # ----------------------------------------
  benford_anomaly:
    id: benford_anomaly_ordering
    name: "Benford Anomaly Ordering (Statistical Distribution Detection)"
    category: detection_verification

    philosophy: |
      Use mathematical laws about naturally-occurring number distributions
      to identify fabricated data, then investigate deviations. Benford's
      Law states that in many real-world datasets, leading digits follow
      a specific logarithmic distribution (1 appears ~30%, 9 appears ~5%).
      Fabricated numbers deviate from this pattern because humans intuitively
      spread digits more uniformly. Order analysis from broad statistical
      tests to specific transaction investigation.

    when_to_use:
      - Large datasets of naturally-occurring numbers
      - Tax return analysis
      - Financial statement audits
      - Election result verification
      - Scientific data integrity checks
      - Insurance claim analysis

    key_concepts:
      benfords_law: "P(d) = log10(1 + 1/d) for first digit d"
      expected_distribution: "1: 30.1%, 2: 17.6%, 3: 12.5%, 4: 9.7%, 5: 7.9%, 6: 6.7%, 7: 5.8%, 8: 5.1%, 9: 4.6%"
      chi_squared_test: "Statistical test for goodness of fit"
      fabrication_signals: "Excess 5s, uniform distribution, avoidance of 1s"
      scale_invariance: "Benford applies regardless of units (dollars, euros, etc.)"

    algorithm:
      phase_1_applicability_check:
        - "Verify dataset spans multiple orders of magnitude"
        - "Confirm numbers arise naturally (not assigned)"
        - "Check minimum sample size (typically n > 500)"
        - "Verify numbers aren't constrained (not prices like $9.99)"
      phase_2_first_digit_analysis:
        - "Extract first significant digit from all values"
        - "Calculate observed frequency distribution"
        - "Compare to expected Benford distribution"
        - "Calculate chi-squared statistic and p-value"
      phase_3_second_digit_analysis:
        - "Repeat analysis for second significant digits"
        - "Check first-two digits combination"
        - "Second digit more sensitive to manipulation"
      phase_4_spike_investigation:
        - "Identify specific digits with excess frequency"
        - "Pull transactions with those leading digits"
        - "Analyze for common characteristics"
      phase_5_targeted_verification:
        - "Substantively test flagged transactions"
        - "Verify documentation and authorization"

    prioritization_rules:
      1_confirm_applicability:
        rule: "Verify Benford's Law applies before drawing conclusions"
        reason: "Not all datasets follow Benford; false positives waste resources"
        inapplicable_cases:
          - "Assigned numbers (phone numbers, zip codes)"
          - "Small range data (percentages 0-100)"
          - "Constrained transactions (reimbursements with max limits)"
          - "Price-clustered data (consumer prices at .99)"

      2_multiple_digit_positions:
        rule: "Test first digit, second digit, and first-two digits"
        reason: "Sophisticated manipulators may defeat first-digit test but fail second-digit"

      3_investigate_spikes_not_dips:
        rule: "Focus on over-represented digits, not under-represented"
        reason: "Under-representation is usually natural variation; spikes indicate fabrication"

      4_segmented_analysis:
        rule: "Run Benford separately on subsets (by vendor, time period, type)"
        reason: "Aggregation can hide manipulation in specific segments"

    variants:
      election_forensics:
        focus: "Vote count verification"
        additional_tests:
          - "Precinct-level analysis"
          - "Compare to historical patterns"
          - "Second-digit test more sensitive here"
      tax_evasion:
        focus: "Income and expense fabrication"
        additional_tests:
          - "Compare personal to business accounts"
          - "Year-over-year consistency"
      scientific_fraud:
        focus: "Research data fabrication"
        additional_tests:
          - "Compare to raw data if available"
          - "Check for terminal digit preferences"

    comparison:
      vs_random_sampling: "Benford provides mathematical basis for flagging; sampling is arbitrary"
      vs_forensic_audit: "Benford is one tool within forensic audit framework"
      vs_manual_review: "Benford scales to millions of records instantly"

    anti_patterns:
      - "Applying Benford to inapplicable data types"
      - "Using only first-digit test (sophisticated fraud defeats it)"
      - "Concluding fraud from statistics alone without corroboration"
      - "Ignoring base rates (some deviation is normal)"
      - "Running on datasets too small for statistical significance"

    example:
      context: "Auditing expense reports for fabricated receipts"
      steps:
        - "Review receipts over $500 manually"
        - "Check for round numbers"
        - "Run Benford analysis on all expenses"
        - "Interview employees with unusual patterns"
        - "Verify vendor existence"
      benford_order:
        1: "Run first-digit Benford test on all expense amounts (n=15,000)"
        2: "Run second-digit test (more sensitive to careful fabrication)"
        3: "Segment by employee and re-run (identify individuals)"
        4: "Flag employees with chi-squared > critical value"
        5: "Pull flagged employees' receipts, especially those starting with over-represented digits"
        6: "Verify vendor existence for flagged transactions"
        7: "Interview employees only after documentation review"
      rationale: "Statistical approach identifies suspects before labor-intensive verification"

    source: "Benford's Law: Applications for Forensic Accounting, Auditing, and Fraud Detection (Nigrini)"

  # ----------------------------------------
  # VARIATION 110: ACADEMIC INTEGRITY ORDERING
  # ----------------------------------------
  academic_integrity:
    id: academic_integrity_ordering
    name: "Academic Integrity Ordering (Plagiarism and Cheating Detection)"
    category: detection_verification

    philosophy: |
      Layer multiple detection methods from automated screening through
      targeted verification to oral defense. Academic cheating has evolved
      to defeat single-method detection, so the ordering must combine
      statistical analysis, content matching, behavioral signals, and
      competency verification. The key insight is that cheaters often
      fail competency checks even when content-matching tools miss them.

    when_to_use:
      - Grading academic submissions
      - Reviewing research papers for fabrication
      - Proctoring examinations
      - Thesis defense preparation
      - Credential verification

    key_concepts:
      contract_cheating: "Purchasing custom-written work (defeats plagiarism detection)"
      collusion: "Unauthorized collaboration (similar errors, phrasing)"
      competency_gap: "Submission quality exceeds demonstrable knowledge"
      stylometry: "Writing style fingerprint analysis"
      citation_manipulation: "Fake or misleading references"

    algorithm:
      phase_1_automated_screening:
        - "Run plagiarism detection (Turnitin, similarity matching)"
        - "Check citation validity (do references exist?)"
        - "Analyze metadata (creation date, author, revision history)"
        - "Compare writing style to baseline (if available)"
      phase_2_pattern_analysis:
        - "Compare submissions within cohort (collusion detection)"
        - "Identify unusual sophistication jumps between assignments"
        - "Check for identical errors or unusual patterns"
        - "Analyze submission timing and editing patterns"
      phase_3_competency_verification:
        - "Verbal questions about submission content"
        - "Ask to explain methodology or derive conclusions"
        - "Request clarification on specific passages"
        - "Note response latency and confidence"
      phase_4_evidence_correlation:
        - "Correlate competency gaps with other red flags"
        - "Check for patterns across multiple submissions"
        - "Document evidence chain for formal proceedings"

    prioritization_rules:
      1_automated_first_but_not_only:
        rule: "Start with automated tools but never rely solely on them"
        reason: "Contract cheating and AI-generated content often defeats content-matching"

      2_baseline_comparison:
        rule: "Establish baseline performance before flagging anomalies"
        reason: "Students improve; genuine growth shouldn't trigger false positives"

      3_competency_over_content:
        rule: "Prioritize competency verification over content similarity"
        reason: "Can't fake understanding in real-time verbal examination"

      4_pattern_over_instance:
        rule: "Look for patterns across submissions, not single red flags"
        reason: "Single anomalies have innocent explanations; patterns indicate systematic cheating"

    variants:
      examination_proctoring:
        focus: "Real-time cheating during exams"
        additional_checks:
          - "Eye movement and gaze tracking"
          - "Background noise analysis"
          - "Browser/tab switching detection"
          - "Response time analysis"
      research_fraud:
        focus: "Data fabrication and falsification"
        additional_checks:
          - "Statistical analysis of reported results (GRIM, SPRITE)"
          - "Image manipulation detection"
          - "Raw data verification"
      credential_fraud:
        focus: "Fake degrees and transcripts"
        additional_checks:
          - "Direct verification with institution"
          - "Format and watermark analysis"
          - "Historical consistency check"

    comparison:
      vs_plagiarism_only: "Academic integrity includes cheating, fabrication, collusion beyond copying"
      vs_trust_based: "Trust but verify approach systematically checks rather than assuming good faith"
      vs_punitive_first: "Verification before accusation protects innocent students"

    anti_patterns:
      - "Relying solely on plagiarism software match percentages"
      - "Accusing without competency verification"
      - "Ignoring AI-generated content possibility"
      - "Treating all similarity as cheating (legitimate common phrases exist)"
      - "Confronting student without documented evidence"

    example:
      context: "Grading programming assignment with suspected contract cheating"
      steps:
        - "Run code similarity tool"
        - "Grade submission"
        - "Ask student about code in oral exam"
        - "Check code style against previous submissions"
        - "Review submission metadata"
      academic_integrity_order:
        1: "Run code similarity against cohort and internet (automated)"
        2: "Check submission metadata (creation date, file properties)"
        3: "Compare code style/idioms to student's previous work (baseline)"
        4: "Flag anomalies: unusual libraries, comments in different language, style shift"
        5: "Oral examination: ask student to explain specific functions and make small modifications"
        6: "Document competency gaps vs submission quality"
      rationale: "Even purchased code fails competency test; verbal exam is decisive"

    source: "International Center for Academic Integrity; Contract Cheating Research"

  # ----------------------------------------
  # VARIATION 111: ANTI-CHEAT BEHAVIORAL ORDERING
  # ----------------------------------------
  anti_cheat_behavioral:
    id: anti_cheat_behavioral_ordering
    name: "Anti-Cheat Behavioral Ordering (Statistical and Behavioral Analysis)"
    category: detection_verification

    philosophy: |
      Combine client-side detection, server-side statistical analysis, and
      human review in layers. Modern game anti-cheat recognizes that no
      single detection method is sufficient. Client detection catches simple
      cheats but is bypassable; statistical analysis catches impossible
      performance but misses subtle aim-assist; human review catches obvious
      cheaters but doesn't scale. The ordering builds evidence across methods
      before taking action.

    when_to_use:
      - Online game integrity
      - Competitive examination platforms
      - Performance-based assessments
      - Speed running verification
      - Trading or betting pattern analysis

    key_concepts:
      statistical_impossibility: "Performance beyond human capability bounds"
      reaction_time_analysis: "Sub-human response times indicate automation"
      behavioral_fingerprint: "Unique patterns in input timing, movement"
      kernel_level_detection: "Deep system inspection for cheat software"
      replay_analysis: "Post-hoc review of recorded sessions"

    algorithm:
      phase_1_passive_monitoring:
        - "Collect input telemetry (mouse movements, key timing)"
        - "Record performance metrics (accuracy, reaction time)"
        - "Establish behavioral fingerprint"
        - "Compare to population baselines"
      phase_2_statistical_analysis:
        - "Flag statistical outliers (accuracy > 99.9th percentile)"
        - "Check for inhuman reaction times"
        - "Analyze movement patterns (too smooth = aimbot)"
        - "Look for impossible positioning or timing"
      phase_3_integrity_verification:
        - "Memory scan for known cheat signatures"
        - "Check for debuggers or injection tools"
        - "Verify game client integrity"
        - "Analyze network traffic patterns"
      phase_4_behavioral_deep_dive:
        - "Review recorded sessions of flagged accounts"
        - "Look for tell-tale cheat behaviors (snapping to targets)"
        - "Analyze decision-making patterns"
        - "Check for consistent with skill level in other contexts"
      phase_5_adversarial_testing:
        - "Present scenarios designed to expose specific cheats"
        - "Vary conditions to test consistency"
        - "Use honeypot techniques (detectable cheats)"

    prioritization_rules:
      1_passive_before_active:
        rule: "Collect evidence silently before taking any action"
        reason: "Alerting cheaters allows them to evade or create new accounts"

      2_statistical_impossible_first:
        rule: "Start with clearly impossible performance, not merely suspicious"
        reason: "False positives damage trust; start with high-confidence cases"

      3_multiple_independent_signals:
        rule: "Require corroboration across detection methods"
        reason: "Each method has false positives; intersection has fewer"

      4_delay_punishment:
        rule: "Bank evidence and delay bans to obscure detection methods"
        reason: "Immediate bans reveal what triggered detection"

    variants:
      fps_games:
        focus: "Aim assistance and wall hacks"
        key_metrics:
          - "Pre-fire accuracy"
          - "Target acquisition time"
          - "Through-wall tracking"
      strategy_games:
        focus: "Map hacks and automation"
        key_metrics:
          - "Fog-of-war violations"
          - "APM consistency"
          - "Reaction to hidden events"
      speedrunning:
        focus: "Tool-assisted runs presented as human"
        key_metrics:
          - "Frame-perfect inputs"
          - "Input timing variance"
          - "Splice detection"

    comparison:
      vs_client_only: "Server-side analysis catches cheats that modify client data"
      vs_statistical_only: "Client verification catches cheats that hide statistics"
      vs_manual_only: "Automation scales; humans can only review flagged cases"

    anti_patterns:
      - "Relying solely on client-side detection (bypassable)"
      - "Banning immediately on first flag (reveals detection)"
      - "Using same detection across all skill levels (smurfs vs cheaters)"
      - "Ignoring context (professional players may have extreme stats legitimately)"
      - "Publishing detection methods (enables evasion)"

    example:
      context: "Investigating suspected aimbot in competitive FPS"
      steps:
        - "Ban player immediately"
        - "Check if player has cheat software installed"
        - "Review kill recordings manually"
        - "Analyze headshot percentage"
        - "Compare to player's historical stats"
      anti_cheat_order:
        1: "Pull player's historical performance baseline"
        2: "Calculate statistical deviation from baseline (sudden skill jump?)"
        3: "Analyze input telemetry (inhuman reaction times, perfect tracking)"
        4: "Check for signature aim patterns (snap-to-target, smooth tracking)"
        5: "Review recorded gameplay clips manually"
        6: "Cross-reference with known cheat behavior patterns"
        7: "If multiple signals converge, add to ban wave (delayed, not immediate)"
      rationale: "Build multi-source evidence case; delay ban to obscure detection"

    source: "Game Developers Conference Anti-Cheat talks; Valve Anti-Cheat documentation"

  # ----------------------------------------
  # VARIATION 112: BASELINE DEVIATION ORDERING
  # ----------------------------------------
  baseline_deviation:
    id: baseline_deviation_ordering
    name: "Baseline Deviation Ordering (Establish-Compare-Probe)"
    category: detection_verification

    philosophy: |
      Establish reliable behavioral baselines before attempting to detect
      deception. Deception detection is fundamentally about spotting deviation
      from normal behavior - but "normal" must be established first. Without
      baselines, there's no way to distinguish nervousness from deception,
      or unusual speech from lying. The ordering ensures baseline calibration
      happens in low-stakes, non-threatening contexts.

    when_to_use:
      - Interview-based investigations
      - Employee background screening
      - Insurance claim interviews
      - Security clearance interviews
      - Any deception detection context

    key_concepts:
      baseline_behavior: "Individual's normal responses under non-threatening conditions"
      calibration_questions: "Neutral questions to establish response patterns"
      verbal_baseline: "Normal speech rate, vocabulary, detail level"
      nonverbal_baseline: "Normal posture, eye contact, gestures"
      deviation_delta: "Difference between baseline and response to critical questions"

    algorithm:
      phase_1_environment_setup:
        - "Create comfortable, non-threatening atmosphere"
        - "Build rapport before substantive questions"
        - "Explain process to reduce anxiety-based false signals"
      phase_2_baseline_calibration:
        - "Ask verifiable neutral questions (biographical facts)"
        - "Observe response style, timing, detail level"
        - "Ask questions with known answers to calibrate truthful behavior"
        - "Note verbal patterns: hedging, qualifiers, specificity"
        - "Note nonverbal patterns: eye movement, posture, gestures"
      phase_3_comparison_questioning:
        - "Transition to investigation-relevant questions"
        - "Mirror question structure to calibration phase"
        - "Note deviations from established baseline"
        - "Use unexpected questions to prevent rehearsed responses"
      phase_4_deviation_probing:
        - "Return to questions that showed deviation"
        - "Request elaboration and additional detail"
        - "Check for consistency across retellings"
        - "Use strategic evidence disclosure"

    prioritization_rules:
      1_baseline_before_critical:
        rule: "Never ask critical questions before establishing baseline"
        reason: "Without baseline, cannot distinguish deception from personality"

      2_same_person_comparison:
        rule: "Compare individual to themselves, not to stereotypes"
        reason: "Base rates of behaviors vary wildly between individuals"

      3_context_matching:
        rule: "Baseline questions should match critical question format/stakes"
        reason: "Increased formality or stress naturally changes behavior"

      4_multiple_baselines:
        rule: "Establish baselines across different question types"
        reason: "Emotional vs factual questions produce different patterns"

    variants:
      cognitive_interview:
        focus: "Memory retrieval in witnesses"
        baseline_approach: "Context reinstatement, peripheral detail recall"
      forensic_interview:
        focus: "Criminal investigation"
        baseline_approach: "Establish truthful narrative style before critical questions"
      employment_screening:
        focus: "Background verification"
        baseline_approach: "Verify known employment history before disputed items"

    comparison:
      vs_no_baseline: "Baseline makes detection possible; without it, just guessing"
      vs_polygraph: "Polygraph attempts physiological baseline; behavioral is more reliable"
      vs_accusatory: "Baseline approach is rapport-based, not confrontational"

    anti_patterns:
      - "Jumping to critical questions immediately"
      - "Using population stereotypes instead of individual baseline"
      - "Establishing baseline under different conditions than interview"
      - "Treating any nervousness as deception"
      - "Ignoring that innocent people may be anxious about false accusation"

    example:
      context: "Interviewing employee about suspected expense fraud"
      steps:
        - "Directly ask about fraudulent transactions"
        - "Monitor for nervousness"
        - "Ask about their work history"
        - "Build rapport"
        - "Ask comparison questions about legitimate expenses"
      baseline_deviation_order:
        1: "Build rapport - discuss neutral topics (recent projects, weekend)"
        2: "Establish verbal baseline - ask about verified facts (start date, manager, office location)"
        3: "Establish detail baseline - ask about recent legitimate expense they submitted"
        4: "Ask about similar expense in investigation period (compare detail level)"
        5: "Ask about specific flagged transaction (note deviations from baseline)"
        6: "Probe deviations - request elaboration, check consistency"
      rationale: "Establish how this person talks when telling truth before assessing critical responses"

    source: "FBI Behavioral Analysis; Principles of Kinesic Interview and Interrogation"

  # ----------------------------------------
  # VARIATION 113: COGNITIVE LOAD INTERVIEW ORDERING
  # ----------------------------------------
  cognitive_load_interview:
    id: cognitive_load_interview_ordering
    name: "Cognitive Load Interview Ordering (Increase Load, Detect Strain)"
    category: detection_verification

    philosophy: |
      Lying is cognitively demanding - liars must suppress truth, construct
      plausible fabrication, monitor interviewer reactions, and maintain
      consistency. By strategically increasing cognitive load, deception
      becomes harder to maintain. Order questions to progressively increase
      mental demands, making deception more difficult and detectable. This
      approach leverages the fundamental asymmetry: truth-tellers access
      memory, liars construct and maintain fabrications.

    when_to_use:
      - Investigative interviews
      - Security screening interviews
      - Insurance claim verification
      - Research on statement validity
      - Any context where memory vs fabrication distinction matters

    key_concepts:
      cognitive_load: "Mental effort required to process and respond"
      load_sources: "Divided attention, working memory, monitoring, construction"
      truth_teller_advantage: "Memory retrieval is less demanding than fabrication"
      verbal_leakage: "Under load, truth accidentally emerges"
      detail_degradation: "Fabricated stories lose detail under load"

    algorithm:
      phase_1_baseline_establishment:
        - "Ask low-load questions to establish behavioral baseline"
        - "Simple biographical or neutral event recall"
        - "Note response latency, detail level, fluency"
      phase_2_moderate_load:
        - "Ask for more detail in target narrative"
        - "Request chronological then reverse chronological retelling"
        - "Ask about peripheral details (what others were doing)"
      phase_3_high_load_techniques:
        - "Divide attention during recall (secondary task)"
        - "Ask unexpected questions about stated narrative"
        - "Request drawing or spatial description while talking"
        - "Ask to tell story from different perspective"
      phase_4_comparison_analysis:
        - "Compare detail consistency across retellings"
        - "Note where story degraded vs enriched under load"
        - "Identify implausible additions or contradictions"
        - "Assess whether load increased or decreased detail (liars decrease)"

    prioritization_rules:
      1_rapport_before_load:
        rule: "Build rapport before applying cognitive pressure"
        reason: "Pressure without rapport produces resistance, not revelation"

      2_gradual_increase:
        rule: "Increase load progressively, not suddenly"
        reason: "Gradual increase prevents interviewee from recognizing technique"

      3_unexpected_over_repeated:
        rule: "Unexpected questions are higher load than repeated ones"
        reason: "Rehearsed answers handle repetition; novel questions require construction"

      4_detail_direction:
        rule: "Note whether detail increases or decreases under load"
        reason: "Truth-tellers produce more detail; liars produce less"

    variants:
      reverse_order:
        focus: "Reverse chronological recall"
        rationale: "Fabricated stories are encoded forward; reversing is difficult"
      drawing_interview:
        focus: "Sketch while describing"
        rationale: "Spatial and verbal processing compete; truth-tellers handle better"
      unanticipated_questions:
        focus: "Questions about aspects liar didn't prepare"
        rationale: "Liars plan answers to expected questions; unexpected reveals gaps"

    comparison:
      vs_baseline_only: "Baseline tells you normal; load reveals deviation"
      vs_confrontational: "Load approach is information-gathering, not accusatory"
      vs_traditional: "Traditional interviews reduce load (comfortable); this strategically increases it"

    anti_patterns:
      - "Maximum pressure immediately (produces shutdown, not information)"
      - "Same load for all questions (can't compare responses)"
      - "Ignoring that some people are naturally anxious"
      - "Treating any hesitation as deception"
      - "Using only one load technique (may not work for this individual)"

    example:
      context: "Investigating alibi for suspected insider theft"
      steps:
        - "Ask where they were at time of theft"
        - "Apply maximum cognitive load immediately"
        - "Accuse of lying"
        - "Ask to repeat story"
        - "Build rapport"
      cognitive_load_order:
        1: "Build rapport, establish baseline with neutral recall (last vacation)"
        2: "Ask for alibi narrative (moderate load, forward chronological)"
        3: "Ask for peripheral details (who else was there, what were they wearing)"
        4: "Ask to retell in reverse chronological order (high load)"
        5: "Ask unexpected questions (sounds heard, temperature, smells)"
        6: "Ask to sketch the location while describing again"
        7: "Compare detail richness across techniques (should increase if true)"
      rationale: "Progressive load increase makes fabrication increasingly difficult to maintain"

    source: "Aldert Vrij cognitive lie detection research; Strategic Use of Evidence (SUE)"

  # ----------------------------------------
  # VARIATION 114: PEACE MODEL ORDERING
  # ----------------------------------------
  peace_model:
    id: peace_model_ordering
    name: "PEACE Model Ordering (Ethical Interview Framework)"
    category: detection_verification

    philosophy: |
      Structure interviews to maximize information quality while maintaining
      ethical standards. PEACE (Planning, Engage, Account, Closure, Evaluate)
      emerged as an alternative to accusatory interrogation methods that
      produced false confessions. The ordering emphasizes obtaining complete
      accounts through rapport and active listening rather than pressure
      and confrontation. Information quality trumps confession quantity.

    when_to_use:
      - Investigative interviews (suspect, witness, victim)
      - Employee misconduct investigations
      - Compliance interviews
      - Child interview contexts
      - Any interview where false confession risk exists

    key_concepts:
      information_gathering: "Goal is accurate information, not confession"
      cognitive_interview_elements: "Memory-enhancing techniques integrated"
      conversation_management: "Structured but flexible approach"
      challenge_phase: "Present inconsistencies for explanation, not accusation"
      no_deception_allowed: "Interviewer never lies or misrepresents evidence"

    algorithm:
      planning_and_preparation:
        - "Review all available evidence and information"
        - "Identify knowledge gaps interview should fill"
        - "Prepare topic areas (not scripted questions)"
        - "Plan physical environment and timing"
        - "Decide on evidence disclosure strategy"
      engage_and_explain:
        - "Introduce self and explain interview purpose"
        - "Establish rapport through genuine interest"
        - "Explain process, rights, and expectations"
        - "Active listening and acknowledgment"
      account:
        - "Invite free narrative without interruption"
        - "Use open questions to expand account"
        - "Clarify and probe specific points"
        - "Challenge inconsistencies by asking for explanation"
        - "Summarize understanding and verify accuracy"
      closure:
        - "Summarize key points and findings"
        - "Invite any additions or corrections"
        - "Explain next steps in process"
        - "Ensure interviewee wellbeing"
      evaluation:
        - "Review interview against objectives"
        - "Assess information reliability and completeness"
        - "Identify follow-up investigation needs"
        - "Document lessons for future interviews"

    prioritization_rules:
      1_information_over_admission:
        rule: "Prioritize obtaining accurate information over securing admissions"
        reason: "False confessions are worse than no confession"

      2_listen_before_challenge:
        rule: "Get complete account before presenting contradictions"
        reason: "Interruptions limit information; full account reveals inconsistencies naturally"

      3_explain_rather_than_accuse:
        rule: "Ask interviewee to explain inconsistencies, don't accuse"
        reason: "Accusations produce defensiveness; requests for explanation produce information"

      4_never_deceive:
        rule: "Never lie about evidence or make false promises"
        reason: "Deception corrodes trust and produces unreliable information"

    variants:
      witness_interview:
        focus: "Maximizing memory retrieval"
        emphasis: "Cognitive interview techniques, context reinstatement"
      suspect_interview:
        focus: "Testing account against evidence"
        emphasis: "Strategic evidence disclosure, challenge phase"
      vulnerable_interviewee:
        focus: "Children, cognitive impairment"
        emphasis: "Simplified language, additional safeguards, intermediaries"

    comparison:
      vs_reid_technique: "PEACE is information-gathering; Reid is confession-oriented"
      vs_accusatory: "PEACE challenges accounts; accusatory methods confront persons"
      vs_polygraph: "PEACE assesses verbal account quality; polygraph measures physiology"

    anti_patterns:
      - "Leading or suggestive questions"
      - "Accusing before hearing complete account"
      - "Lying about evidence strength"
      - "Continuing after interviewee requests break or counsel"
      - "Prioritizing confession over accurate information"
      - "Multiple interviewers without clear roles"

    example:
      context: "Interviewing employee about suspected policy violation"
      steps:
        - "Confront with accusation"
        - "Demand explanation"
        - "Review evidence"
        - "Build rapport"
        - "Close interview"
      peace_order:
        1: "Planning - review incident report, evidence, witnesses, knowledge gaps"
        2: "Engage - introduce self, explain process, build rapport genuinely"
        3: "Account - invite their complete narrative without interruption"
        4: "Account - ask open questions to fill gaps"
        5: "Account - present inconsistencies as puzzles to explain"
        6: "Closure - summarize understanding, invite corrections"
        7: "Evaluate - assess information quality and next steps"
      rationale: "Complete account first; challenge after; information quality over admission"

    source: "PEACE Model (UK Home Office); Investigative Interviewing: Psychology and Practice"

  # ----------------------------------------
  # VARIATION 115: MICE ACCESS ORDERING
  # ----------------------------------------
  mice_access:
    id: mice_access_ordering
    name: "MICE Access Ordering (Counter-Intelligence Vulnerability Assessment)"
    category: detection_verification

    philosophy: |
      Assess insider threat risk by analyzing access, motivation, capability,
      and indicators in structured sequence. MICE (Money, Ideology, Coercion,
      Ego) represents the classic recruitment motivations; combined with access
      analysis, it identifies who could harm the organization and why they
      might. Order assessment from low-intrusiveness (access review) to
      high-intrusiveness (behavioral investigation).

    when_to_use:
      - Insider threat programs
      - Security clearance investigations
      - Sensitive position vetting
      - Post-incident attribution
      - Periodic reinvestigation

    key_concepts:
      mice_motivations:
        money: "Financial pressure or greed"
        ideology: "Disagreement with organization's mission"
        coercion: "Blackmail, threats to self or family"
        ego: "Desire for recognition, revenge, importance"
      access_analysis: "What could this person access or damage"
      behavioral_indicators: "Observable changes suggesting risk"
      whole_person: "Pattern of behavior, not single data points"
      continuous_evaluation: "Ongoing vs point-in-time assessment"

    algorithm:
      phase_1_access_mapping:
        - "Document systems, data, facilities person can access"
        - "Map critical assets to access levels"
        - "Identify access beyond role requirements"
        - "Review access request and usage patterns"
      phase_2_motivation_screening:
        - "Review for financial stress indicators (public records)"
        - "Assess ideological alignment (social media, statements)"
        - "Check for coercion vectors (travel, contacts, vulnerabilities)"
        - "Evaluate recognition needs (career trajectory, grievances)"
      phase_3_capability_assessment:
        - "Technical ability to exploit access"
        - "Knowledge of security controls and gaps"
        - "External connections that could enable harm"
      phase_4_indicator_monitoring:
        - "Access pattern anomalies"
        - "Behavioral changes (attitude, hours, stress)"
        - "Policy violations (even minor)"
        - "Foreign contact and travel"
      phase_5_holistic_assessment:
        - "Combine access + motivation + capability + indicators"
        - "Assess risk level and appropriate response"
        - "Document decision rationale"

    prioritization_rules:
      1_access_before_motivation:
        rule: "Understand what someone could do before analyzing why they might"
        reason: "Access determines harm potential; motivation determines likelihood"

      2_open_sources_first:
        rule: "Use open source and system data before intrusive investigation"
        reason: "Respect privacy; intrusive investigation only when justified"

      3_pattern_over_incident:
        rule: "Assess behavior patterns, not isolated incidents"
        reason: "Single events have innocent explanations; patterns indicate risk"

      4_continuous_not_point:
        rule: "Ongoing monitoring trumps periodic deep dives"
        reason: "Circumstances change; point-in-time assessment becomes stale"

    variants:
      pre_employment:
        focus: "Hiring screening"
        emphasis: "Background verification, reference checks"
      clearance_investigation:
        focus: "Government security clearance"
        emphasis: "Full scope background investigation"
      continuous_evaluation:
        focus: "Ongoing insider threat monitoring"
        emphasis: "Automated indicator monitoring, periodic reviews"

    comparison:
      vs_trust_based: "MICE acknowledges trusted insiders cause most damage"
      vs_perimeter_security: "Insider threat is beyond the firewall"
      vs_behavioral_only: "Access analysis provides context for behavior assessment"

    anti_patterns:
      - "Focusing only on external threats"
      - "Assuming cleared/vetted individuals are safe"
      - "Over-relying on technical controls without human assessment"
      - "Conducting invasive investigation without justification"
      - "Ignoring indicators because person is well-liked"
      - "Point-in-time check without continuous monitoring"

    example:
      context: "Assessing insider threat risk for system administrator"
      steps:
        - "Trust them because they're senior"
        - "Monitor their emails"
        - "Review their access levels"
        - "Check for motivation indicators"
        - "Investigate their finances"
      mice_access_order:
        1: "Map access - document all systems, data, privileges this role provides"
        2: "Review access patterns - any unusual access to systems outside role?"
        3: "Check financial indicators - public records for liens, judgments"
        4: "Assess ideological alignment - any expressed grievances or disagreements?"
        5: "Review behavioral indicators - changes in attitude, hours, cooperation?"
        6: "Check for coercion vectors - foreign contacts, vulnerable circumstances?"
        7: "Holistic assessment - combine factors, document risk level"
      rationale: "Systematic assessment from least to most intrusive; context before investigation"

    source: "NIST SP 800-53 (Insider Threat); Intelligence Community Directives"

  # ----------------------------------------
  # VARIATION 116: BEHAVIORAL TELLS ORDERING
  # ----------------------------------------
  behavioral_tells:
    id: behavioral_tells_ordering
    name: "Behavioral Tells Ordering (Poker-Derived Reading)"
    category: detection_verification

    philosophy: |
      Observe behavioral patterns for information leakage, establishing
      baseline before looking for deviations. Professional poker players
      have refined techniques for reading opponents that apply beyond the
      card table. The key insight is that tells are individual - the same
      behavior that indicates bluffing in one person indicates confidence
      in another. Baseline establishment and deviation detection are essential.

    when_to_use:
      - Negotiation and deal-making
      - Interview assessment
      - Sales and persuasion contexts
      - Competitive situations
      - Any high-stakes interpersonal interaction

    key_concepts:
      tell: "Unintentional behavior that reveals information"
      reverse_tell: "Deliberate fake tell to mislead"
      timing_tell: "Information revealed by response speed"
      betting_pattern: "Actions speak louder than physical tells"
      hand_reading: "Deducing situation from action sequence"

    algorithm:
      phase_1_baseline_observation:
        - "Observe behavior in low-stakes situations first"
        - "Note personal patterns (posture, speech rate, eye contact)"
        - "Identify individual's comfort behaviors"
        - "Establish timing norms for decisions"
      phase_2_pattern_cataloging:
        - "Track action patterns across multiple interactions"
        - "Note what behaviors accompany what outcomes"
        - "Build individual-specific tell library"
        - "Distinguish real tells from noise"
      phase_3_real_time_observation:
        - "Monitor baseline deviations during interaction"
        - "Note timing changes (faster or slower than usual)"
        - "Observe micro-expressions and involuntary reactions"
        - "Watch for inconsistency between verbal and nonverbal"
      phase_4_hypothesis_testing:
        - "Don't act on single observation"
        - "Look for confirming/disconfirming patterns"
        - "Probe to elicit more information"
        - "Update mental model based on outcomes"

    prioritization_rules:
      1_baseline_essential:
        rule: "Never assess without established baseline"
        reason: "Same behavior means different things for different people"

      2_action_over_acting:
        rule: "Weight actual decisions more than physical behaviors"
        reason: "Actions are harder to fake than expressions"

      3_timing_is_information:
        rule: "How long someone takes to respond reveals confidence"
        reason: "Genuine reactions are faster; calculated responses take time"

      4_pattern_over_instance:
        rule: "Single tells are unreliable; patterns are meaningful"
        reason: "Noise exists; signal emerges from repeated observation"

    variants:
      negotiation_context:
        focus: "Deal-making tells"
        key_tells:
          - "Reaction to your offer (genuine interest vs polite rejection)"
          - "Urgency signals (real deadline vs fake pressure)"
          - "Certainty displays (bluffing vs confident)"
      interview_context:
        focus: "Candidate assessment"
        key_tells:
          - "Comfort with specific topics"
          - "Rehearsed vs spontaneous answers"
          - "Confidence calibration (accurate self-assessment)"
      competitive_context:
        focus: "Opponent reading"
        key_tells:
          - "Strength vs weakness displays"
          - "Preparation level signals"
          - "Commitment indicators"

    comparison:
      vs_deception_detection: "Behavioral tells are broader than just detecting lies"
      vs_body_language_myths: "Real tells are individual and subtle, not universal"
      vs_intuition_only: "Systematic observation beats unconscious impression"

    anti_patterns:
      - "Relying on body language stereotypes (crossing arms means defensive)"
      - "Acting on single observations without confirmation"
      - "Ignoring that sophisticated opponents fake tells"
      - "Believing own tells are undetectable"
      - "Over-confidence in reading ability (most people are bad at this)"

    example:
      context: "Negotiating contract price with vendor"
      steps:
        - "Make offer and watch reaction"
        - "Trust gut feeling about their confidence"
        - "Push hard if they seem uncertain"
        - "Build rapport"
      behavioral_tells_order:
        1: "Small talk phase - observe baseline behaviors (posture, speech rate, eye contact)"
        2: "Low-stakes questions - establish response timing norms"
        3: "Present initial offer - observe immediate involuntary reaction"
        4: "Note timing of response (immediate vs delayed indicates preparation)"
        5: "Track consistency between verbal response and nonverbal signals"
        6: "Probe on specific terms - note which terms produce stress signals"
        7: "Form hypothesis about their true position; test with probing questions"
      rationale: "Baseline before high-stakes; involuntary reactions before calculated responses"

    source: "Caro's Book of Poker Tells; Reading Poker Tells (Elwood)"

  # ----------------------------------------
  # VARIATION 117: TRUST BUT VERIFY ORDERING
  # ----------------------------------------
  trust_but_verify:
    id: trust_but_verify_ordering
    name: "Trust But Verify Ordering (Progressive Verification)"
    category: detection_verification

    philosophy: |
      Extend trust provisionally while building verification systems. The
      Reagan doctrine for arms control applies broadly: don't let verification
      requirements block initial cooperation, but don't proceed without
      verification either. Order actions to enable trust while progressively
      building verification capability. Trust without verification is naive;
      verification without trust is hostile.

    when_to_use:
      - Partnership and vendor relationships
      - Employee management and delegation
      - International agreements
      - Supply chain management
      - Any situation requiring extended trust with risk

    key_concepts:
      provisional_trust: "Trust sufficient to begin, not unconditional"
      progressive_verification: "Verification grows with relationship"
      verification_infrastructure: "Systems to detect violation"
      red_lines: "Violations that terminate trust"
      trust_but_verify_loop: "Observe, verify, adjust trust level"

    algorithm:
      phase_1_initial_assessment:
        - "Assess reputation, track record, references"
        - "Identify what can be verified and what must be trusted"
        - "Define verification methods for verifiable claims"
        - "Define red lines and unacceptable violations"
      phase_2_provisional_extension:
        - "Extend trust sufficient for initial engagement"
        - "Limit exposure during trust-building phase"
        - "Make verification expectations explicit"
        - "Begin relationship with smaller stakes"
      phase_3_verification_implementation:
        - "Deploy verification mechanisms (audits, monitoring, check-ins)"
        - "Verify independently, don't just ask"
        - "Compare claimed vs observed outcomes"
        - "Document verification results"
      phase_4_trust_adjustment:
        - "Increase trust if verification passes consistently"
        - "Reduce trust if discrepancies found"
        - "Terminate if red lines crossed"
        - "Expand scope as trust is earned"
      phase_5_maintenance:
        - "Continue verification even after trust is established"
        - "Random deep-dives prevent complacency"
        - "Update red lines as relationship evolves"

    prioritization_rules:
      1_enable_before_constrain:
        rule: "Verification should enable trust, not replace it"
        reason: "Excessive control prevents the benefits of trust"

      2_proportional_verification:
        rule: "Match verification intensity to stakes"
        reason: "Over-verification is costly and damages relationships"

      3_verify_independently:
        rule: "Don't rely on the trusted party for verification data"
        reason: "Self-reporting can be manipulated"

      4_continuous_not_one_time:
        rule: "Verification must continue throughout relationship"
        reason: "Circumstances change; initial trust can decay"

    variants:
      vendor_management:
        focus: "Third-party risk management"
        verification_methods:
          - "SOC 2 audits"
          - "Penetration testing"
          - "Reference checks"
      employee_delegation:
        focus: "Management trust"
        verification_methods:
          - "Regular check-ins"
          - "Output review"
          - "360 feedback"
      international_agreements:
        focus: "Treaty compliance"
        verification_methods:
          - "On-site inspection"
          - "Technical monitoring"
          - "Intelligence collection"

    comparison:
      vs_blind_trust: "Trust but verify maintains healthy skepticism"
      vs_zero_trust: "Allows trust to build; zero-trust never trusts"
      vs_micromanagement: "Verification at appropriate intervals, not constant"

    anti_patterns:
      - "All trust, no verification (naive)"
      - "All verification, no trust (paranoid/controlling)"
      - "One-time verification then permanent trust"
      - "Verification that humiliates or demeans"
      - "No clear red lines or consequences"
      - "Trusting self-reported verification"

    example:
      context: "Hiring contractor for sensitive software project"
      steps:
        - "Trust them completely, they seem nice"
        - "Never check their work"
        - "Give full access immediately"
        - "Check references"
        - "Set up monitoring"
      trust_but_verify_order:
        1: "Initial assessment - verify credentials, check references independently"
        2: "Define red lines - code quality thresholds, security requirements"
        3: "Provisional extension - start with small, non-critical module"
        4: "Verify first deliverable - code review, security scan"
        5: "Adjust access - expand scope if verification passes"
        6: "Ongoing verification - periodic code reviews, access audits"
        7: "Trust earned - eventually larger scope with lighter verification"
      rationale: "Small initial trust, verified, expanded progressively based on track record"

    source: "Arms control theory; Vendor risk management frameworks"

  # ----------------------------------------
  # VARIATION 118: LAYERED VERIFICATION ORDERING
  # ----------------------------------------
  layered_verification:
    id: layered_verification_ordering
    name: "Layered Verification Ordering (Defense in Depth for Trust)"
    category: detection_verification

    philosophy: |
      Deploy multiple independent verification methods so that defeating
      one doesn't defeat all. Like defense-in-depth in security, layered
      verification ensures that sophisticated attempts to deceive face
      multiple hurdles. Each layer should catch different types of deception
      and operate independently. The ordering moves from cheap automated
      checks to expensive human review.

    when_to_use:
      - High-stakes verification decisions
      - Sophisticated adversarial contexts
      - Regulatory compliance requiring multiple controls
      - Any situation where single verification method is insufficient

    key_concepts:
      independence: "Layers should fail independently, not together"
      diversity: "Different methods catch different things"
      cost_ordering: "Cheap automated first, expensive human later"
      false_positive_management: "Multiple layers reduce false positives"
      coverage_mapping: "Know what each layer catches and misses"

    algorithm:
      phase_1_automated_screening:
        - "Apply automated checks first (cheapest, fastest)"
        - "Pattern matching, rules-based detection"
        - "Statistical anomaly detection"
        - "Flag for human review, don't reject automatically"
      phase_2_documentary_verification:
        - "Verify documentation against independent sources"
        - "Check internal consistency of documents"
        - "Cross-reference with external records"
      phase_3_testimonial_verification:
        - "Interview relevant parties separately"
        - "Check for consistency across accounts"
        - "Use cognitive load techniques if appropriate"
      phase_4_physical_verification:
        - "On-site inspection if feasible"
        - "Physical examination of relevant items"
        - "Environmental verification"
      phase_5_adversarial_testing:
        - "Red team attempts to defeat verification"
        - "Penetration testing of trust assumptions"
        - "Scenario planning for sophisticated deception"

    prioritization_rules:
      1_cheap_before_expensive:
        rule: "Run cheap automated checks before expensive human review"
        reason: "Filter obvious cases; reserve human judgment for edge cases"

      2_independent_layers:
        rule: "Each verification layer should work independently"
        reason: "Defeating one layer shouldn't defeat all"

      3_different_evidence_types:
        rule: "Use documentary, testimonial, and physical evidence"
        reason: "Different evidence types are fabricated differently"

      4_adversarial_assumption:
        rule: "Assume sophisticated actor trying to deceive"
        reason: "Design for adversary who knows your verification methods"

    variants:
      financial_audit:
        layers:
          - "Automated transaction analysis"
          - "Documentary verification"
          - "Management inquiry"
          - "Physical inventory"
          - "External confirmation"
      identity_verification:
        layers:
          - "Document authenticity check"
          - "Biometric matching"
          - "Knowledge-based authentication"
          - "Behavioral analysis"
          - "Third-party verification"
      supply_chain:
        layers:
          - "Supplier documentation"
          - "Third-party certification"
          - "On-site audit"
          - "Product testing"
          - "Track record analysis"

    comparison:
      vs_single_method: "Layered catches what single method misses"
      vs_redundant: "Layers are diverse (different methods), not redundant (same method repeated)"
      vs_sequential_only: "Some layers run parallel; not strictly sequential"

    anti_patterns:
      - "Single verification method regardless of stakes"
      - "Correlated layers (if one fails, others likely fail too)"
      - "Expensive layers before cheap (wasteful)"
      - "Assuming any layer is infallible"
      - "Not mapping coverage (blind spots remain)"

    example:
      context: "Verifying acquisition target's claimed customer base"
      steps:
        - "Trust their customer list"
        - "Manually call every customer"
        - "Review their documentation"
        - "Visit their office"
        - "Run automated checks on customer data"
      layered_verification_order:
        1: "Automated analysis - check customer list for patterns (duplicates, formatting anomalies)"
        2: "Documentary - cross-reference with billing records, contracts"
        3: "Statistical - compare revenue per customer to industry benchmarks"
        4: "Testimonial - randomly sample customers for direct confirmation"
        5: "Physical - visit office, observe operations"
        6: "Adversarial - ask what would fake customer list look like, check for those patterns"
      rationale: "Multiple independent methods; sophisticated fraud defeated by layer diversity"

    source: "Defense in depth security principles; Audit methodology literature"

# ============================================
# SELECTION PROCEDURE
# ============================================
selection_procedure:
  name: "Select Ordering Variation"
  version: "2.0.0"
  description: |
    A formalized system for selecting the optimal ordering variation.
    Combines a decision tree for rapid narrowing, a scoring system for
    nuanced multi-factor decisions, and a context questionnaire for
    gathering the information needed to decide.

  # ==========================================
  # CONTEXT QUESTIONNAIRE
  # ==========================================
  # Ask these questions BEFORE using the decision tree or scoring system
  context_questionnaire:
    instructions: |
      Answer each question to gather context. Questions are grouped by category.
      Answers feed into the decision tree and scoring system.

    categories:
      constraints:
        - id: Q_DEADLINE
          question: "Is there a hard deadline driving the work?"
          type: boolean
          follow_up:
            if_yes: Q_DEADLINE_IMMOVABLE
        - id: Q_DEADLINE_IMMOVABLE
          question: "Is the deadline immovable (external, contractual, event-based)?"
          type: boolean
        - id: Q_MULTIPLE_DEADLINES
          question: "Are there multiple deadlines for different deliverables?"
          type: boolean
        - id: Q_RESOURCE_LIMITED
          question: "Are resources (time, people, budget) severely constrained?"
          type: boolean
        - id: Q_DEPENDENCIES_STRICT
          question: "Are there strict technical dependencies that force ordering?"
          type: boolean

      uncertainty:
        - id: Q_FEASIBILITY_UNKNOWN
          question: "Is the feasibility of the work unknown or uncertain?"
          type: boolean
        - id: Q_REQUIREMENTS_CHANGING
          question: "Are requirements likely to change during execution?"
          type: boolean
        - id: Q_UNKNOWN_UNKNOWNS
          question: "Do you suspect there are unknown unknowns to discover?"
          type: boolean
        - id: Q_NEED_VALIDATION
          question: "Does this need validation from users/stakeholders before proceeding?"
          type: boolean

      executor:
        - id: Q_EXECUTOR_TYPE
          question: "Who will execute this work?"
          type: enum
          options: [human_solo, human_team, ai_agent, automated_system, mixed]
        - id: Q_TEAM_SIZE
          question: "If team, how many people?"
          type: number
          condition: Q_EXECUTOR_TYPE in [human_team, mixed]
        - id: Q_ENERGY_MATTERS
          question: "Does executor energy/fatigue need to be managed?"
          type: boolean
          condition: Q_EXECUTOR_TYPE in [human_solo, human_team]
        - id: Q_SESSION_LENGTH
          question: "How long is the work session?"
          type: enum
          options: [short_under_2h, medium_2_4h, long_over_4h, multi_day]

      stakes:
        - id: Q_IRREVERSIBLE_ACTIONS
          question: "Are there irreversible or hard-to-reverse actions?"
          type: boolean
        - id: Q_HIGH_COST_FAILURE
          question: "Would failure have high costs (financial, reputational, safety)?"
          type: boolean
        - id: Q_SAFETY_CRITICAL
          question: "Is this safety-critical work requiring redundancy?"
          type: boolean

      nature_of_work:
        - id: Q_LEARNING_PRIMARY
          question: "Is learning or skill-building a primary goal?"
          type: boolean
        - id: Q_CREATIVE_WORK
          question: "Is this primarily creative/generative work?"
          type: boolean
        - id: Q_OPTIMIZATION_WORK
          question: "Is this optimization/improvement of existing work?"
          type: boolean
        - id: Q_DEBUGGING_DIAGNOSTIC
          question: "Is this debugging or diagnostic work (finding root cause)?"
          type: boolean
        - id: Q_PRESENTATION_NARRATIVE
          question: "Is this for presentation to an audience?"
          type: boolean
        - id: Q_NEGOTIATION_CONTEXT
          question: "Is this in a negotiation or competitive context?"
          type: boolean

      military_strategy:
        - id: Q_ACTIVE_COMPETITOR
          question: "Is there an active competitor/adversary who will react to your actions?"
          type: boolean
        - id: Q_RAPID_TEMPO_NEEDED
          question: "Do you need to act faster than the environment/competition changes?"
          type: boolean
        - id: Q_DECISIVE_POINT_EXISTS
          question: "Is there one decisive point where victory would make everything else easier?"
          type: boolean
        - id: Q_DISTRIBUTED_EXECUTION
          question: "Will execution be distributed with need for local autonomy?"
          type: boolean
        - id: Q_RESOURCES_FOR_ALL_FRONTS
          question: "Do you have enough resources to fully address all objectives?"
          type: boolean
        - id: Q_MULTIPLE_SEPARATED_THREATS
          question: "Are you facing multiple separated threats/competitors?"
          type: boolean
        - id: Q_RISK_OF_OVEREXTENSION
          question: "Could success lead to overextension or unsustainable commitments?"
          type: boolean
        - id: Q_CAMPAIGN_HAS_PHASES
          question: "Does this work have distinct preparation, execution, and sustain phases?"
          type: boolean

      pedagogy:
        - id: Q_LONG_TERM_RETENTION
          question: "Is long-term retention more important than immediate performance?"
          type: boolean
        - id: Q_LEARNER_NOVICE
          question: "Is the learner a novice in this domain (no existing schemas)?"
          type: boolean
        - id: Q_MATERIAL_COMPLEX
          question: "Does the material have high intrinsic complexity (many interacting elements)?"
          type: boolean
        - id: Q_SKILLS_HIERARCHICAL
          question: "Are skills strictly hierarchical (gaps in earlier skills cause cascading failure)?"
          type: boolean
        - id: Q_MULTIPLE_TOPICS
          question: "Are there multiple related topics/skills to learn?"
          type: boolean
        - id: Q_INTUITION_BEFORE_FORMAL
          question: "Should learner build intuition before formal understanding?"
          type: boolean
        - id: Q_LEARNER_NEEDS_SUPPORT
          question: "Does the learner currently need scaffolding/support to succeed?"
          type: boolean
        - id: Q_PROCEDURAL_SKILLS
          question: "Are these procedural skills with clear solution steps?"
          type: boolean

      technical:
        - id: Q_MEMORY_CONSTRAINED
          question: "Is memory/working memory a constraint?"
          type: boolean
        - id: Q_PARALLEL_POSSIBLE
          question: "Can multiple steps run in parallel?"
          type: boolean
        - id: Q_HEURISTIC_AVAILABLE
          question: "Do you have a good heuristic for estimating progress/distance?"
          type: boolean
        - id: Q_EXPLORATION_NEEDED
          question: "Is exploration of solution space needed (vs. exploitation)?"
          type: boolean

  # ==========================================
  # DECISION TREE
  # ==========================================
  # Traverse from root, following yes/no branches until reaching a recommendation
  decision_tree:
    instructions: |
      Start at 'root'. For each node, evaluate the question.
      Follow 'yes' or 'no' branch. Continue until you reach a 'recommend' node.
      Some branches lead to the scoring system for more nuanced decisions.

    nodes:
      root:
        question: "Are step dependencies strict and technically enforced?"
        yes: strict_deps_branch
        no: deadline_check

      strict_deps_branch:
        question: "Is this a build/compile/dependency resolution task?"
        yes:
          recommend: topological_sort
          confidence: high
          rationale: "Explicit dependencies require topological ordering"
        no:
          recommend: topological_sort
          confidence: high
          rationale: "Strict dependencies must be respected regardless of context"

      deadline_check:
        question: "Is there a hard, immovable deadline?"
        yes: deadline_branch
        no: crisis_check

      deadline_branch:
        question: "Are there multiple competing deadlines?"
        yes:
          recommend: critical_ratio_dynamic
          confidence: high
          rationale: "Multiple deadlines need dynamic rebalancing"
        no: deadline_single_branch

      deadline_single_branch:
        question: "Is the deadline very tight with little buffer?"
        yes:
          recommend: deadline_driven
          confidence: high
          rationale: "Hard deadline with no slack dominates all other concerns"
        no: deadline_with_options

      deadline_with_options:
        question: "Is there significant uncertainty about feasibility?"
        yes:
          recommend: fail_fast
          confidence: high
          rationale: "Even with deadline, must validate feasibility early"
        no:
          recommend: deadline_driven
          confidence: medium
          rationale: "Deadline exists but has buffer; work backward from constraint"

      crisis_check:
        question: "Is this a crisis/emergency with limited resources?"
        yes: crisis_branch
        no: uncertainty_check

      crisis_branch:
        question: "Are multiple systems/issues competing for attention?"
        yes:
          recommend: triage_severity
          confidence: high
          rationale: "Crisis requires triage - save what can be saved"
        no:
          recommend: fail_fast
          confidence: high
          rationale: "Single crisis item - validate critical path immediately"

      uncertainty_check:
        question: "Is there high uncertainty about feasibility or requirements?"
        yes: uncertainty_branch
        no: executor_check

      uncertainty_branch:
        question: "Do you need user/stakeholder validation?"
        yes: validation_branch
        no: exploration_branch

      validation_branch:
        question: "Can you build a quick prototype or MVP?"
        yes:
          recommend: build_measure_learn
          confidence: high
          rationale: "Validate with minimal viable product before full build"
        no:
          recommend: fail_fast
          confidence: high
          rationale: "Identify feasibility blockers as early as possible"

      exploration_branch:
        question: "Is the solution space well-defined with a clear goal?"
        yes: search_strategy_branch
        no: open_exploration_branch

      search_strategy_branch:
        question: "Do you have a good heuristic to estimate distance to goal?"
        yes:
          recommend: heuristic_guided
          confidence: high
          rationale: "Use A* style search with your heuristic"
        no: no_heuristic_branch

      no_heuristic_branch:
        question: "Is memory/state tracking constrained?"
        yes:
          recommend: iterative_deepening
          confidence: high
          rationale: "Memory-efficient optimal search"
        no:
          recommend: breadth_first
          confidence: medium
          rationale: "Finds shortest path when heuristic unavailable"

      open_exploration_branch:
        question: "Is novelty/diversity more important than immediate quality?"
        yes:
          recommend: novelty_search
          confidence: medium
          rationale: "Maximize behavioral diversity, ignore fitness"
        no: exploration_quality_branch

      exploration_quality_branch:
        question: "Do you need both quality AND diversity?"
        yes:
          recommend: quality_diversity
          confidence: high
          rationale: "MAP-Elites or similar to fill behavior-performance space"
        no:
          recommend: epsilon_greedy
          confidence: medium
          rationale: "Simple exploration with tunable randomness"

      executor_check:
        question: "Is this being executed by a team (2+ people)?"
        yes: team_branch
        no: solo_executor_check

      team_branch:
        question: "Is wall-clock time the primary constraint?"
        yes:
          recommend: parallel_maximizing
          confidence: high
          rationale: "Maximize parallel execution to minimize elapsed time"
        no: team_other_concerns

      team_other_concerns:
        question: "Do team members have different skill levels?"
        yes:
          recommend: scaffolded_progression
          confidence: medium
          rationale: "Build skills incrementally, each step works standalone"
        no: use_scoring_system

      solo_executor_check:
        question: "Is executor a human (vs AI/automated)?"
        yes: human_solo_branch
        no: automated_branch

      human_solo_branch:
        question: "Is this a long work session (4+ hours)?"
        yes: long_session_branch
        no: short_session_branch

      long_session_branch:
        question: "Is motivation/energy currently low?"
        yes:
          recommend: momentum
          confidence: high
          rationale: "Build momentum with quick wins to restore energy"
        no:
          recommend: energy_envelope
          confidence: high
          rationale: "Plan peaks and valleys over extended session"

      short_session_branch:
        question: "Is there a mix of hard and easy tasks?"
        yes:
          recommend: energy_aware
          confidence: medium
          rationale: "Match difficulty to energy levels"
        no: nature_of_work_check

      automated_branch:
        question: "Is this a scheduling/assignment problem?"
        yes: scheduling_branch
        no: algorithmic_branch

      scheduling_branch:
        question: "Must items be processed fairly (no starvation)?"
        yes:
          recommend: round_robin
          confidence: high
          rationale: "Equal turns prevents starvation"
        no:
          recommend: priority_queue
          confidence: high
          rationale: "Dynamic priorities with arrivals/changes"

      algorithmic_branch:
        question: "Can the problem be divided into independent subproblems?"
        yes:
          recommend: divide_conquer
          confidence: high
          rationale: "Split, solve independently, combine results"
        no:
          recommend: greedy_local
          confidence: medium
          rationale: "Local optimum approach when divide-conquer not applicable"

      nature_of_work_check:
        question: "Is this primarily learning/skill-building?"
        yes: learning_branch
        no: work_type_branch

      learning_branch:
        question: "Are there strict prerequisites (topic A before topic B) where gaps cause cascading failure?"
        yes: mastery_vs_prereq
        no: learning_retention_check

      mastery_vs_prereq:
        question: "Is ensuring complete mastery at each stage critical?"
        yes:
          recommend: mastery_learning
          confidence: high
          rationale: "Gate progress on mastery to prevent accumulating gaps"
        no:
          recommend: prerequisite_chain
          confidence: high
          rationale: "Follow prerequisite dependencies for effective learning"

      learning_retention_check:
        question: "Is long-term retention more important than immediate performance?"
        yes: retention_learning_branch
        no: novice_check

      retention_learning_branch:
        question: "Are there multiple related topics/skills to learn?"
        yes:
          recommend: interleaved_practice
          confidence: high
          rationale: "Mixing topics forces discrimination and improves retention"
        no:
          recommend: spaced_repetition
          confidence: high
          rationale: "Optimal review intervals maximize retention with minimal effort"

      novice_check:
        question: "Is the learner a novice who needs scaffolding?"
        yes: novice_learning_branch
        no: complexity_check

      novice_learning_branch:
        question: "Are these procedural skills with clear solution steps?"
        yes:
          recommend: worked_examples
          confidence: high
          rationale: "Examples before practice reduces cognitive load for novices"
        no:
          recommend: fading_scaffolds
          confidence: high
          rationale: "Provide support initially, then gradually release responsibility"

      complexity_check:
        question: "Does the material have high intrinsic complexity (many interacting elements)?"
        yes:
          recommend: cognitive_load
          confidence: high
          rationale: "Sequence by element interactivity, build schemas before complexity"
        no: intuition_check

      intuition_check:
        question: "Should learner build intuition before formal understanding?"
        yes:
          recommend: spiral_curriculum
          confidence: high
          rationale: "Revisit topics at increasing depth, concrete before abstract"
        no:
          recommend: learning_optimized
          confidence: medium
          rationale: "Maximize information gain per unit effort"

      work_type_branch:
        question: "Is this debugging/diagnostic work?"
        yes:
          recommend: bisection_debugging
          confidence: high
          rationale: "Binary search to find root cause efficiently"
        no: presentation_check

      presentation_check:
        question: "Is this for presentation to an audience?"
        yes: presentation_branch
        no: optimization_check

      presentation_branch:
        question: "Might the audience not finish/read everything?"
        yes:
          recommend: inverted_pyramid
          confidence: high
          rationale: "Most important first, details in descending order"
        no:
          recommend: tension_arc
          confidence: high
          rationale: "Build dramatic tension to climax then resolve"

      optimization_check:
        question: "Is this optimization/improvement work?"
        yes:
          recommend: diminishing_returns
          confidence: high
          rationale: "Stop before returns drop below cost"
        no: investigation_check

      investigation_check:
        question: "Is this an investigation, audit, or verification task?"
        yes: investigation_branch
        no: strategic_deception_check

      investigation_branch:
        question: "Does it involve financial records or transaction data?"
        yes:
          recommend: forensic_audit
          confidence: high
          rationale: "Automated red flags first, then relationship mapping, then confrontation"
        no: interview_based_check

      interview_based_check:
        question: "Is this primarily interview-based investigation?"
        yes: interview_deception_branch
        no:
          recommend: layered_verification
          confidence: high
          rationale: "Multiple independent verification methods catch different deception types"

      interview_deception_branch:
        question: "Is building rapport and information quality more important than detection?"
        yes:
          recommend: peace_model
          confidence: high
          rationale: "Ethical interviewing - complete account before challenging"
        no:
          recommend: baseline_deviation
          confidence: high
          rationale: "Establish baseline before probing sensitive topics"

      strategic_deception_check:
        question: "Is this a legitimate competitive context where strategic misdirection is appropriate?"
        yes: deception_context_branch
        no: competitive_check

      deception_context_branch:
        question: "Is attention management the primary concern (magic, presentations)?"
        yes:
          recommend: misdirection_attention
          confidence: high
          rationale: "Control where audience directs attention"
        no: deception_game_theory_check

      deception_game_theory_check:
        question: "Is the opponent analyzing and predicting your patterns?"
        yes:
          recommend: leveling_metagame
          confidence: high
          rationale: "Operate one level above opponent's strategic thinking"
        no:
          recommend: signal_manipulation
          confidence: medium
          rationale: "Shape opponent beliefs through strategic signal ordering"

      competitive_check:
        question: "Is there an active competitor/adversary who will react to your actions?"
        yes: competitive_branch
        no: reversibility_check

      competitive_branch:
        question: "Do you need to act faster than the competition can react?"
        yes:
          recommend: ooda_loop
          confidence: high
          rationale: "Faster decision cycles outmaneuver slower opponents"
        no: competitive_resources_check

      competitive_resources_check:
        question: "Are your resources limited relative to competitors?"
        yes: concentration_branch
        no: competitive_phases_check

      concentration_branch:
        question: "Is there one decisive point where winning would change everything?"
        yes:
          recommend: schwerpunkt
          confidence: high
          rationale: "Concentrate overwhelming force at the decisive point"
        no:
          recommend: economy_of_force
          confidence: high
          rationale: "Minimum necessary on secondary fronts, concentrate on main effort"

      competitive_phases_check:
        question: "Does this campaign have distinct preparation, action, and sustain phases?"
        yes:
          recommend: phases_of_operations
          confidence: high
          rationale: "Structure work into shape, decisive, and sustain phases"
        no: reversibility_check

      reversibility_check:
        question: "Are there irreversible or high-cost-to-reverse actions?"
        yes:
          recommend: reversibility
          confidence: high
          rationale: "Delay irreversible actions until maximum certainty"
        no: use_scoring_system

      use_scoring_system:
        action: "Use scoring system below for nuanced multi-factor decision"
        confidence: medium
        rationale: "Multiple factors present; scoring provides weighted selection"

  # ==========================================
  # SCORING SYSTEM
  # ==========================================
  # Use when decision tree reaches 'use_scoring_system' or for nuanced decisions
  scoring_system:
    instructions: |
      Add points for each applicable context factor. The variation with the
      highest total score is recommended. If tied, prefer the one listed first.
      Minimum score of 5 points needed for confident recommendation.

    context_factors:
      # Constraint Factors
      - id: CF_HARD_DEADLINE
        description: "Hard external deadline exists"
        points:
          deadline_driven: 5
          critical_ratio_dynamic: 3
          parallel_maximizing: 2

      - id: CF_MULTIPLE_DEADLINES
        description: "Multiple competing deadlines"
        points:
          critical_ratio_dynamic: 5
          urgency_importance: 3
          deadline_driven: 2

      - id: CF_RESOURCE_CONSTRAINED
        description: "Severely limited resources (time, people, budget)"
        points:
          triage_severity: 4
          vital_few_first: 4
          throughput_optimized: 3
          greedy_local: 2

      - id: CF_STRICT_DEPENDENCIES
        description: "Technical dependencies force ordering"
        points:
          topological_sort: 10
          prerequisite_chain: 3

      # Uncertainty Factors
      - id: CF_HIGH_UNCERTAINTY
        description: "Feasibility is unknown or highly uncertain"
        points:
          fail_fast: 5
          build_measure_learn: 4
          learning_optimized: 3
          option_preserving: 2

      - id: CF_REQUIREMENTS_CHANGING
        description: "Requirements likely to change during execution"
        points:
          demand_driven: 4
          build_measure_learn: 4
          option_preserving: 3
          fail_fast: 2

      - id: CF_UNKNOWN_UNKNOWNS
        description: "Suspected unknown unknowns"
        points:
          learning_optimized: 4
          curiosity_driven: 4
          fail_fast: 3
          exploration: 2

      - id: CF_NEEDS_VALIDATION
        description: "Needs user/stakeholder validation"
        points:
          build_measure_learn: 5
          fail_fast: 3
          demand_driven: 3
          information_position: 2

      # Executor Factors
      - id: CF_HUMAN_SOLO
        description: "Single human executor"
        points:
          energy_aware: 3
          momentum: 3
          energy_envelope: 2

      - id: CF_TEAM_EXECUTION
        description: "Team with multiple people"
        points:
          parallel_maximizing: 4
          convergence_timing: 3
          weighted_fairness: 2

      - id: CF_LOW_MOTIVATION
        description: "Executor has low motivation or is overwhelmed"
        points:
          momentum: 5
          scaffolded_progression: 3
          energy_envelope: 2

      - id: CF_LONG_SESSION
        description: "Work session longer than 4 hours"
        points:
          energy_envelope: 4
          energy_aware: 3
          batch_vs_stream: 2

      - id: CF_AI_AGENT
        description: "AI agent executor"
        points:
          parallel_maximizing: 2
          throughput_optimized: 2
          depth_first: 1

      # Stakes Factors
      - id: CF_IRREVERSIBLE_ACTIONS
        description: "Contains irreversible or costly-to-reverse actions"
        points:
          reversibility: 5
          option_preserving: 4
          information_position: 3

      - id: CF_HIGH_COST_FAILURE
        description: "Failure would have high costs"
        points:
          fail_fast: 4
          defense_in_depth: 4
          reversibility: 3
          information_position: 2

      - id: CF_SAFETY_CRITICAL
        description: "Safety-critical requiring redundancy"
        points:
          defense_in_depth: 6
          reversibility: 3
          fail_fast: 2

      # Nature of Work Factors
      - id: CF_LEARNING_GOAL
        description: "Learning or skill-building is a primary goal"
        points:
          learning_optimized: 4
          scaffolded_progression: 4
          prerequisite_chain: 3
          curiosity_driven: 2

      - id: CF_CREATIVE_WORK
        description: "Primarily creative or generative work"
        points:
          novelty_search: 3
          quality_diversity: 3
          map_elites: 2
          energy_aware: 2

      - id: CF_OPTIMIZATION_WORK
        description: "Optimization or improvement of existing work"
        points:
          diminishing_returns: 5
          hill_climbing: 3
          simulated_annealing: 3
          greedy_local: 2

      - id: CF_DEBUGGING_WORK
        description: "Debugging or diagnostic work"
        points:
          bisection_debugging: 6
          depth_first: 2
          backtrack_prune: 2

      - id: CF_PRESENTATION
        description: "Output is for presentation to audience"
        points:
          tension_arc: 4
          inverted_pyramid: 4
          peak_targeting: 3

      - id: CF_NEGOTIATION
        description: "Negotiation or competitive context"
        points:
          commitment_first: 5
          concession_patterned: 4
          information_position: 3

      # Technical Factors
      - id: CF_MEMORY_CONSTRAINED
        description: "Memory or working memory is constrained"
        points:
          depth_first: 4
          iterative_deepening: 5
          beam_search: 3
          greedy_local: 2

      - id: CF_PARALLEL_POSSIBLE
        description: "Multiple steps can run in parallel"
        points:
          parallel_maximizing: 4
          dependency_fanout: 3
          divide_conquer: 2

      - id: CF_GOOD_HEURISTIC
        description: "Good heuristic available for progress estimation"
        points:
          heuristic_guided: 5
          branch_bound: 3
          greedy_local: 2

      - id: CF_EXPLORATION_NEEDED
        description: "Need to explore solution space"
        points:
          epsilon_greedy: 3
          thompson_sampling: 3
          ucb_exploration: 3
          monte_carlo_tree: 3
          curiosity_driven: 2

      - id: CF_LOCAL_OPTIMA_RISK
        description: "Risk of getting stuck in local optima"
        points:
          simulated_annealing: 5
          random_restart: 4
          tabu_search: 3
          levy_flight: 2

      - id: CF_MANY_SMALL_TASKS
        description: "Many small independent tasks"
        points:
          throughput_optimized: 5
          round_robin: 3
          batch_vs_stream: 2

      - id: CF_FAIRNESS_REQUIRED
        description: "Must balance priority with fairness"
        points:
          weighted_fairness: 5
          round_robin: 4
          priority_queue: 2

      # Music Composition and Performance Factors
      - id: CF_NARRATIVE_ARC_NEEDED
        description: "Content needs introduce-develop-resolve structure"
        points:
          sonata_form: 5
          tension_arc: 3
          crescendo_building: 2

      - id: CF_CORE_THEME_MULTIPLE_CONTEXTS
        description: "Same principle/theme explored in multiple contexts"
        points:
          theme_and_variations: 5
          rondo_form: 3

      - id: CF_MULTIPLE_VOICES_WEAVE
        description: "Multiple independent perspectives must combine harmoniously"
        points:
          fugue_construction: 5
          parallel_maximizing: 2

      - id: CF_RECURRING_KEY_MESSAGE
        description: "Key message must be reinforced through repetition"
        points:
          rondo_form: 5
          theme_and_variations: 2

      - id: CF_ITERATIVE_EXCHANGE
        description: "Work proceeds through call-and-response dialogue"
        points:
          call_and_response: 5
          build_measure_learn: 2

      - id: CF_BUILD_TO_REVEAL
        description: "Need to build gradually toward climactic reveal"
        points:
          crescendo_building: 5
          tension_arc: 3
          peak_targeting: 2

      - id: CF_EXTENDED_ENGAGEMENT
        description: "Extended experience needs energy variety and management"
        points:
          concert_setlist: 5
          energy_envelope: 4
          energy_aware: 2

      # Military Tactics and Strategy Factors
      - id: CF_COMPETITIVE_ADVERSARIAL
        description: "Competitive or adversarial situation with active opponent"
        points:
          ooda_loop: 5
          center_of_gravity: 4
          interior_lines: 3

      - id: CF_RAPID_RESPONSE_NEEDED
        description: "Must respond faster than environment/competitor changes"
        points:
          ooda_loop: 5
          fail_fast: 3

      - id: CF_DECISIVE_BREAKTHROUGH_NEEDED
        description: "Need breakthrough at one point rather than incremental progress"
        points:
          schwerpunkt: 5
          concentration_of_force: 4
          vital_few_first: 2

      - id: CF_DISTRIBUTED_AUTONOMOUS_EXECUTION
        description: "Execution is distributed and needs local autonomy"
        points:
          auftragstaktik: 5
          parallel_maximizing: 2

      - id: CF_INSUFFICIENT_RESOURCES_ALL_FRONTS
        description: "Cannot fully resource all objectives; must economize"
        points:
          economy_of_force: 5
          schwerpunkt: 4
          triage_severity: 3

      - id: CF_WINNER_TAKE_ALL_DYNAMICS
        description: "Competition follows square law/winner-take-all dynamics"
        points:
          concentration_of_force: 5
          schwerpunkt: 4

      - id: CF_MULTIPLE_SEPARATED_OPPONENTS
        description: "Multiple threats/competitors that are separated"
        points:
          interior_lines: 5
          concentration_of_force: 3

      - id: CF_RISK_OF_OVEREXTENSION
        description: "Success may lead to overextension or unsustainable position"
        points:
          culminating_point: 5
          diminishing_returns: 3

      - id: CF_LEVERAGE_POINT_ANALYSIS
        description: "Need to find where effort has maximum effect"
        points:
          center_of_gravity: 5
          vital_few_first: 3

      - id: CF_CAMPAIGN_WITH_PHASES
        description: "Long campaign with distinct preparation, execution, and sustain phases"
        points:
          phases_of_operations: 5
          build_measure_learn: 2

      # Project Management Factors
      - id: CF_FORMAL_PROJECT_MGMT
        description: "Formal project management context (construction, gov, enterprise)"
        points:
          pert: 4
          critical_path: 5
          critical_chain: 4
          earned_value: 3

      - id: CF_DURATION_UNCERTAINTY
        description: "Task durations are highly uncertain, need probabilistic estimates"
        points:
          pert: 5
          critical_chain: 3
          monte_carlo_tree: 2

      - id: CF_NETWORK_OF_DEPENDENCIES
        description: "Complex network of task dependencies with parallel paths"
        points:
          critical_path: 5
          topological_sort: 4
          pert: 3

      - id: CF_RESOURCE_CONTENTION
        description: "Multiple tasks competing for same limited resources"
        points:
          resource_leveling: 5
          critical_chain: 4
          round_robin: 2

      - id: CF_SCHEDULE_COMPRESSION_NEEDED
        description: "Need to complete faster than normal schedule allows"
        points:
          fast_tracking_crashing: 5
          parallel_maximizing: 3
          critical_path: 2

      - id: CF_COST_SCHEDULE_TRACKING
        description: "Must track cost and schedule performance against baseline"
        points:
          earned_value: 5
          critical_path: 2

      - id: CF_AGILE_CONTEXT
        description: "Iterative delivery with changing requirements"
        points:
          agile_sprint: 5
          build_measure_learn: 4
          demand_driven: 3

      - id: CF_FIXED_ITERATIONS
        description: "Work organized into fixed-length iterations/sprints"
        points:
          agile_sprint: 5
          timeboxed: 3

      - id: CF_BUFFER_MANAGEMENT
        description: "Need to protect against aggregate uncertainty"
        points:
          critical_chain: 5
          pert: 3

      - id: CF_MULTITASKING_PROBLEM
        description: "Team suffers from context switching and multitasking"
        points:
          critical_chain: 5
          focus: 3
          depth_first: 2

      - id: CF_GOVERNMENT_COMPLIANCE
        description: "Government or regulatory compliance requirements"
        points:
          earned_value: 5
          critical_path: 3
          pert: 3

      # Detection & Verification Factors
      - id: CF_FRAUD_INVESTIGATION
        description: "Investigating potential fraud, cheating, or deception"
        points:
          forensic_audit: 5
          benford_anomaly: 4
          layered_verification: 3
          baseline_deviation: 2

      - id: CF_FINANCIAL_AUDIT
        description: "Auditing financial records or transaction data"
        points:
          forensic_audit: 5
          benford_anomaly: 5
          layered_verification: 3

      - id: CF_INTERVIEW_DECEPTION_DETECTION
        description: "Conducting interviews where deception is possible"
        points:
          baseline_deviation: 5
          cognitive_load_interview: 5
          peace_model: 4
          behavioral_tells: 3

      - id: CF_ACADEMIC_INTEGRITY_CHECK
        description: "Verifying academic work authenticity"
        points:
          academic_integrity: 5
          layered_verification: 3

      - id: CF_INSIDER_THREAT_ASSESSMENT
        description: "Assessing risk from individuals with privileged access"
        points:
          mice_access: 5
          behavioral_tells: 4
          trust_but_verify: 3

      - id: CF_TRUST_CALIBRATION
        description: "Need to establish or adjust trust levels with verification"
        points:
          trust_but_verify: 5
          layered_verification: 4
          baseline_deviation: 2

      - id: CF_ANTI_CHEAT_GAMING
        description: "Detecting cheating in games or competitive systems"
        points:
          anti_cheat_behavioral: 5
          baseline_deviation: 3

      # Strategic Deception Factors (Legitimate Competitive Contexts)
      - id: CF_MAGIC_PERFORMANCE
        description: "Magic or illusion performance requiring attention management"
        points:
          misdirection_attention: 5
          forcing_choice: 4
          false_pattern: 3

      - id: CF_POKER_BLUFFING
        description: "Poker or game strategy with bluffing dynamics"
        points:
          false_pattern: 5
          leveling_metagame: 5
          tempo_disruption: 3
          behavioral_tells: 3

      - id: CF_RED_TEAM_SECURITY
        description: "Authorized red team or penetration testing"
        points:
          layered_deception: 5
          misdirection_attention: 4
          tempo_disruption: 3

      - id: CF_STRATEGIC_NEGOTIATION
        description: "Negotiation where information asymmetry is strategic"
        points:
          signal_manipulation: 5
          strategic_revelation: 4
          forcing_choice: 3
          information_position: 3

      - id: CF_SURPRISE_REVEAL
        description: "Presentation or announcement designed for surprise impact"
        points:
          strategic_revelation: 5
          crescendo_building: 4
          misdirection_attention: 3

      - id: CF_OPPONENT_ANALYZING_PATTERNS
        description: "Opponent is analyzing and predicting your moves"
        points:
          leveling_metagame: 5
          false_pattern: 4
          tempo_disruption: 3

    score_thresholds:
      high_confidence: 8
      medium_confidence: 5
      low_confidence: 3
      insufficient: 0

    scoring_procedure:
      - step: 1
        action: "Identify all applicable context factors from questionnaire"
      - step: 2
        action: "For each factor, add points to applicable variations"
      - step: 3
        action: "Sum total points for each variation"
      - step: 4
        action: "Rank variations by total score"
      - step: 5
        action: "If top score >= 8, recommend with high confidence"
      - step: 6
        action: "If top score 5-7, recommend with medium confidence"
      - step: 7
        action: "If top score 3-4, recommend with low confidence, suggest hybrid"
      - step: 8
        action: "If top score < 3, use default ordering or ask more questions"

  # ==========================================
  # CONFLICT RESOLUTION
  # ==========================================
  conflict_resolution:
    instructions: |
      Some variations fundamentally conflict. Use these rules to resolve.

    conflict_pairs:
      - pair: [fail_fast, momentum]
        nature: "Opposite priorities (uncertainty vs. energy)"
        resolution: "If uncertainty threatens project viability, fail_fast wins"
        tiebreaker: fail_fast

      - pair: [reversibility, commitment_first]
        nature: "Opposite philosophies (preserve options vs. commit early)"
        resolution: "If irreversible action affects third parties, reversibility wins"
        tiebreaker: reversibility

      - pair: [demand_driven, deadline_driven]
        nature: "Pull vs. push conflict"
        resolution: "External deadline always wins over internal pull system"
        tiebreaker: deadline_driven

      - pair: [throughput_optimized, learning_optimized]
        nature: "Speed vs. depth conflict"
        resolution: "If primary goal is learning, accept slower throughput"
        tiebreaker: learning_optimized

      - pair: [energy_aware, parallel_maximizing]
        nature: "Individual pacing vs. team speed"
        resolution: "Team context makes parallel_maximizing win"
        tiebreaker: parallel_maximizing

      - pair: [depth_first, breadth_first]
        nature: "Memory vs. optimality trade-off"
        resolution: "If memory constrained, depth_first; if need shortest path, breadth_first"
        tiebreaker: breadth_first

      # Project Management Conflicts
      - pair: [critical_path, critical_chain]
        nature: "Traditional vs. buffer-based scheduling"
        resolution: "If multitasking is a problem, critical_chain; if need clear accountability, critical_path"
        tiebreaker: critical_chain

      - pair: [agile_sprint, critical_path]
        nature: "Iterative vs. predictive planning"
        resolution: "If requirements are stable and deadlines firm, critical_path; if change expected, agile_sprint"
        tiebreaker: agile_sprint

      - pair: [pert, agile_sprint]
        nature: "Upfront estimation vs. emergent understanding"
        resolution: "If need probabilistic schedule for stakeholders, pert; if learning through doing, agile_sprint"
        tiebreaker: agile_sprint

      - pair: [fast_tracking_crashing, resource_leveling]
        nature: "Schedule compression vs. resource smoothing"
        resolution: "If deadline is hard constraint, fast_tracking_crashing; if resources are hard constraint, resource_leveling"
        tiebreaker: fast_tracking_crashing

    dominance_rules:
      - rule: "Hard external deadline dominates all non-safety concerns"
        applies_when: CF_HARD_DEADLINE is true
        dominant: deadline_driven

      - rule: "Safety-critical dominates all non-safety concerns"
        applies_when: CF_SAFETY_CRITICAL is true
        dominant: defense_in_depth

      - rule: "Strict dependencies must be respected regardless of other factors"
        applies_when: CF_STRICT_DEPENDENCIES is true
        dominant: topological_sort

      - rule: "Active crisis dominates normal prioritization"
        applies_when: "Crisis or emergency situation"
        dominant: triage_severity

  # ==========================================
  # HYBRID COMBINATIONS
  # ==========================================
  hybrid_strategies:
    instructions: |
      When multiple concerns are important, consider hybrid approaches.

    common_hybrids:
      - name: "Deadline + Fail-Fast"
        combination: [deadline_driven, fail_fast]
        when: "Hard deadline but significant uncertainty"
        how: "Work backward from deadline; within that, prioritize uncertainty resolution"

      - name: "Learning + Momentum"
        combination: [learning_optimized, momentum]
        when: "Learning goal but motivation is low"
        how: "Choose learnings that also provide quick wins"

      - name: "Parallel + Energy-Aware"
        combination: [parallel_maximizing, energy_aware]
        when: "Team execution with human members"
        how: "Enable parallel work but respect individual energy cycles"

      - name: "Fail-Fast + Reversibility"
        combination: [fail_fast, reversibility]
        when: "High uncertainty AND irreversible actions"
        how: "Test uncertainty first; sequence reversible before irreversible"

      - name: "Throughput + Fairness"
        combination: [throughput_optimized, weighted_fairness]
        when: "Many tasks with different priority classes"
        how: "SPT within priority tiers; allocation across tiers by weight"

      - name: "Exploration + Exploitation"
        combination: [epsilon_greedy, greedy_local]
        when: "Need to balance discovery with progress"
        how: "Mostly exploit best known; occasionally explore randomly"

      # Project Management Hybrids
      - name: "PERT + Critical Path"
        combination: [pert, critical_path]
        when: "Formal project with significant duration uncertainty"
        how: "Use PERT three-point estimates to identify critical path with probability; focus on high-variance critical activities"

      - name: "Critical Chain + Agile"
        combination: [critical_chain, agile_sprint]
        when: "Need buffer protection but also iterative delivery"
        how: "Plan in sprints but include project buffer; track buffer consumption across sprints"

      - name: "Earned Value + Agile"
        combination: [earned_value, agile_sprint]
        when: "Government/compliance context with agile delivery"
        how: "Use story points as earned value; calculate SPI/CPI at sprint boundaries"

      - name: "Resource Leveling + Critical Path"
        combination: [resource_leveling, critical_path]
        when: "Resource constraints affect critical path"
        how: "Identify critical path first; level resources consuming only available slack; recalculate if critical path changes"

      - name: "Fast-Tracking + PERT"
        combination: [fast_tracking_crashing, pert]
        when: "Must compress schedule with uncertain durations"
        how: "Use PERT analysis to identify which parallel paths have highest schedule risk; crash high-variance critical activities first"

  # ==========================================
  # EXECUTION STEPS
  # ==========================================
  steps:
    - id: 1
      name: "Complete context questionnaire"
      action: |
        Answer questions from context_questionnaire above.
        Focus on the categories most relevant to your situation.
        Note which context factors (CF_*) apply.

    - id: 2
      name: "Traverse decision tree"
      action: |
        Start at decision_tree.nodes.root.
        Follow yes/no branches based on questionnaire answers.
        If you reach 'use_scoring_system', proceed to step 3.
        Otherwise, note the recommendation and confidence level.

    - id: 3
      name: "Apply scoring system (if needed)"
      action: |
        If decision tree led to scoring, or if confidence is low:
        - Add points for each applicable context factor
        - Sum totals for each variation
        - Select highest scoring variation
        - Check confidence threshold

    - id: 4
      name: "Check for conflicts"
      action: |
        If top two variations conflict (see conflict_pairs):
        - Apply resolution rule
        - Consider hybrid approach if both concerns are critical

    - id: 5
      name: "Consider hybrid approach"
      action: |
        If multiple factors scored highly (difference < 2 points):
        - Check hybrid_strategies for common combinations
        - Design custom hybrid if needed

    - id: 6
      name: "Apply selected variation"
      action: |
        Use the prioritization rules from selected variation
        to order the steps within dependency constraints.

    - id: 7
      name: "Document rationale"
      action: |
        In STEPS.md, note:
        - Which ordering variation was used (or hybrid)
        - Key context factors that drove the decision
        - Decision tree path or scoring breakdown
        - What trade-offs were accepted
        - Confidence level of the selection

# ============================================
# EXAMPLES
# ============================================
examples:
  - name: "Ordering for a risky new initiative"
    context: "Team considering new market, high uncertainty"
    selected_variation: fail_fast
    rationale: "Unknown if market exists; find out before investing"

  - name: "Ordering for a demoralized team"
    context: "Long project, team burnt out, need morale boost"
    selected_variation: momentum
    rationale: "Quick wins restore energy and confidence"

  - name: "Ordering for a tight deadline"
    context: "Must ship by conference date, no flexibility"
    selected_variation: deadline_driven
    rationale: "External constraint dominates all other concerns"

  - name: "Ordering for a support queue"
    context: "100 tickets of varying complexity"
    selected_variation: throughput_optimized
    rationale: "SPT minimizes average wait time, serves most people fastest"

  - name: "Ordering for uncertain product requirements"
    context: "Building features, don't know what users want"
    selected_variation: demand_driven
    rationale: "Pull system avoids building features nobody uses"

  - name: "Ordering for a contract negotiation"
    context: "Negotiating deal, need leverage"
    selected_variation: commitment_first
    rationale: "Strategic commitments shape counterparty behavior"

  - name: "Ordering for optimization work"
    context: "Performance tuning, risk of over-engineering"
    selected_variation: diminishing_returns
    rationale: "Know when to stop before returns drop below cost"

  - name: "Ordering for learning a new technology"
    context: "Team learning Kubernetes"
    selected_variation: scaffolded_progression
    rationale: "Build from simple to complex, each step works"

  - name: "Ordering for project with shifting deadlines"
    context: "Multiple deliverables, priorities change weekly"
    selected_variation: critical_ratio_dynamic
    rationale: "Dynamic rebalancing as time and work change"

  - name: "Ordering during production incident"
    context: "Multiple systems down, limited engineers"
    selected_variation: triage_severity
    rationale: "Greatest good for greatest number - some systems may not be saveable"

  - name: "Ordering for conference demo"
    context: "Must peak on demo day, not before or after"
    selected_variation: peak_targeting
    rationale: "Periodize work to hit maximum performance at specific time"

  - name: "Ordering a sales pitch"
    context: "Need to engage audience and close deal"
    selected_variation: tension_arc
    rationale: "Build stakes to climax, then resolve with call to action"

  - name: "Ordering work after vacation"
    context: "Returning to many projects, need to re-orient"
    selected_variation: recency_weighted
    rationale: "Start with most recent context, let old items resurface if needed"

  - name: "Ordering daily standup routine"
    context: "Want to build consistent morning habit"
    selected_variation: anchor_based
    rationale: "Attach to existing behavior (coffee), chain subsequent steps"

  - name: "Ordering interview schedule"
    context: "Must schedule 10 candidates, various constraints"
    selected_variation: most_constrained_first
    rationale: "Schedule candidates with fewest available slots first"

  - name: "Ordering multi-track project delivery"
    context: "Frontend, backend, and docs must ship together"
    selected_variation: convergence_timing
    rationale: "Plan start times so all tracks converge at launch"

  - name: "Ordering support queue with multiple tiers"
    context: "Enterprise, pro, and free customers waiting"
    selected_variation: weighted_fairness
    rationale: "Give each tier its fair share; don't starve free users"

  - name: "Ordering architecture decisions"
    context: "Must choose database, but requirements still evolving"
    selected_variation: option_preserving
    rationale: "Delay binding decisions; preserve flexibility"

  - name: "Ordering all-day training session"
    context: "8-hour workshop, need to maintain engagement"
    selected_variation: energy_envelope
    rationale: "Plan peaks and valleys; don't exhaust learners"

  - name: "Ordering contract negotiation steps"
    context: "Multiple issues to negotiate with vendor"
    selected_variation: concession_patterned
    rationale: "Small concessions early, bigger ones reserved for close"

  - name: "Ordering ML curriculum"
    context: "Teaching machine learning from scratch"
    selected_variation: prerequisite_chain
    rationale: "Linear algebra before calculus before optimization before ML"

  - name: "Ordering security implementation"
    context: "Protecting production system from attacks"
    selected_variation: defense_in_depth
    rationale: "Layer independent defenses; no single point of failure"

  - name: "Finding which commit broke the build"
    context: "Build worked yesterday, broken today, 100 commits between"
    selected_variation: bisection_debugging
    rationale: "Binary search finds culprit in 7 tests instead of 100"

  - name: "Writing executive summary email"
    context: "CEO needs quick update, may not read entire email"
    selected_variation: inverted_pyramid
    rationale: "Key takeaway first; details in descending importance"

  - name: "Weekly task planning"
    context: "Mix of urgent requests and important projects"
    selected_variation: urgency_importance
    rationale: "Protect Q2 time for important-not-urgent work"

  - name: "Building microservice for partner integration"
    context: "Partner team needs stable API to integrate against"
    selected_variation: outside_in
    rationale: "API contract first; implementation follows"

  - name: "Building financial calculation engine"
    context: "Complex tax rules, correctness is critical"
    selected_variation: inside_out
    rationale: "Get domain logic correct first; interface can vary"

  - name: "Processing email inbox"
    context: "200 emails, mix of quick replies and deep reads"
    selected_variation: batch_vs_stream
    rationale: "Batch similar types; don't context-switch per email"

  - name: "Launching new product feature"
    context: "Uncertain if users will want this"
    selected_variation: build_measure_learn
    rationale: "MVP first, measure adoption, then iterate or pivot"

  - name: "Allocating team across initiatives"
    context: "4 projects with different risk/reward profiles"
    selected_variation: proportional_confidence
    rationale: "Size investment proportional to expected value"

  - name: "Making hiring decision"
    context: "Can observe candidate in trial project first"
    selected_variation: information_position
    rationale: "Gather information before committing"

  - name: "Prioritizing bug fixes"
    context: "100 bugs reported, limited engineering time"
    selected_variation: vital_few_first
    rationale: "Top 10 bugs cause 85% of user complaints"

  # Computer Science Algorithm Examples:
  - name: "Building software with dependencies"
    context: "Modules depend on other modules"
    selected_variation: topological_sort
    rationale: "Can't build D until A, B, C are built"

  - name: "Finding minimum steps to solve puzzle"
    context: "Word ladder, minimum edits between words"
    selected_variation: breadth_first
    rationale: "BFS finds shortest path (fewest steps)"

  - name: "Generating all combinations"
    context: "Need every possible subset or permutation"
    selected_variation: depth_first
    rationale: "DFS naturally explores all paths"

  - name: "Scheduling non-overlapping meetings"
    context: "Maximize meetings that fit in day"
    selected_variation: greedy_local
    rationale: "Earliest finish time first is optimal for activity selection"

  - name: "Computing edit distance between strings"
    context: "Minimum insertions/deletions to transform"
    selected_variation: dynamic_subproblem
    rationale: "Overlapping subproblems - cache partial results"

  - name: "Solving Sudoku puzzle"
    context: "Constraint satisfaction with 81 cells"
    selected_variation: backtrack_prune
    rationale: "Try digit, check constraints, backtrack if stuck"

  - name: "Route planning on map"
    context: "Find shortest driving path between cities"
    selected_variation: heuristic_guided
    rationale: "A* with straight-line heuristic guides search"

  - name: "Sorting large dataset"
    context: "1 million records to sort"
    selected_variation: divide_conquer
    rationale: "Merge sort: split, sort halves, merge"

  - name: "Event-driven simulation"
    context: "Events arrive at different times with different priorities"
    selected_variation: priority_queue
    rationale: "Always process next most important event"

  - name: "Time-sharing CPU among processes"
    context: "Multiple processes need CPU, must be fair"
    selected_variation: round_robin
    rationale: "Each process gets equal time slices"

  - name: "Solving traveling salesman optimally"
    context: "Must visit all cities with minimum distance"
    selected_variation: branch_bound
    rationale: "Prune branches that can't beat best known tour"

  # Search Procedure Examples:
  - name: "Searching game tree with limited memory"
    context: "Chess position analysis, need optimal but low memory"
    selected_variation: iterative_deepening
    rationale: "IDDFS combines BFS optimality with DFS memory efficiency"

  - name: "Optimizing hyperparameters locally"
    context: "ML model tuning, in good region already"
    selected_variation: hill_climbing
    rationale: "Local improvement when near optimum is efficient"

  - name: "Escaping local optimum in ML training"
    context: "Neural network stuck, need to escape local minimum"
    selected_variation: simulated_annealing
    rationale: "Accept worse moves early to find global optimum"

  - name: "Parsing with memory constraints"
    context: "Natural language processing with limited compute"
    selected_variation: beam_search
    rationale: "Keep top-k candidates instead of full tree"

  - name: "Evolving neural network architecture"
    context: "AutoML - need to find good model structure"
    selected_variation: genetic_evolutionary
    rationale: "Population-based search with crossover and mutation"

  - name: "Game playing without good heuristic"
    context: "Go position evaluation, no reliable heuristic"
    selected_variation: monte_carlo_tree
    rationale: "MCTS with UCB balances exploration and exploitation"

  - name: "Optimizing highly multimodal landscape"
    context: "Many local optima, need global exploration"
    selected_variation: random_restart
    rationale: "Multiple random starts find different local optima"

  - name: "Avoiding repeated states in search"
    context: "Optimization cycling between similar solutions"
    selected_variation: tabu_search
    rationale: "Memory of recent moves prevents cycling"

  - name: "Finding path in known environment"
    context: "Robot navigation, know both start and goal"
    selected_variation: bidirectional_search
    rationale: "Meet in middle, exponentially fewer states"

  - name: "Finding cheapest path in weighted graph"
    context: "Route planning with varying edge costs"
    selected_variation: uniform_cost
    rationale: "Dijkstra's explores by cumulative cost, not hops"

  # Exploration Procedure Examples:
  - name: "A/B testing website buttons"
    context: "Testing 4 button colors, want mostly best + some exploration"
    selected_variation: epsilon_greedy
    rationale: "80% best performer, 20% random discovery"

  - name: "Clinical trial adaptive allocation"
    context: "Assigning patients to treatments, learn as we go"
    selected_variation: thompson_sampling
    rationale: "Bayesian allocation explores uncertain treatments proportionally"

  - name: "Restaurant recommendation"
    context: "Suggesting restaurants with quality estimates"
    selected_variation: softmax_boltzmann
    rationale: "Graded probability by rating, temperature controls exploration"

  - name: "Autonomous robot skill learning"
    context: "Robot learning without explicit reward function"
    selected_variation: curiosity_driven
    rationale: "Explore where predictions are wrong, learn from surprise"

  - name: "Generating diverse creative options"
    context: "Brainstorming, need radically different ideas"
    selected_variation: novelty_search
    rationale: "Ignore quality, maximize behavioral difference"

  - name: "Exploring hard Atari game states"
    context: "Sparse reward, easy to forget promising areas"
    selected_variation: go_explore
    rationale: "Archive states, return to frontiers, explore systematically"

  - name: "Building robot locomotion repertoire"
    context: "Need diverse gaits for different terrains"
    selected_variation: map_elites
    rationale: "Fill behavior space with best gait per terrain type"

  - name: "Searching for sparse mineral deposits"
    context: "Targets randomly distributed, unknown locations"
    selected_variation: levy_flight
    rationale: "Local search + occasional big jumps is optimal for sparse targets"

  - name: "Ad selection for new users"
    context: "Limited data, need to explore while earning"
    selected_variation: ucb_exploration
    rationale: "Optimistic about rarely-shown ads until proven otherwise"

  - name: "Building investment portfolio"
    context: "Need diverse strategies, each good in its niche"
    selected_variation: quality_diversity
    rationale: "Best strategy per market condition, not just one global best"

  # Music Composition and Performance Examples:
  - name: "Structuring a keynote presentation"
    context: "Major conference talk needs narrative arc with resolution"
    selected_variation: sonata_form
    rationale: "Introduce thesis, develop through challenges, return to thesis transformed"

  - name: "Teaching design patterns"
    context: "Same core principle applied across multiple scenarios"
    selected_variation: theme_and_variations
    rationale: "Core pattern stated, then shown in different contexts"

  - name: "Cross-functional product planning"
    context: "Engineering, design, and product voices must combine"
    selected_variation: fugue_construction
    rationale: "Each team introduces perspective, then weave together"

  - name: "Marketing campaign with key message"
    context: "Need to reinforce brand message across content pieces"
    selected_variation: rondo_form
    rationale: "Return to key message between different topics (ABACA)"

  - name: "Pair programming session"
    context: "Driver-navigator pattern with regular switching"
    selected_variation: call_and_response
    rationale: "One codes, one reviews, then switch - rhythm of exchange"

  - name: "Investor pitch building to ask"
    context: "Need to build conviction before revealing funding request"
    selected_variation: crescendo_building
    rationale: "Start soft, build evidence gradually, peak at the ask"

  - name: "Multi-day offsite agenda"
    context: "48-hour intensive needs energy management"
    selected_variation: concert_setlist
    rationale: "Open strong, vary intensity, close memorably, plan rest periods"

  # Military Tactics Examples:
  - name: "Responding to fast-moving competitor"
    context: "Competitor shipping features weekly, need to keep pace"
    selected_variation: ooda_loop
    rationale: "Faster decision cycles let us outmaneuver; observe market, orient on gaps, decide quickly, ship fast"

  - name: "Startup with limited resources against large incumbent"
    context: "10-person team vs 1000-person competitor"
    selected_variation: schwerpunkt
    rationale: "Cannot compete everywhere; concentrate 80% on one niche where we can win decisively"

  - name: "Distributed product teams building features"
    context: "Multiple teams, central planning bottlenecked"
    selected_variation: auftragstaktik
    rationale: "Define intent and success criteria; let teams decide how to achieve it locally"

  - name: "Allocating engineering across products"
    context: "5 products, 10 engineers, can't fully staff all"
    selected_variation: economy_of_force
    rationale: "Main effort on flagship, minimum viable on others, accept calculated risk"

  - name: "Enterprise sales with limited team"
    context: "100 prospects, 10 reps vs competitor's 30"
    selected_variation: concentration_of_force
    rationale: "Concentrate all reps on top 20 accounts; local superiority beats thin coverage"

  - name: "Competing against two market leaders"
    context: "Startup positioned between enterprise and consumer players"
    selected_variation: interior_lines
    rationale: "Use mid-market position to engage each competitor separately before they react"

  - name: "Post-hypergrowth consolidation"
    context: "3x'd team in 18 months, now quality and morale declining"
    selected_variation: culminating_point
    rationale: "Recognize overextension symptoms; pause growth, consolidate, rebuild before next push"

  - name: "Analyzing competitor for market entry"
    context: "Need to identify where to attack established player"
    selected_variation: center_of_gravity
    rationale: "Find their source of power (key partnerships); attack that, not surface features"

  - name: "Product launch campaign"
    context: "Major new product, 9-month timeline"
    selected_variation: phases_of_operations
    rationale: "Shape (build, hire, partner), Decisive (launch, acquire users), Sustain (maintain, optimize)"

  # Project Management Examples:
  - name: "R&D project with high uncertainty"
    context: "Building novel technology, estimates are guesses"
    selected_variation: pert
    rationale: "Three-point estimates with probability analysis reveal true schedule risk"

  - name: "Construction project planning"
    context: "Office buildout with multiple trades"
    selected_variation: critical_path
    rationale: "Clear dependencies, need to know which tasks have slack and which are critical"

  - name: "Multi-project engineering portfolio"
    context: "Same engineers shared across 4 projects, all late"
    selected_variation: critical_chain
    rationale: "Resource contention causing delays; pool buffers, eliminate multitasking"

  - name: "Startup MVP development"
    context: "Uncertain requirements, need fast feedback"
    selected_variation: agile_sprint
    rationale: "Deliver incrementally, reorder backlog as we learn what users want"

  - name: "Government contract tracking"
    context: "DoD project with cost-plus contract, EVM required"
    selected_variation: earned_value
    rationale: "Integrated cost/schedule tracking to detect and report variances early"

  - name: "Event planning with contractor constraints"
    context: "Conference setup with limited venue crews"
    selected_variation: resource_leveling
    rationale: "Cannot exceed crew capacity; smooth demand by shifting flexible tasks"

  - name: "Behind schedule for critical launch"
    context: "Must hit conference demo date, currently 3 weeks behind"
    selected_variation: fast_tracking_crashing
    rationale: "Overlap where risk is low, add resources where cheap; compress critical path"

  # Strategic Deception Examples:
  - name: "Magic stage performance sequence"
    context: "Close-up card magic routine for sophisticated audience"
    selected_variation: misdirection_attention
    rationale: "Control where audience looks; secret move during attention relaxation after reveal"

  - name: "Vendor negotiation with multiple options"
    context: "Need 3-year contract but want vendor to feel they chose terms"
    selected_variation: forcing_choice
    rationale: "Present 1/3/5 year options making 3-year most psychologically attractive"

  - name: "Startup fundraising credibility building"
    context: "Unknown startup needs to signal quality to investors"
    selected_variation: signal_manipulation
    rationale: "Lead with costly signals (top advisors, audited metrics) before pitch"

  - name: "Red team penetration test"
    context: "Authorized security test against corporate SOC"
    selected_variation: layered_deception
    rationale: "Surface attacks distract while true vector exploits orthogonal vulnerability"

  - name: "Poker tournament against aggressive player"
    context: "Heads-up against opponent who sets fast pace"
    selected_variation: tempo_disruption
    rationale: "Slow play to establish rhythm, then sudden aggression exploits their adjustment"

  - name: "Product launch timing vs competitor"
    context: "Competitor has announced launch date; we're ready earlier"
    selected_variation: strategic_revelation
    rationale: "Announce day before their event; force them to react to our frame"

  - name: "Tournament poker pattern exploitation"
    context: "Deep in tournament against opponent who tracks betting patterns"
    selected_variation: false_pattern
    rationale: "Establish predictable betting pattern, then exploit their learned expectation"

  - name: "Negotiation against sophisticated counterparty"
    context: "Both sides know the other is strategizing"
    selected_variation: leveling_metagame
    rationale: "Assess their thinking level; operate one level above, not more"

  # Detection & Verification Examples:
  - name: "Investigating accounts payable fraud"
    context: "Anonymous tip about fake vendor scheme"
    selected_variation: forensic_audit
    rationale: "Automated red flags first (duplicate payments, round numbers), relationship mapping before confrontation"

  - name: "Auditing tax returns for fabrication"
    context: "IRS examining Schedule C expenses for patterns"
    selected_variation: benford_anomaly
    rationale: "Statistical digit distribution analysis flags fabricated amounts before manual review"

  - name: "Grading student thesis with plagiarism suspicion"
    context: "Writing style suddenly changed, very sophisticated"
    selected_variation: academic_integrity
    rationale: "Automated screening plus competency verification - can they explain their own work?"

  - name: "Detecting cheaters in online competitive game"
    context: "Player with suspicious accuracy in FPS"
    selected_variation: anti_cheat_behavioral
    rationale: "Statistical impossibility check, behavioral fingerprint, delayed ban wave to obscure detection"

  - name: "Interviewing witness in investigation"
    context: "Need to assess truthfulness of account"
    selected_variation: baseline_deviation
    rationale: "Establish baseline with neutral questions before probing suspicious topics"

  - name: "Insurance claim interview with suspected fraud"
    context: "Claimant story has inconsistencies"
    selected_variation: cognitive_load_interview
    rationale: "Increase cognitive load progressively - reverse order telling, unexpected questions reveal fabrication"

  - name: "HR investigation of employee misconduct"
    context: "Allegation of policy violation, need full account"
    selected_variation: peace_model
    rationale: "Ethical interviewing - get complete account before challenging, information quality over confession"

  - name: "Assessing insider threat risk"
    context: "System administrator with broad access"
    selected_variation: mice_access
    rationale: "Map access first, then motivation screening (MICE), continuous evaluation over point-in-time"

  - name: "Reading vendor in contract negotiation"
    context: "Trying to understand their true price flexibility"
    selected_variation: behavioral_tells
    rationale: "Establish baseline behavior before high-stakes offer, observe involuntary reactions"

  - name: "Onboarding new outsourced development team"
    context: "Critical project, first time working with vendor"
    selected_variation: trust_but_verify
    rationale: "Small initial scope, progressive verification, expand trust as earned"

  - name: "Due diligence on acquisition target"
    context: "Verifying claimed customer base and revenue"
    selected_variation: layered_verification
    rationale: "Multiple independent verification methods - automated, documentary, testimonial, physical"

# ============================================
# GOSM INTEGRATION
# ============================================
gosm_integration:
  use_cases:
    - During STEPS generation to justify sequence
    - When default ordering feels wrong for context
    - When comparing alternative execution plans
    - When explaining to stakeholders why this order

  gates:
    - gate: ordering_appropriate
      question: "Is the selected ordering variation appropriate for context?"

    - gate: dependencies_respected
      question: "Does the order satisfy all hard dependencies?"

  related_procedures:
    - order_procedure: Base ordering algorithm
    - steps_generation: Consumer of ordering output
    - decomposition: Creates steps to be ordered
    - parallel_identification: Related to parallel_maximizing variation
