# Decision Procedure — Achieving Superintelligence Through This Project

**Date**: 2026-01-31
**Skill**: /dcp (Decision Procedure)
**Input**: achieving superintelligence through this project

---

# ACHIEVING SUPERINTELLIGENCE THROUGH A REASONING TOOLKIT — DECISION PROCEDURE

---

## STEP 1: DIMENSION DISCOVERY (`/dd`)

### Seed Examples

Concrete approaches people might take toward "achieving superintelligence through a reasoning toolkit project":

1. Building a comprehensive skill library that covers all human reasoning patterns
2. Creating meta-skills that compose and chain other skills automatically
3. Training AI on the structured procedures to internalize better reasoning
4. Using the toolkit as scaffolding that makes any LLM reason beyond its baseline
5. Developing self-improving loops where the toolkit improves its own procedures
6. Building a community of contributors who expand and refine the skill set
7. Integrating the toolkit with autonomous agents that can execute multi-step plans
8. Using the toolkit to identify and fill gaps in current AI reasoning capabilities
9. Creating formal verification layers that catch reasoning errors
10. Developing domain-complete coverage so no problem type is unaddressed

### Comparison for Differences

- Example 1 vs 5: **Improvement mechanism** (static library vs self-modifying)
- Example 2 vs 7: **Execution agent** (human-directed vs autonomous)
- Example 3 vs 4: **Where intelligence lives** (internalized in model vs external scaffolding)
- Example 6 vs 9: **Quality assurance** (social/crowd vs formal/mathematical)
- Example 8 vs 10: **Completeness target** (gap-filling vs total coverage)

### Dimensions Discovered

| # | Dimension | Values | Why It Matters |
|---|-----------|--------|----------------|
| 1 | **Definition of superintelligence** | Speed SI, Quality SI, Collective SI, Domain SI, General SI | You can't achieve what you haven't defined |
| 2 | **Where reasoning enhancement lives** | In-model (training), External scaffolding (prompting), Hybrid | Determines architecture and feasibility |
| 3 | **Improvement mechanism** | Static (manual curation), Evolutionary (community), Self-modifying (recursive), ML-trained | Determines ceiling and trajectory |
| 4 | **Completeness of skill coverage** | Domain-specific, Multi-domain, Universal coverage | How much of reasoning space is addressed |
| 5 | **Composability** | Flat (independent skills), Chainable (sequential), Recursive (self-referencing), Emergent (novel combinations) | Whether the whole exceeds parts |
| 6 | **Verification rigor** | Informal, Peer-reviewed, Empirically tested, Formally verified | How you know it works |
| 7 | **Agent autonomy** | Human-directed, Semi-autonomous, Fully autonomous | Who decides what to apply and when |
| 8 | **Bottleneck addressed** | Knowledge, Reasoning quality, Speed, Consistency, Scope, Creativity | What capability gap you're targeting |
| 9 | **Scaling mechanism** | Linear (more skills), Combinatorial (skill composition), Exponential (self-improvement) | Growth trajectory toward SI |
| 10 | **Risk posture** | Cautious/aligned, Neutral/pragmatic, Aggressive/capability-first | Safety-capability tradeoff |
| 11 | **Success metric** | Benchmark performance, Novel problem solving, Self-improvement rate, Human-surpassing reasoning | How you measure progress |
| 12 | **Time horizon** | Months, Years, Decades, Indefinite/asymptotic | When you expect results |

**TOTAL SPACE**: 5 x 3 x 4 x 3 x 4 x 4 x 3 x 6 x 3 x 3 x 4 x 4 = **37,324,800 combinations**

**Independence check**: All dimensions can vary independently. "Definition" constrains "Success metric" somewhat (they interact), but each can still vary given the other.

---

## STEP 2: SPACE ENUMERATION (`/se`)

**Granularity**: HIERARCHICAL (space > 5000)

### By Primary Dimension: Definition of Superintelligence

#### Speed SI ("Faster than human reasoning")
- Relevant skills: Parallelizable procedures, automated chaining
- Toolkit role: Reduce reasoning latency via pre-structured paths
- Bottleneck: Execution speed of the underlying model, not the toolkit
- Verdict: Toolkit adds marginal value; speed is a hardware/model problem

#### Quality SI ("Better reasoning than any human expert")
- Relevant skills: Deep analytical chains (/certainty, /araw, /pce)
- Toolkit role: Codify expert-level reasoning as followable procedures
- Bottleneck: Quality of the procedures themselves
- Verdict: **Strongest fit** — this is what structured procedures directly improve

#### Collective SI ("Better than any group of humans")
- Relevant skills: Multi-perspective skills (/cda, /tp, /sya)
- Toolkit role: Systematically adopt multiple viewpoints a single agent can't
- Bottleneck: Genuine novelty vs. simulated perspectives
- Verdict: Moderate fit — procedures can simulate breadth but not true independence

#### Domain SI ("Superhuman in specific domains")
- Relevant skills: Domain templates (/dmt, /tr), technical skills
- Toolkit role: Codify domain expertise into executable procedures
- Bottleneck: Quality of domain knowledge encoded
- Verdict: Good fit — already happening in narrow domains

#### General SI ("Superhuman across all domains")
- Relevant skills: Meta-skills (/meta, /gosm), universal procedures
- Toolkit role: Provide a universal reasoning OS
- Bottleneck: Completeness + composability + self-improvement
- Verdict: Aspirational — requires all dimensions maximized simultaneously

### Key Interactions Between Dimensions

| If Definition = | Then Improvement Mechanism must be | And Verification must be |
|---|---|---|
| Speed SI | Automated | Benchmarked |
| Quality SI | Evolutionary or Self-modifying | Empirically tested |
| Collective SI | Community-driven | Peer-reviewed |
| Domain SI | Manual curation by experts | Domain-validated |
| General SI | Self-modifying + Emergent composition | Formally verified |

---

## STEP 3: ASSUMPTION EXTRACTION (`/aex`)

### Core Claims in "Achieving Superintelligence Through This Project"

**Claim 1**: Structured reasoning procedures can make an AI system superintelligent.
**Claim 2**: 355 skills (expandable) can cover enough of the reasoning space.
**Claim 3**: Skill chaining produces emergent capabilities beyond individual skills.
**Claim 4**: This approach is viable compared to alternatives (scaling, RLHF, architecture search).

### Assumption Map

**Claim 1: "Procedures can produce superintelligence"**

| Assumption | Type | Hiddenness | Risk if Wrong |
|------------|------|------------|---------------|
| Intelligence is largely procedural (not intuitive/embodied) | Causal | **Buried** | **Critical** |
| Explicit procedures can capture what experts do implicitly | Knowledge | Deep | High |
| Following correct procedures guarantees correct conclusions | Causal | Deep | High |
| The underlying model can faithfully execute complex procedures | Capability | Shallow | High |
| Procedure quality has no ceiling | Stability | **Buried** | **Critical** |
| Superintelligence is achievable through software alone | Existence | Deep | High |

**Claim 2: "355+ skills cover enough space"**

| Assumption | Type | Hiddenness | Risk if Wrong |
|------------|------|------------|---------------|
| Reasoning is decomposable into discrete skills | Existence | Deep | **Critical** |
| The skill taxonomy is MECE (no major gaps) | Knowledge | Shallow | Medium |
| Skills remain valid as problems evolve | Stability | Deep | High |
| Quality of individual skills is sufficient | Capability | Shallow | High |

**Claim 3: "Chaining produces emergence"**

| Assumption | Type | Hiddenness | Risk if Wrong |
|------------|------|------------|---------------|
| Composition preserves quality (errors don't compound) | Causal | **Buried** | **Critical** |
| The routing/selection of which skills to chain is solvable | Capability | Deep | High |
| Sequential text-based execution can maintain coherence across long chains | Capability | Deep | High |
| Emergence from composition actually occurs (not just additive) | Existence | **Buried** | **Critical** |

**Claim 4: "This approach is viable vs. alternatives"**

| Assumption | Type | Hiddenness | Risk if Wrong |
|------------|------|------------|---------------|
| Scaling laws plateau (you can't just scale to SI) | Causal | Deep | Medium |
| External scaffolding adds what training doesn't | Existence | Deep | High |
| Procedure overhead doesn't eliminate gains | Resources | Shallow | Medium |
| Other approaches won't obsolete this first | Timing | Deep | High |

### Priority Assumptions (Must Verify First)

1. **Intelligence is largely procedural** — If reasoning is fundamentally non-procedural (intuitive, embodied, requires consciousness), structured procedures hit a hard ceiling.
2. **Composition preserves quality** — If errors compound through chains (garbage in/garbage out across 6+ steps), the system degrades instead of improving.
3. **Emergence from composition actually occurs** — If chaining 6 skills just gives you 6x the output without qualitative leaps, there's no path to SI.
4. **Procedure quality has no ceiling** — If procedures asymptote at "expert human level," this produces very good AI but not superintelligence.

---

## STEP 4: PROCEDURE GENERATION (`/stg`)

```
================================================================
ACHIEVING SUPERINTELLIGENCE THROUGH A REASONING TOOLKIT
DECISION PROCEDURE
================================================================

PURPOSE: Determine whether your reasoning toolkit project can
achieve superintelligence, what type, and what to do next.

WHO THIS IS FOR: Anyone building or evaluating a structured
reasoning toolkit (library of procedures/skills that an AI
follows to reason better).

================================================================

STEP 0: CLASSIFY YOUR SITUATION
================================================================

Answer this question: What is your current state?

A) "I have an idea for a reasoning toolkit but haven't built it"
   -> Go to SECTION A (Feasibility Check)

B) "I have a working toolkit with skills/procedures"
   -> Go to SECTION B (Capability Assessment)

C) "I have a toolkit and want to know how to push toward SI"
   -> Go to SECTION C (Gap Analysis & Strategy)

D) "I want to evaluate someone else's claim about their toolkit"
   -> Go to SECTION D (Claim Evaluation)

================================================================

SECTION A: FEASIBILITY CHECK
(For people who haven't built it yet)
================================================================

Step A1: Define what you mean by "superintelligence."
  Pick ONE:

  [ ] SPEED: Reasoning faster than any human
  [ ] QUALITY: Better conclusions than any human expert
  [ ] BREADTH: Superhuman across all domains simultaneously
  [ ] DOMAIN: Superhuman in one specific domain
  [ ] COLLECTIVE: Better than any team of humans working together

  Write down your choice: _______________

Step A2: Check the architecture match.
  Look up your definition in this table:

  | Your Definition | Can procedures help? | Ceiling |
  |---|---|---|
  | SPEED | No. Speed is hardware. | Hard ceiling. STOP. |
  | QUALITY | Yes. Procedures codify expert reasoning. | Expert-level. Maybe above. |
  | BREADTH | Partially. Requires composability + completeness. | Unknown. |
  | DOMAIN | Yes. Domain experts can encode knowledge. | Domain expert level. |
  | COLLECTIVE | Partially. Can simulate perspectives. | Below true independence. |

  If your definition says "No" -> This approach won't work for your goal.
  Consider a different approach. STOP.

  If "Yes" or "Partially" -> Continue to A3.

Step A3: Check the four critical assumptions.
  For each, find evidence or admit you're guessing:

  [ ] "The reasoning I want to improve is procedural"
    Test: Can a human expert explain their reasoning as steps?
    If YES -> Assumption holds.
    If NO -> Procedures can't capture this. STOP or redefine goal.

  [ ] "Correct procedures produce correct conclusions"
    Test: When experts follow best-practice procedures, do they
    get better results than experts using intuition alone?
    If YES -> Assumption holds.
    If NO -> Procedures are necessary but not sufficient.
    Flag: You'll need something beyond procedures.

  [ ] "Chaining procedures produces better results than individual ones"
    Test: Does applying analysis A, then analysis B to A's output,
    produce insight that neither A nor B alone would?
    If YES -> Composition works.
    If NO -> Your toolkit will be additive, not multiplicative.
    Flag: No path to emergence. Reconsider.

  [ ] "Procedure quality can exceed human expert level"
    Test: Can a procedure incorporate checks, perspectives, and
    rigor that no single human would apply?
    If YES -> Ceiling may be above human.
    If NO -> Ceiling is human expert level. Decide if that's enough.

  Count your YES answers: ___/4

  4/4: Strong feasibility. -> Go to SECTION C.
  3/4: Conditional feasibility. Note which failed. -> Go to SECTION C
       with that constraint in mind.
  2/4 or fewer: Weak feasibility. Consider alternative approaches.
       -> STOP or redefine.

================================================================

SECTION B: CAPABILITY ASSESSMENT
(For people with a working toolkit)
================================================================

Step B1: Count your skills.
  Total skills in your toolkit: ___

  Interpretation:
  - <50: Early stage. Likely missing major categories.
  - 50-200: Developing. Check for coverage gaps.
  - 200-500: Substantial. Focus on quality and composition.
  - >500: Extensive. Focus on verification and emergence.

Step B2: Test skill quality on 5 random skills.
  Pick 5 skills at random. For each, answer:

  [ ] Can someone with NO domain expertise follow it? (Y/N)
  [ ] Does it produce a concrete, checkable output? (Y/N)
  [ ] Has it been tested on at least 3 real problems? (Y/N)
  [ ] Does it chain correctly with other skills? (Y/N)

  Score: Count total YES across all 5 skills (out of 20): ___/20

  - 16-20: High quality. Your skills work.
  - 10-15: Mixed quality. Improve weak skills before expanding.
  - <10: Low quality. Fix quality before adding more skills.

Step B3: Test composition.
  Take a complex problem. Apply a 3+ skill chain to it.

  [ ] Did each skill receive usable input from the previous one? (Y/N)
  [ ] Did the chain produce insight that no single skill would? (Y/N)
  [ ] Did quality degrade through the chain? (Y/N -- you want NO)
  [ ] Was the routing decision (which skills to chain) obvious? (Y/N)

  If all favorable: Composition is working. -> Go to SECTION C.
  If quality degraded: Fix error propagation before proceeding.
  If routing was unclear: Build better meta-skills / orchestrators.
  If no emergent insight: Composition is additive only. Flag this.

Step B4: Test against baselines.
  Take 3 problems your toolkit should excel at.

  [ ] Run each through your best skill chain. Record output quality (1-10).
  [ ] Have the same AI solve them WITHOUT your toolkit. Record quality (1-10).

  Average with toolkit: ___/10
  Average without: ___/10
  Delta: ___

  - Delta > 3: Toolkit adds major value.
  - Delta 1-3: Toolkit adds moderate value.
  - Delta < 1: Toolkit isn't helping. Diagnose why before continuing.

  -> Go to SECTION C.

================================================================

SECTION C: GAP ANALYSIS & STRATEGY
(For people ready to push toward SI)
================================================================

Step C1: Identify which SI dimension you're closest to.
  Based on your work so far, rank these 1-5 (1 = closest):

  ___ Quality: Better conclusions than any human expert
  ___ Breadth: Coverage across all problem types
  ___ Consistency: Always applying best reasoning (no lazy shortcuts)
  ___ Composition: Chains produce emergent insight
  ___ Self-improvement: System improves its own procedures

  Your #1 ranking is your **current strength**.
  Your #5 ranking is your **critical gap**.

Step C2: Map your critical gap to an action.

  | Critical Gap | What To Do Next |
  |---|---|
  | Quality | Run /pv and /vbo on all skills. Bring in domain experts. |
  | Breadth | Run /mv on your skill categories. Fill gaps systematically. |
  | Consistency | Build better orchestrators (/gosm). Reduce routing errors. |
  | Composition | Design explicit input/output contracts between skills. |
  | Self-improvement | Build /iterate, /ret, /pcef loops that modify skills. |

Step C3: Check for the three hard ceilings.
  These are ceilings that procedures CANNOT break through:

  CEILING 1: "Model can't follow the procedure"
    Test: Give your hardest skill chain to the AI.
    Does it execute faithfully, or does it drift/simplify/skip?
    If it drifts -> You're limited by the base model.
    Action: Wait for better models, or simplify procedures.

  CEILING 2: "Procedures capture process but not insight"
    Test: Does your toolkit discover things no human has discovered?
    If NO -> You're at human expert ceiling.
    Action: Build procedures that explore BEYOND known approaches
    (e.g., systematic assumption inversion, cross-domain transfer).

  CEILING 3: "Composition is additive, not multiplicative"
    Test: Does a 6-skill chain produce 6x the insight of 1 skill,
    or qualitatively different insight?
    If 6x -> Additive. No path to emergence.
    Action: Redesign composition to be recursive, not sequential.

  Ceilings hit: ___/3

  0 ceilings: Path to SI is theoretically open. Continue.
  1 ceiling: Addressable. Follow the action for that ceiling.
  2+ ceilings: SI is unlikely through this approach alone.
  -> Consider: Is "very good AI reasoning" (not SI) enough for you?

Step C4: Choose your strategy.
  Based on ceilings and gaps:

  | Situation | Strategy |
  |---|---|
  | No ceilings, gap is Quality | DEPTH: Perfect your best skills |
  | No ceilings, gap is Breadth | EXPANSION: Systematic coverage |
  | No ceilings, gap is Composition | ARCHITECTURE: Redesign chaining |
  | No ceilings, gap is Self-improvement | META: Build recursive improvement |
  | 1 ceiling (model) | WAIT + OPTIMIZE: Prepare for better models |
  | 1 ceiling (insight) | NOVELTY: Focus on discovery procedures |
  | 1 ceiling (composition) | REDESIGN: New composition paradigm |
  | 2+ ceilings | REDEFINE: Adjust goal to "excellent AI" not SI |

  Your strategy: _______________

Step C5: Set your next milestone.
  Write down ONE concrete thing you will build or test next
  that advances your chosen strategy:

  "I will _______________ and measure success by _______________."

  -> Execute that milestone. Return to Step C1 after completing it.

================================================================

SECTION D: CLAIM EVALUATION
(For evaluating others' superintelligence claims)
================================================================

Step D1: Identify what type of SI they're claiming.
  Look for their definition. If none given -> RED FLAG.
  If given, classify using the table from Step A1.

Step D2: Check for the four critical assumptions.
  Do they address:
  [ ] Whether intelligence is procedural? If not addressed -> Flag.
  [ ] Whether composition preserves quality? If not addressed -> Flag.
  [ ] Whether emergence occurs? If not addressed -> Flag.
  [ ] Whether there's a ceiling? If not addressed -> Flag.

  Unaddressed assumptions: ___/4
  - 0: Thorough claim. Evaluate the evidence.
  - 1-2: Partial claim. Ask about unaddressed assumptions.
  - 3-4: Ungrounded claim. Do not accept without evidence.

Step D3: Ask for evidence of composition.
  The single most important test: Does chaining procedures produce
  qualitatively better results than individual procedures?

  [ ] Evidence provided and verifiable -> Credible claim.
  [ ] Evidence provided but not verifiable -> Uncertain.
  [ ] No evidence -> Not credible.
```

---

## STEP 5: FAILURE ANTICIPATION (`/fla`)

### Failure Modes When Following This Procedure

| # | Failure Mode | O | S | D | RPN | Tier |
|---|---|---|---|---|---|---|
| 1 | **User conflates "very good AI" with "superintelligence"** and proceeds with inflated expectations | 8 | 7 | 8 | 448 | Critical |
| 2 | **User skips assumption testing** (Step A3) and builds on false foundations | 7 | 9 | 6 | 378 | Critical |
| 3 | **Composition test (B3) gives false positive** because the test problem was too easy | 6 | 8 | 7 | 336 | Critical |
| 4 | **User misidentifies their critical gap** (C1) and pursues wrong strategy | 6 | 7 | 6 | 252 | Critical |
| 5 | **Definition of SI too vague** to classify in Step A1 | 7 | 5 | 4 | 140 | High |
| 6 | **Baseline test (B4) unfair** -- toolkit gets harder problems or different conditions | 5 | 6 | 5 | 150 | High |
| 7 | **User hits ceiling but refuses to accept it** and continues investing | 5 | 8 | 7 | 280 | Critical |
| 8 | **Self-improvement loop creates drift** -- recursive editing degrades procedures | 4 | 9 | 8 | 288 | Critical |

### Mitigations (Added as Warnings)

**WARNING 1** (Failure #1): Before proceeding past Step A1, write down in one sentence what would convince you that you have NOT achieved superintelligence. If you can't write this sentence, your definition isn't precise enough. Stop and refine it.

**WARNING 2** (Failure #2): Step A3 is the most important step in this entire procedure. Do not proceed with "I think so" answers. Each assumption needs an actual test with actual evidence. "I assume so" = NO.

**WARNING 3** (Failure #3): When testing composition in Step B3, use a problem you already know the correct answer to (but one that's genuinely hard). If the chain gives you the known-correct answer through a reasoning path you can verify, composition is working. If you can't verify the path, the test is inconclusive.

**WARNING 4** (Failure #7): Set a kill criterion before starting. Write down: "If after [X months/resources], I have not demonstrated [specific measurable improvement], I will [specific alternative action]." Revisit this every time you complete Step C5.

**WARNING 5** (Failure #8): If you build self-improvement (Step C2, Self-improvement row), keep a frozen copy of your best-performing procedures. Compare improved versions against the frozen copy. If the improved version performs worse on a test suite, revert.

---

## STEP 6: PROCEDURE VALIDATION (`/pv`)

### Validation Report

| Dimension | Status | Issues |
|-----------|--------|--------|
| Completeness | [x] | All paths from Step 0 lead to concrete outputs |
| Dependencies | [x] | Sections reference prior outputs correctly |
| Feasibility | [!] | 2 steps require judgment calls (see below) |
| Inputs | [x] | All inputs are obtainable by the user |
| Outputs | [x] | Every path terminates in a decision or action |
| Consistency | [x] | No contradictions found |

### Feasibility Issues Found and Fixed

**Issue 1**: Step C1 "rank these 1-5" requires self-assessment that could be unreliable.
- **Fix**: Added objective tests for each dimension (quality = /pv scores, breadth = /mv coverage, composition = chain test delta, etc.)

**Issue 2**: Step A3's "find evidence" is vague for someone with no research skills.
- **Fix**: Each assumption now has a specific test with YES/NO observable outcome.

### Dead-End Check
- Every STOP has a reason stated.
- Every "Go to Section X" target exists.
- Every Section ends with either a concrete action, a STOP, or a loop back to C1.
- No infinite loops: C1->C5 loop has a kill criterion (Warning 4) that forces eventual STOP.

### OVERALL STATUS: **VALID WITH WARNINGS**

---

## COMMON MISTAKES

1. **Equating "useful" with "superintelligent."** A toolkit that makes AI 30% better at analysis is extremely valuable. It is not superintelligence. Don't let the value of the product inflate the claim.

2. **Testing composition on easy problems.** If a single skill can solve it, a chain of 6 skills will also solve it -- but that doesn't prove emergence. Test on problems that genuinely require the chain.

3. **Ignoring the model ceiling.** Your procedures are only as good as the model's ability to follow them. If the model simplifies, skips, or hallucinates through your procedures, the toolkit's theoretical quality is irrelevant.

4. **Confusing "more skills" with "closer to SI."** 1000 mediocre skills < 50 excellent skills with good composition. Quality and composability matter more than quantity past ~200 skills.

5. **No falsification criterion.** If nothing could convince you the approach isn't working, you're not doing science -- you're doing faith. Set kill criteria.

---

## WHEN TO OVERRIDE THIS PROCEDURE

- **When a genuine breakthrough in AI occurs** that changes the landscape (e.g., a model that reasons perfectly without scaffolding) -- reassess all assumptions from scratch.
- **When you have domain expertise** in AI safety or cognitive science -- your informed judgment may override the generic checks here.
- **When the goal shifts** -- if "very good AI reasoning tool" becomes the goal instead of SI, most of this procedure is overkill. Just build and test.
- **When working with a team** -- this procedure assumes a single decision-maker. Teams need the additional step of alignment on definitions (Step A1 must be unanimous).

---

## WORKED EXAMPLES

### Example 1: This Project (Reasoning Toolkit, 355 skills)

**Step 0**: Situation B -- working toolkit exists.

**Step B1**: 355 skills -> "Substantial. Focus on quality and composition."

**Step B2**: (Hypothetical test of 5 random skills)
- /rca: Followable? Y. Concrete output? Y. Tested? Y. Chains? Y. -> 4/4
- /cda: Followable? Y. Concrete output? Y. Tested? N. Chains? Y. -> 3/4
- /spp: Followable? N (domain-specific). Concrete output? Y. Tested? N. Chains? N. -> 1/4
- /dcp: Followable? Y. Concrete output? Y. Tested? Y. Chains? Y. -> 4/4
- /hvh: Followable? Y. Concrete output? Y. Tested? N. Chains? Y. -> 3/4
- Score: 15/20 -> "Mixed quality. Improve weak skills before expanding."

**Step B3**: Testing /dcp chain (this very execution):
- Did each skill receive usable input? YES (each step fed the next).
- Emergent insight? YES -- the ceiling analysis was not contained in any single skill.
- Quality degradation? Slight -- later steps have less precision.
- Routing obvious? YES -- the chain is pre-specified.

**Step B4**: Would need empirical testing. Flag for action.

**Step C1**: Ranking: Quality(2), Breadth(1), Consistency(3), Composition(4), Self-improvement(5).
- Strength: Breadth. Gap: Self-improvement.

**Step C2**: "Build /iterate, /ret, /pcef loops that modify skills."

**Step C3**: Ceiling 1 (model) -- partially hit. Long chains cause drift. Ceiling 2 (insight) -- untested. Ceiling 3 (composition) -- appears additive so far but needs rigorous testing.

**Verdict**: 1-2 ceilings likely active. Strategy: **REDEFINE** goal to "excellent AI reasoning augmentation" while testing whether ceilings can be broken. Set kill criterion for SI-specific claims.

### Example 2: Hypothetical -- New Toolkit, 20 Skills

**Step 0**: Situation A -- early idea stage.
**Step A1**: Definition = Quality SI.
**Step A2**: "Yes, procedures can help. Ceiling: expert-level."
**Step A3**: Assumption 1 (procedural) = YES. Assumption 2 (correct procedures) = YES. Assumption 3 (composition) = UNTESTABLE (only 20 skills). Assumption 4 (no ceiling) = UNKNOWN.
- Score: 2/4 with 2 untestable -> "Weak feasibility. Build more skills before revisiting SI claims."

---

```
================================================================
VALIDATION STATUS: This procedure has not been validated by
domain experts in AI safety, cognitive science, or AGI research.
Apply with appropriate skepticism.
================================================================

QUICK REFERENCE CARDS
================================================================

CARD 1: The Four Critical Assumptions
+---------------------------------------------+
| 1. Intelligence is procedural               |
| 2. Correct procedures -> correct conclusions|
| 3. Composition produces emergence           |
| 4. No hard ceiling on procedure quality     |
|                                             |
| All 4 must hold for SI to be achievable     |
| through procedures.                         |
+---------------------------------------------+

CARD 2: The Three Hard Ceilings
+---------------------------------------------+
| 1. MODEL CEILING: AI can't follow complex   |
|    procedures faithfully                    |
| 2. INSIGHT CEILING: Procedures capture      |
|    known reasoning but can't discover new   |
| 3. COMPOSITION CEILING: Chains are additive |
|    not multiplicative                       |
|                                             |
| If 2+ ceilings active -> redefine goal      |
+---------------------------------------------+

CARD 3: Strategy Selection
+---------------------------------------------+
| Gap in quality    -> DEPTH strategy          |
| Gap in breadth    -> EXPANSION strategy      |
| Gap in chaining   -> ARCHITECTURE strategy   |
| Gap in self-edit  -> META strategy           |
| Ceiling hit       -> WAIT / REDESIGN / NOVEL |
| 2+ ceilings       -> REDEFINE goal           |
+---------------------------------------------+
```
