# DCP — How to Innovate

**Date**: 2026-01-31
**Input**: How to innovate

---

## Step 1: Decision Dimensions (`/dd`)

### Dimension 1: Innovation Type
- **Process innovation** — doing an existing thing in a new way
- **Product innovation** — creating a new thing
- **Business model innovation** — new way of capturing/delivering value
- **Experience innovation** — new way people interact with existing things
- **Category innovation** — creating a new market category

### Dimension 2: Problem Clarity
- No problem identified yet (exploring)
- Vague dissatisfaction
- Clear problem, no solution
- Clear problem, known bad solutions
- Clear problem, existing solutions with known gaps

### Dimension 3: Domain Familiarity
- Complete outsider
- Adjacent (know a related domain)
- Practitioner (work in the domain daily)
- Expert (deep domain knowledge)

### Dimension 4: Resource Level
- Zero budget, spare time only
- Small budget ($1K-$10K), part-time
- Dedicated budget ($10K-$100K), full-time
- Significant resources ($100K+), team available

### Dimension 5: Constraint Profile
- Regulatory/legal constraints
- Physical/technical constraints
- Market/customer constraints
- Resource/time constraints
- Organizational/political constraints

### Dimension 6: Novelty Requirement
- Must be genuinely new to the world
- New to this industry/domain (can exist elsewhere)
- New to this organization (can exist in competitors)
- New combination of existing elements

### Dimension 7: Validation Speed
- Can test in hours/days (software, content, services)
- Can test in weeks (physical products, processes)
- Can test in months (business models, platforms)
- Takes years to validate (infrastructure, deep tech)

### Dimension 8: Adoption Dependency
- Works for one person/org immediately
- Requires small group adoption
- Requires ecosystem/network adoption
- Requires behavioral/cultural shift

### Dimension 9: Existing Attempts
- Many have tried, all failed
- Some have tried, partial success
- Few have tried (unclear why)
- Nobody has tried (hidden reasons?)
- Others succeeded but solution is inaccessible

### Dimension 10: Value Capture
- Value is inherently capturable (product you can sell)
- Value is diffuse (improves a system, hard to charge for)
- Value accrues to others (platform dynamics)
- Value is long-term/speculative

---

## Step 2: Option Space (`/se`)

### Innovation Method Inventory

| Method | Best when... | Worst when... |
|---|---|---|
| **Customer problem interviews** | Problem unclear, domain familiar | Outsider with no access to users |
| **Analogical transfer** | Adjacent domain knowledge, low novelty requirement | Must be genuinely world-new |
| **Constraint removal** | Many assumed constraints, expert in domain | Constraints are truly immovable |
| **Inversion** | Industry has strong conventions | Conventions exist for regulatory reasons |
| **Combination** | Both things exist and work, nobody combined them | Components are incompatible |
| **Simplification** | Existing solutions are bloated/complex | Complexity is load-bearing |
| **10x target** | Clear metric to improve, resources available | No measurable target |
| **Edge case focus** | Mainstream well-served, edges ignored | Edge cases too small to sustain |
| **Process observation** | Process innovation, domain access | No access to the actual process |
| **First principles decomposition** | Technical/physical domain, expert knowledge | Social/behavioral domain |

### Interaction Rules
- If Problem Clarity = 1-2 → must start with problem discovery
- If Domain Familiarity = 1 → must start with domain immersion
- If Validation Speed = 4 → must have resources for sustained R&D
- If Existing Attempts = "Many tried, all failed" → must understand WHY before attempting

---

## Step 3: Hidden Assumptions (`/aex`)

**A1: "Innovation requires creativity"**
Reality: Most successful innovation is systematic pattern matching — finding what works elsewhere and applying it here.

**A2: "Good ideas are rare and valuable"**
Reality: Ideas are abundant and nearly worthless. The bottleneck is problem identification, execution, and adoption.

**A3: "Innovation starts with brainstorming"**
Reality: Innovation starts with observation — watching real people struggle with real tasks.

**A4: "Disruption means replacing the incumbent"**
Reality: Most successful innovations serve people who currently can't be served or improve one dimension dramatically while being worse on others.

**A5: "You need a unique idea"**
Reality: Execution uniqueness matters more than idea uniqueness.

**A6: "Innovation requires big leaps"**
Reality: Most valuable innovation is incremental — small improvements compounded over time.

**A7: "The best idea wins"**
Reality: The idea with the best distribution wins.

**A8: "You should protect your idea"**
Reality: Stealth mode kills more innovations than theft does. Sharing gets you feedback, collaborators, and customers.

**A9: "Innovation means technology"**
Reality: Many impactful innovations are process, business model, or experience innovations using no new technology.

**A10: "Failure is learning"**
Reality: Failure is only learning if you structured the attempt to generate specific information. Unstructured failure teaches nothing.

---

## Step 4: The Procedure (`/stg`)

```
INNOVATION PROCEDURE
=====================

WHO THIS IS FOR: Anyone trying to create something new.
WHAT YOU'LL GET: A specific, testable innovation hypothesis and a
plan to validate it in the smallest possible way.

═══════════════════════════════════════════════
STEP 0: DO YOU HAVE A PROBLEM?
═══════════════════════════════════════════════

  → YES, I can describe who has it and what they do → SECTION B
  → SORT OF, vague sense something should be better → SECTION A
  → NO, I just want to innovate / find opportunities → SECTION A

═══════════════════════════════════════════════
SECTION A: PROBLEM DISCOVERY
═══════════════════════════════════════════════

Step A1: Choose an observation domain.
  Pick ONE:
  □ Your own daily work (what frustrates you?)
  □ A specific industry you know (what's wasteful?)
  □ A group of people you have access to (what do they struggle with?)
  □ A process you participate in (what's broken?)

  RULE: Pick the domain where you have the most ACCESS TO REAL
  PEOPLE DOING REAL TASKS.

Step A2: Observe for problems (not solutions).
  Spend 5-10 hours over the next week doing ONE of:
  □ Shadow 3 people. Write down every tool switch, redo, wait,
    complaint, unnecessary step, mistake recovery.
  □ Interview 5 people. Ask ONLY:
    - "Walk me through your typical [day/week/process]."
    - "What's the most annoying part?"
    - "What takes longer than it should?"
    - "What do you wish someone would fix?"
    - "What did you try that didn't work?"
  □ Do the task yourself. Keep a frustration journal.

  OUTPUT: At least 10 observed problems/frustrations.

  RULE: Do NOT think about solutions. Write solution ideas in a
  SEPARATE list and go back to observing.

Step A3: Rank problems by pain × frequency.
  - PAIN (1-3): 1 = minor, 2 = significant, 3 = real damage
  - FREQUENCY (1-3): 1 = rarely, 2 = weekly, 3 = daily+
  - Priority = Pain × Frequency (1-9)

  CHECKPOINT: At least 3 problems scoring 6+?
    → YES: Pick highest. Go to SECTION B.
    → NO: Observation was too shallow. Repeat A2 with more time.

═══════════════════════════════════════════════
SECTION B: PROBLEM DEFINITION
═══════════════════════════════════════════════

Step B1: Write the problem statement.
  Fill in ALL blanks:
  WHO: [specific person/role]
  DOES WHAT: [specific task]
  USING: [current method/tool]
  AND THE PROBLEM IS: [specific pain]
  WHICH COSTS THEM: [measurable consequence]

  RULE: If you can't fill in "WHICH COSTS THEM" with a number,
  the problem may not be painful enough.

Step B2: Verify the problem is real.
  Ask 5 people who match your WHO:
  □ "Do you experience [PROBLEM]?"
  □ "How often?"
  □ "What do you currently do about it?"
  □ "How much does it cost you?"
  □ "Have you tried to solve it?"

  CHECKPOINT: 4 of 5 confirmed?
    → YES: Go to B3.
    → NO: Back to A2. Listen for THEIR problems.

Step B3: Map existing solutions.
  List EVERY way people currently deal with this:
  □ Commercial products/services
  □ DIY workarounds
  □ The "do nothing" approach
  □ Hiring someone

  For each: what it does well, where it falls short, why used.

  CHECKPOINT: 0 existing solutions?
    → WARNING: Usually means problem isn't painful enough or
      structural barrier exists. Ask WHO: "Would you pay $X?"
      If yes → rare opportunity. If no → different problem.

Step B4: Identify the gap.
  "Existing solutions fail because they _______________.
  If a solution could _______________ instead, it would be
  worth [time/money] to [WHO]."

  This is your INNOVATION HYPOTHESIS.

→ Go to SECTION C.

═══════════════════════════════════════════════
SECTION C: SOLUTION GENERATION
═══════════════════════════════════════════════

Step C1: Steal from adjacent domains.
  Ask:
  □ "What OTHER industry has a similar problem?"
  □ "What field handles [your core challenge] routinely?"
  □ "If [different profession] faced this, what would they do?"

  Write down 3-5 analogies from other domains.

  SEARCH TIP: "[your core problem verb] in [random industry]"

Step C2: Apply constraint removal.
  For each constraint you assume:
  | Current constraint | What if removed? | Actually immovable? |

  Any "not actually immovable" = potential innovation vector.

Step C3: Apply inversion.
  Write standard approach. Do the opposite on each dimension:
  | Standard approach | Opposite | Could opposite work? |

Step C4: Generate candidate solutions.
  Using C1-C3, write 5-10 solutions. For each:
  "[Solution] solves [problem] by [mechanism] for [WHO]."

  RULE: Do not evaluate yet. Just generate.

Step C5: Score solutions.
  - FEASIBILITY (1-3): 1 = major breakthroughs, 3 = prototype this month
  - IMPACT (1-3): 1 = marginal, 3 = transformative/10x
  - DEFENSIBILITY (1-3): 1 = trivially copyable, 3 = structural moat
  - Total = F + I + D (3-9)

  Pick highest score. If tied, pick higher Feasibility.

→ Go to SECTION D.

═══════════════════════════════════════════════
SECTION D: MINIMUM VIABLE TEST
═══════════════════════════════════════════════

Step D1: Identify the riskiest assumption.
  List assumptions:
  □ "[WHO] actually has this problem" (validated in B2 ✓)
  □ "[WHO] would use this solution"
  □ "[WHO] would pay for this solution"
  □ "This solution is technically feasible"
  □ "This is better than current alternatives"

  Circle the ONE that, if wrong, kills everything.

Step D2: Design the cheapest possible test.
  | Assumption type | Cheapest test |
  | "People want this" | Landing page + signup. 100 visitors → 10+ signups? |
  | "People would pay" | Pre-sell. Take payment before building. 5+ paid? |
  | "Technically possible" | Build core mechanism only. Does it work? |
  | "Better than alternatives" | Give 5 users both. Which preferred? |

  RULE: Completable in 1-2 weeks with current resources.

Step D3: Define success/failure criteria BEFORE testing.
  - "This test PASSES if: _______________"
  - "This test FAILS if: _______________"
  - "This test is INCONCLUSIVE if: _______________"

Step D4: Run the test.
  → PASS: Go to Section E.
  → FAIL: Back to B4 (refine hypothesis) or C4 (different solution).
  → INCONCLUSIVE: Redesign test (D2) with clearer criteria (D3).

═══════════════════════════════════════════════
SECTION E: BUILD & ITERATE
═══════════════════════════════════════════════

Step E1: Build minimum viable product.
  MVP includes ONLY:
  □ Core mechanism that solves the problem
  □ Minimum interface for someone to use it
  □ Way to collect feedback

  MVP does NOT include:
  ✗ User accounts (unless essential)
  ✗ Payment (charge manually first)
  ✗ Polish
  ✗ Edge cases
  ✗ Scale

Step E2: Get 10 real users.
  Not friends. Real people matching WHO. Watch them use it.
  Record: understanding, completion, return rate, complaints, requests.

Step E3: Decide next step.
  | Signal | Action |
  | Complete task, come back | Improve and grow |
  | Complete task, don't return | Revisit B1 — problem real? |
  | Can't complete task | Back to C4 — different approach |
  | Don't understand it | Rewrite pitch |
  | Ask for different feature | Back to A2 — observe more |

Step E4: Iterate.
  1. Fix #1 complaint
  2. Get 10 more users
  3. Repeat E2-E3
  4. Continue to 100 active users

  CHECKPOINT at 100 users:
  → Users paying? → You have an innovation. Focus on distribution.
  → Like it but won't pay? → Feature, not product. Find different
    value capture or integrate into existing product.
  → Can't reach 100? → Market too small or solution not compelling.
    Back to B1 with learnings.

→ PROCEDURE COMPLETE
```

---

## Step 5: Failure Modes (`/fla`)

### FAILURE MODE 1: "Solution-First Thinking"
**Recognize**: Jumped to Section C/D without A or B. Have a solution looking for a problem.
**Fix**: Stop. Go to Section A. Observe 5 hours before generating ANY solutions.

### FAILURE MODE 2: "Idea Hoarding"
**Recognize**: 50+ ideas, none tested. Keep generating because testing feels scary.
**Fix**: Pick highest feasibility idea. Test THIS WEEK.

### FAILURE MODE 3: "Build Trap"
**Recognize**: Building for months without showing to a real user. "Not ready yet."
**Fix**: Ship what you have. Today. To one person.

### FAILURE MODE 4: "Confirmation Bias in Testing"
**Recognize**: Test "passed" but success defined after results. Only showed to friends.
**Fix**: Re-run D3. Write criteria first. Show to strangers. Ask "would you pay $X right now?"

### FAILURE MODE 5: "Innovating Where Nobody Asked"
**Recognize**: Technically impressive but users shrug. Keep explaining why they should care.
**Fix**: If you have to explain why it's better, it's not better enough. Back to B1.

### FAILURE MODE 6: "Premature Scaling"
**Recognize**: 10 users, building for 10,000. Hiring before product-market fit.
**Fix**: Don't add people or infrastructure until 100-user checkpoint passes.

### FAILURE MODE 7: "Ignoring Existing Attempts"
**Recognize**: Didn't research B3, repeating someone else's failed approach.
**Fix**: 2 hours researching who tried before. Find them. Ask what went wrong.

### FAILURE MODE 8: "Wrong Dimension"
**Recognize**: Making something faster when the real problem is it shouldn't exist. Making something cheaper when the problem is trust.
**Fix**: Back to B2. Ask "wave a magic wand, change ONE thing." Listen for THEIR dimension.

---

## Step 6: Validation (`/pv`)

All steps verified as executable by non-experts. All checkpoints route to forward progress or specific back-steps with new information. No dead ends or infinite loops.

---

## QUICK REFERENCE CARDS

### Card 1: The Innovation Sequence
```
OBSERVE (problems) → DEFINE (one problem precisely) →
VERIFY (others have it too) → GENERATE (from analogies,
constraints, inversions) → TEST (cheapest validation) →
BUILD (minimum viable) → ITERATE
```

### Card 2: The Three Questions That Matter
```
1. Who has this problem? (If nobody, stop.)
2. What do they do about it now? (If nothing, why?)
3. Would they switch to your solution? (If not, why?)
```

### Card 3: Kill Signals
```
STOP if:
- 5 interviews, nobody confirms the problem
- Built a test, result was FAIL
- 10 users tried it, none came back
- 3 months building with 0 users
```

---

## COMMON MISTAKES

1. **Starting with solutions** — "I have an idea for an app!" is not innovation. Find the problem first.
2. **Brainstorming before observing** — Go watch someone work instead.
3. **Asking people what they want** — They can't tell you. Observe behavior.
4. **Treating innovation as a single event** — It's an iterative loop.
5. **Building instead of testing** — Every month without feedback = accumulated wrong assumptions.
6. **Confusing novelty with value** — "Nobody has done this" is usually a warning sign.
7. **Protecting the idea** — Share with 100 people. Reactions > secrecy.
8. **Optimizing before validating** — Don't make it better until confirmed someone wants it.
9. **Ignoring distribution** — How people FIND it matters as much as what it is.
10. **Innovating on strengths not pain** — Start from their pain, not your toolkit.

---

## WHEN TO OVERRIDE

- **Domain expert**: Skip A, start at B. Still do B2.
- **Scientific/deep-tech**: Replace D with formal research design. A-B still apply.
- **Internal to organization**: Add stakeholder alignment between B and C.
- **Artist/creative**: Different rules — taste and vision matter more.
- **Paying customer requesting something**: Skip everything. Build what they asked for.

---

## WORKED EXAMPLES

### Example 1: Process Innovation (Solo, spare time)
- **A2**: Observed debugging requires checking 5 dashboards (Pain 3 × Freq 3 = 9)
- **B1**: Backend devs / debug production issues / 5 separate tools / context-switching loses 15 min per incident / ~$500/incident
- **C1**: Air traffic controllers use unified display. Applied to debugging.
- **D2**: Chrome extension opening all 5 dashboards pre-filtered in split screen.
- **D4**: 4/5 teammates installed and kept using. PASS.

### Example 2: Product Innovation (Small team)
- **A2**: Shadowed restaurant owners. Food waste from over-ordering (Pain 3 × Freq 3 = 9)
- **B4**: "Existing solutions fail because they require manual data entry. If a solution auto-predicted orders from POS data, save $500/month."
- **D2**: Manually analyzed 3 months POS data, predicted next week's order. Within 8%.
- **D4**: Owner: "I'd pay $100/month." PASS.

### Example 3: Business Model Innovation (Zero budget)
- **B1**: Freelance writers / find clients / cold emails + job boards / 60% time on sales / lose $30K/year potential billing
- **C3** (inversion): Writers find clients → clients find writers. Per-project → subscription.
- **D2**: One writer posted "subscribe to a SaaS writer - 4 posts/month, $2000." Goal: 2 subscribers in 2 weeks.
- **D4**: 1 subscriber + 3 inquiries. Partial pass — continue testing.

---

**Validation status**: This procedure has not been validated by domain experts.
